{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fraud Analytics Project 2 - Fraud Detection in Credit Card Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sps\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from math import log10\n",
    "import random\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96753, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read data set\n",
    "mydata = pd.read_excel('card transactions.xlsx', converters={'Merchnum': lambda x: str(x)})\n",
    "mydata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning: fill in the missing fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill NA for Merch state\n",
    "mydata['Merch state'] = mydata.groupby('Merch description')['Merch state'].apply(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan))\n",
    "mydata['Merch state'] = mydata['Merch state'].fillna(mydata['Merch state'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill NA for Merch zip\n",
    "mydata['Merch zip'] = mydata.groupby('Merch description')['Merch zip'].apply(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan))\n",
    "mydata['Merch zip'] = mydata.groupby('Merch state')['Merch zip'].apply(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan))\n",
    "mydata['Merch zip'] = mydata['Merch zip'].fillna(mydata['Merch zip'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill NA for Merchnum\n",
    "mydata['Merchnum'] = mydata.groupby('Merch description')['Merchnum'].apply(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan))\n",
    "mydata['Merchnum'] = mydata.groupby('Merch zip')['Merchnum'].apply(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan))\n",
    "mydata['Merchnum'] = mydata.groupby('Merch state')['Merchnum'].apply(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check whether there are any NAs for Merchnum\n",
    "mydata['Merchnum'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check whether there are any NAs for Merch state\n",
    "mydata['Merch state'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check whether there are any NAs for Merch zip\n",
    "mydata['Merch zip'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all (expert) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create card at this merchant - card_merch\n",
    "mydata['card_merch'] = mydata.Cardnum.astype(str).str.cat(mydata.Merchnum)\n",
    "\n",
    "## Create card in this zip code - card_zip\n",
    "mydata['card_zip'] = mydata.Cardnum.astype(str).str.cat(mydata['Merch zip'].astype(str))\n",
    "\n",
    "## Create card in this state - card_state\n",
    "mydata['card_state'] = mydata.Cardnum.astype(str).str.cat(mydata['Merch state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5 entities\n",
    "entities = ['Cardnum', 'Merchnum', 'card_merch', 'card_zip', 'card_state']\n",
    "\n",
    "## Copy two columns Recnum -> check_record, Date -> check_date\n",
    "mydata['check_record'] = mydata.Recnum\n",
    "mydata['check_date'] = mydata.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in entities:\n",
    "    ## Days-since variables\n",
    "    df_l = mydata[['Recnum', 'Date', entity]]\n",
    "    df_r = mydata[['check_record', 'check_date', entity, 'Amount']]\n",
    "    temp = pd.merge(df_l, df_r, left_on = entity, right_on = entity)\n",
    "    temp1 = temp[temp.Recnum > temp.check_record][['Recnum', 'Date', 'check_date']].groupby('Recnum')[['Date', 'check_date']].last()\n",
    "    mapper = (temp1.Date - temp1.check_date).dt.days\n",
    "    mydata[entity + '_day_since'] = mydata.Recnum.map(mapper)\n",
    "    mydata[entity + '_day_since'].fillna((mydata.Date - pd.to_datetime('2010-01-01')).dt.days, inplace = True)\n",
    "    \n",
    "    ## Frequency variables\n",
    "    for time in [0, 1, 3, 7, 14, 30]:\n",
    "        temp2 = temp[(temp.check_date >= (temp.Date - dt.timedelta(time))) & (temp.Recnum >= temp.check_record)][['Recnum', entity, 'Amount']]\n",
    "        col_name = entity + '_count_' + str(time)\n",
    "        mapper2 = temp2.groupby('Recnum')[entity].count()\n",
    "        mydata[col_name] = mydata.Recnum.map(mapper2)\n",
    "        \n",
    "        ## Amount variables\n",
    "        mydata[entity + '_avg_' + str(time)] = mydata.Recnum.map(temp2.groupby('Recnum')['Amount'].mean())\n",
    "        mydata[entity + '_max_' + str(time)] = mydata.Recnum.map(temp2.groupby('Recnum')['Amount'].max())\n",
    "        mydata[entity + '_med_' + str(time)] = mydata.Recnum.map(temp2.groupby('Recnum')['Amount'].median())\n",
    "        mydata[entity + '_total_' + str(time)] = mydata.Recnum.map(temp2.groupby('Recnum')['Amount'].sum())\n",
    "        mydata[entity + '_actual/avg_' + str(time)] = mydata['Amount'] / mydata[entity + '_avg_' + str(time)]\n",
    "        mydata[entity + '_actual/max_' + str(time)] = mydata['Amount'] / mydata[entity + '_max_' + str(time)]\n",
    "        mydata[entity + '_actual/med_' + str(time)] = mydata['Amount'] / mydata[entity + '_med_' + str(time)]\n",
    "        mydata[entity + '_actual/total_' + str(time)] = mydata['Amount'] / mydata[entity + '_total_' + str(time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2 entities\n",
    "entities2 = ['Cardnum', 'Merchnum']\n",
    "\n",
    "## Velocity change variables\n",
    "for entity in entities2:\n",
    "    for time1 in [0, 1]:\n",
    "        for time2 in [7, 14, 30]:\n",
    "            mydata[entity + '_count_' + str(time1) + '/avg_count_' + str(time2)] = mydata[entity + '_count_' + str(time1)] / (mydata[entity + '_count_' + str(time2)] / time2)\n",
    "            mydata[entity + '_actual_' + str(time1) + '/avg_' + str(time2)] = mydata[entity + '_total_' + str(time1)] / mydata[entity + '_avg_' + str(time2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "## 2 risk table variables\n",
    "c = 4\n",
    "nmid = 20\n",
    "\n",
    "## Get training_testing data\n",
    "mydata1 = mydata[mydata.Date.dt.month.isin([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])]\n",
    "\n",
    "## Likelihood of fraud for that day of the week\n",
    "fraud_avg = mydata1['Fraud'].mean()\n",
    "mydata1['Weekday'] = mydata1.Date.dt.weekday_name\n",
    "fraud_weekday = mydata1.groupby('Weekday')['Fraud'].mean()\n",
    "num_instances_weekday = mydata1.groupby('Weekday').size()\n",
    "fraud_weekday_smooth = fraud_avg + (fraud_weekday - fraud_avg) / (1 + np.exp(-(num_instances_weekday - nmid) / c))\n",
    "mydata1['weekday_risk'] = mydata1['Weekday'].map(fraud_weekday_smooth)\n",
    "\n",
    "## Likelihood of fraud for that state\n",
    "fraud_state = mydata1.groupby('Merch state')['Fraud'].mean()\n",
    "num_instances_state = mydata1.groupby('Merch state').size()\n",
    "fraud_state_smooth = fraud_avg + (fraud_state - fraud_avg) / (1 + np.exp(-(num_instances_state - nmid) / c))\n",
    "mydata1['state_risk'] = mydata1['Merch state'].map(fraud_state_smooth)\n",
    "\n",
    "## Only keep four columns\n",
    "mydata2 = mydata1[['Weekday', 'weekday_risk']].drop_duplicates()\n",
    "mydata3 = mydata1[['Merch state', 'state_risk']].drop_duplicates()\n",
    "\n",
    "## Join to mydata\n",
    "mydata['Weekday'] = mydata.Date.dt.weekday_name\n",
    "mydata = mydata.merge(mydata2, how = 'left', on = 'Weekday')\n",
    "mydata = mydata.merge(mydata3, how = 'left', on = 'Merch state')\n",
    "\n",
    "## Fill NA for state_risk\n",
    "mydata['state_risk'] = mydata.groupby('Merch zip')['state_risk'].apply(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z Scale all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96753, 301)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Drop categorical variables\n",
    "Date = mydata.Date.tolist()\n",
    "Fraud = mydata.Fraud.tolist()\n",
    "mydata_newV = mydata.drop(['Recnum', 'Cardnum', 'Date', 'Merchnum', 'Merch description', 'Merch state', 'Merch zip', 'Transtype', 'Amount', 'Fraud', 'card_merch', 'card_zip', 'card_state', 'check_record', 'check_date', 'Weekday'], axis = 1)\n",
    "mydata_newV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Z scale each field so that the mean is about 0 and standard deviation is about 1\n",
    "scaler = StandardScaler()\n",
    "fieldName = mydata_newV.columns.values.tolist()\n",
    "for i in fieldName:\n",
    "    mydata_newV[i] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(mydata_newV[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cardnum_day_since</th>\n",
       "      <th>Cardnum_count_0</th>\n",
       "      <th>Cardnum_avg_0</th>\n",
       "      <th>Cardnum_max_0</th>\n",
       "      <th>Cardnum_med_0</th>\n",
       "      <th>Cardnum_total_0</th>\n",
       "      <th>Cardnum_actual/avg_0</th>\n",
       "      <th>Cardnum_actual/max_0</th>\n",
       "      <th>Cardnum_actual/med_0</th>\n",
       "      <th>Cardnum_actual/total_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Merchnum_count_0/avg_count_30</th>\n",
       "      <th>Merchnum_actual_0/avg_30</th>\n",
       "      <th>Merchnum_count_1/avg_count_7</th>\n",
       "      <th>Merchnum_actual_1/avg_7</th>\n",
       "      <th>Merchnum_count_1/avg_count_14</th>\n",
       "      <th>Merchnum_actual_1/avg_14</th>\n",
       "      <th>Merchnum_count_1/avg_count_30</th>\n",
       "      <th>Merchnum_actual_1/avg_30</th>\n",
       "      <th>weekday_risk</th>\n",
       "      <th>state_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "      <td>9.675300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.468777e-17</td>\n",
       "      <td>-2.350043e-18</td>\n",
       "      <td>-2.423481e-18</td>\n",
       "      <td>-3.010992e-18</td>\n",
       "      <td>-7.417322e-18</td>\n",
       "      <td>-6.756373e-18</td>\n",
       "      <td>-9.561736e-17</td>\n",
       "      <td>1.486402e-16</td>\n",
       "      <td>-2.691533e-17</td>\n",
       "      <td>6.268739e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.718469e-16</td>\n",
       "      <td>5.875107e-18</td>\n",
       "      <td>9.752677e-17</td>\n",
       "      <td>7.520136e-17</td>\n",
       "      <td>2.878802e-17</td>\n",
       "      <td>-1.645030e-17</td>\n",
       "      <td>-2.937553e-19</td>\n",
       "      <td>1.762532e-17</td>\n",
       "      <td>-2.632048e-16</td>\n",
       "      <td>-9.400171e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.148231e-01</td>\n",
       "      <td>-2.454078e-01</td>\n",
       "      <td>-3.860027e-02</td>\n",
       "      <td>-3.136488e-02</td>\n",
       "      <td>-3.841379e-02</td>\n",
       "      <td>-4.295330e-02</td>\n",
       "      <td>-2.252805e+00</td>\n",
       "      <td>-3.094904e+00</td>\n",
       "      <td>-1.427115e-01</td>\n",
       "      <td>-2.207244e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.006143e+00</td>\n",
       "      <td>-1.467511e-01</td>\n",
       "      <td>-1.853300e+00</td>\n",
       "      <td>-3.417222e-01</td>\n",
       "      <td>-1.403102e+00</td>\n",
       "      <td>-2.977406e-01</td>\n",
       "      <td>-1.105737e+00</td>\n",
       "      <td>-2.137672e-01</td>\n",
       "      <td>-7.756625e-01</td>\n",
       "      <td>-1.188224e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.148231e-01</td>\n",
       "      <td>-2.454078e-01</td>\n",
       "      <td>-3.500883e-02</td>\n",
       "      <td>-2.894357e-02</td>\n",
       "      <td>-3.494167e-02</td>\n",
       "      <td>-3.998919e-02</td>\n",
       "      <td>-4.621614e-03</td>\n",
       "      <td>4.409888e-01</td>\n",
       "      <td>-4.148800e-02</td>\n",
       "      <td>-7.793521e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.569465e-01</td>\n",
       "      <td>-1.260596e-01</td>\n",
       "      <td>-8.948995e-01</td>\n",
       "      <td>-3.098278e-01</td>\n",
       "      <td>-9.204107e-01</td>\n",
       "      <td>-2.692219e-01</td>\n",
       "      <td>-8.561634e-01</td>\n",
       "      <td>-1.925449e-01</td>\n",
       "      <td>-4.423785e-01</td>\n",
       "      <td>-8.690627e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.565855e-01</td>\n",
       "      <td>-2.454078e-01</td>\n",
       "      <td>-2.517831e-02</td>\n",
       "      <td>-2.175375e-02</td>\n",
       "      <td>-2.502390e-02</td>\n",
       "      <td>-3.208358e-02</td>\n",
       "      <td>-4.621614e-03</td>\n",
       "      <td>4.409888e-01</td>\n",
       "      <td>-4.148800e-02</td>\n",
       "      <td>6.485804e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.914377e-01</td>\n",
       "      <td>-1.217467e-01</td>\n",
       "      <td>-1.233670e-01</td>\n",
       "      <td>-3.021021e-01</td>\n",
       "      <td>-2.610736e-01</td>\n",
       "      <td>-2.614013e-01</td>\n",
       "      <td>-4.481170e-01</td>\n",
       "      <td>-1.867085e-01</td>\n",
       "      <td>-2.515032e-01</td>\n",
       "      <td>-3.183430e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-2.363501e-02</td>\n",
       "      <td>-7.850726e-02</td>\n",
       "      <td>-5.374037e-04</td>\n",
       "      <td>-3.171004e-03</td>\n",
       "      <td>-1.685965e-04</td>\n",
       "      <td>-9.080229e-03</td>\n",
       "      <td>-4.621614e-03</td>\n",
       "      <td>4.409888e-01</td>\n",
       "      <td>-4.148800e-02</td>\n",
       "      <td>6.485804e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.573035e+00</td>\n",
       "      <td>-8.465255e-02</td>\n",
       "      <td>1.033932e+00</td>\n",
       "      <td>-2.043561e-01</td>\n",
       "      <td>1.265812e+00</td>\n",
       "      <td>-1.782802e-01</td>\n",
       "      <td>1.529338e+00</td>\n",
       "      <td>-1.288748e-01</td>\n",
       "      <td>-1.566523e-01</td>\n",
       "      <td>7.584529e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.041777e+01</td>\n",
       "      <td>2.395518e+01</td>\n",
       "      <td>2.601998e+02</td>\n",
       "      <td>1.553154e+02</td>\n",
       "      <td>2.776275e+02</td>\n",
       "      <td>1.533207e+02</td>\n",
       "      <td>5.123640e+01</td>\n",
       "      <td>4.409888e-01</td>\n",
       "      <td>6.645761e+01</td>\n",
       "      <td>6.485804e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.573035e+00</td>\n",
       "      <td>3.152606e+01</td>\n",
       "      <td>1.033932e+00</td>\n",
       "      <td>1.094564e+01</td>\n",
       "      <td>1.265812e+00</td>\n",
       "      <td>1.663616e+01</td>\n",
       "      <td>1.529338e+00</td>\n",
       "      <td>2.667378e+01</td>\n",
       "      <td>3.195323e+00</td>\n",
       "      <td>8.319280e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cardnum_day_since  Cardnum_count_0  Cardnum_avg_0  Cardnum_max_0  \\\n",
       "count       9.675300e+04     9.675300e+04   9.675300e+04   9.675300e+04   \n",
       "mean       -1.468777e-17    -2.350043e-18  -2.423481e-18  -3.010992e-18   \n",
       "std         1.000005e+00     1.000005e+00   1.000005e+00   1.000005e+00   \n",
       "min        -3.148231e-01    -2.454078e-01  -3.860027e-02  -3.136488e-02   \n",
       "25%        -3.148231e-01    -2.454078e-01  -3.500883e-02  -2.894357e-02   \n",
       "50%        -2.565855e-01    -2.454078e-01  -2.517831e-02  -2.175375e-02   \n",
       "75%        -2.363501e-02    -7.850726e-02  -5.374037e-04  -3.171004e-03   \n",
       "max         2.041777e+01     2.395518e+01   2.601998e+02   1.553154e+02   \n",
       "\n",
       "       Cardnum_med_0  Cardnum_total_0  Cardnum_actual/avg_0  \\\n",
       "count   9.675300e+04     9.675300e+04          9.675300e+04   \n",
       "mean   -7.417322e-18    -6.756373e-18         -9.561736e-17   \n",
       "std     1.000005e+00     1.000005e+00          1.000005e+00   \n",
       "min    -3.841379e-02    -4.295330e-02         -2.252805e+00   \n",
       "25%    -3.494167e-02    -3.998919e-02         -4.621614e-03   \n",
       "50%    -2.502390e-02    -3.208358e-02         -4.621614e-03   \n",
       "75%    -1.685965e-04    -9.080229e-03         -4.621614e-03   \n",
       "max     2.776275e+02     1.533207e+02          5.123640e+01   \n",
       "\n",
       "       Cardnum_actual/max_0  Cardnum_actual/med_0  Cardnum_actual/total_0  \\\n",
       "count          9.675300e+04          9.675300e+04            9.675300e+04   \n",
       "mean           1.486402e-16         -2.691533e-17            6.268739e-16   \n",
       "std            1.000005e+00          1.000005e+00            1.000005e+00   \n",
       "min           -3.094904e+00         -1.427115e-01           -2.207244e+00   \n",
       "25%            4.409888e-01         -4.148800e-02           -7.793521e-01   \n",
       "50%            4.409888e-01         -4.148800e-02            6.485804e-01   \n",
       "75%            4.409888e-01         -4.148800e-02            6.485804e-01   \n",
       "max            4.409888e-01          6.645761e+01            6.485804e-01   \n",
       "\n",
       "       ...  Merchnum_count_0/avg_count_30  Merchnum_actual_0/avg_30  \\\n",
       "count  ...                   9.675300e+04              9.675300e+04   \n",
       "mean   ...                  -1.718469e-16              5.875107e-18   \n",
       "std    ...                   1.000005e+00              1.000005e+00   \n",
       "min    ...                  -1.006143e+00             -1.467511e-01   \n",
       "25%    ...                  -8.569465e-01             -1.260596e-01   \n",
       "50%    ...                  -4.914377e-01             -1.217467e-01   \n",
       "75%    ...                   1.573035e+00             -8.465255e-02   \n",
       "max    ...                   1.573035e+00              3.152606e+01   \n",
       "\n",
       "       Merchnum_count_1/avg_count_7  Merchnum_actual_1/avg_7  \\\n",
       "count                  9.675300e+04             9.675300e+04   \n",
       "mean                   9.752677e-17             7.520136e-17   \n",
       "std                    1.000005e+00             1.000005e+00   \n",
       "min                   -1.853300e+00            -3.417222e-01   \n",
       "25%                   -8.948995e-01            -3.098278e-01   \n",
       "50%                   -1.233670e-01            -3.021021e-01   \n",
       "75%                    1.033932e+00            -2.043561e-01   \n",
       "max                    1.033932e+00             1.094564e+01   \n",
       "\n",
       "       Merchnum_count_1/avg_count_14  Merchnum_actual_1/avg_14  \\\n",
       "count                   9.675300e+04              9.675300e+04   \n",
       "mean                    2.878802e-17             -1.645030e-17   \n",
       "std                     1.000005e+00              1.000005e+00   \n",
       "min                    -1.403102e+00             -2.977406e-01   \n",
       "25%                    -9.204107e-01             -2.692219e-01   \n",
       "50%                    -2.610736e-01             -2.614013e-01   \n",
       "75%                     1.265812e+00             -1.782802e-01   \n",
       "max                     1.265812e+00              1.663616e+01   \n",
       "\n",
       "       Merchnum_count_1/avg_count_30  Merchnum_actual_1/avg_30  weekday_risk  \\\n",
       "count                   9.675300e+04              9.675300e+04  9.675300e+04   \n",
       "mean                   -2.937553e-19              1.762532e-17 -2.632048e-16   \n",
       "std                     1.000005e+00              1.000005e+00  1.000005e+00   \n",
       "min                    -1.105737e+00             -2.137672e-01 -7.756625e-01   \n",
       "25%                    -8.561634e-01             -1.925449e-01 -4.423785e-01   \n",
       "50%                    -4.481170e-01             -1.867085e-01 -2.515032e-01   \n",
       "75%                     1.529338e+00             -1.288748e-01 -1.566523e-01   \n",
       "max                     1.529338e+00              2.667378e+01  3.195323e+00   \n",
       "\n",
       "         state_risk  \n",
       "count  9.675300e+04  \n",
       "mean  -9.400171e-18  \n",
       "std    1.000005e+00  \n",
       "min   -1.188224e+00  \n",
       "25%   -8.690627e-01  \n",
       "50%   -3.183430e-01  \n",
       "75%    7.584529e-01  \n",
       "max    8.319280e+00  \n",
       "\n",
       "[8 rows x 301 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check mean (close to 0) and standard deviation (close to 1)\n",
    "mydata_newV.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96753, 303)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get Date column for data separation\n",
    "mydata_newV['Date'] = Date\n",
    "\n",
    "## Get Fraud as label (response variable)\n",
    "mydata_newV['Fraud'] = Fraud\n",
    "mydata_newV.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate data into modeling and OOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80955, 303)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Only use the records from 1/15 through 10/31 for feature selection\n",
    "newdata = mydata_newV.loc[(mydata_newV['Date'] >= dt.datetime.strptime('2010-01-15', \"%Y-%m-%d\")) & (mydata_newV['Date'] <= dt.datetime.strptime('2010-10-31', \"%Y-%m-%d\"))]\n",
    "newdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the modeling data (trn, tst) for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80955, 302)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Drop Date\n",
    "newdata = newdata.drop(['Date'], axis = 1)\n",
    "newdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80955, 303)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add a random number for process validation checks (fraud label already in newdata)\n",
    "newdata['randNum'] = random.sample(range(80955), len(newdata))\n",
    "newdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    80087\n",
       "1      868\n",
       "Name: Fraud, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get label distribution\n",
    "newdata.Fraud.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cardnum_day_since                0\n",
       "Cardnum_count_0                  0\n",
       "Cardnum_avg_0                    0\n",
       "Cardnum_max_0                    0\n",
       "Cardnum_med_0                    0\n",
       "Cardnum_total_0                  0\n",
       "Cardnum_actual/avg_0             0\n",
       "Cardnum_actual/max_0             0\n",
       "Cardnum_actual/med_0             0\n",
       "Cardnum_actual/total_0           0\n",
       "Cardnum_count_1                  0\n",
       "Cardnum_avg_1                    0\n",
       "Cardnum_max_1                    0\n",
       "Cardnum_med_1                    0\n",
       "Cardnum_total_1                  0\n",
       "Cardnum_actual/avg_1             0\n",
       "Cardnum_actual/max_1             0\n",
       "Cardnum_actual/med_1             0\n",
       "Cardnum_actual/total_1           0\n",
       "Cardnum_count_3                  0\n",
       "Cardnum_avg_3                    0\n",
       "Cardnum_max_3                    0\n",
       "Cardnum_med_3                    0\n",
       "Cardnum_total_3                  0\n",
       "Cardnum_actual/avg_3             0\n",
       "Cardnum_actual/max_3             0\n",
       "Cardnum_actual/med_3             0\n",
       "Cardnum_actual/total_3           0\n",
       "Cardnum_count_7                  0\n",
       "Cardnum_avg_7                    0\n",
       "Cardnum_max_7                    0\n",
       "Cardnum_med_7                    0\n",
       "Cardnum_total_7                  0\n",
       "Cardnum_actual/avg_7             0\n",
       "Cardnum_actual/max_7             0\n",
       "Cardnum_actual/med_7             0\n",
       "Cardnum_actual/total_7           0\n",
       "Cardnum_count_14                 0\n",
       "Cardnum_avg_14                   0\n",
       "Cardnum_max_14                   0\n",
       "Cardnum_med_14                   0\n",
       "Cardnum_total_14                 0\n",
       "Cardnum_actual/avg_14            0\n",
       "Cardnum_actual/max_14            0\n",
       "Cardnum_actual/med_14            0\n",
       "Cardnum_actual/total_14          0\n",
       "Cardnum_count_30                 0\n",
       "Cardnum_avg_30                   0\n",
       "Cardnum_max_30                   0\n",
       "Cardnum_med_30                   0\n",
       "Cardnum_total_30                 0\n",
       "Cardnum_actual/avg_30            0\n",
       "Cardnum_actual/max_30            0\n",
       "Cardnum_actual/med_30            0\n",
       "Cardnum_actual/total_30          0\n",
       "Merchnum_day_since               0\n",
       "Merchnum_count_0                 0\n",
       "Merchnum_avg_0                   0\n",
       "Merchnum_max_0                   0\n",
       "Merchnum_med_0                   0\n",
       "Merchnum_total_0                 0\n",
       "Merchnum_actual/avg_0            0\n",
       "Merchnum_actual/max_0            0\n",
       "Merchnum_actual/med_0            0\n",
       "Merchnum_actual/total_0          0\n",
       "Merchnum_count_1                 0\n",
       "Merchnum_avg_1                   0\n",
       "Merchnum_max_1                   0\n",
       "Merchnum_med_1                   0\n",
       "Merchnum_total_1                 0\n",
       "Merchnum_actual/avg_1            0\n",
       "Merchnum_actual/max_1            0\n",
       "Merchnum_actual/med_1            0\n",
       "Merchnum_actual/total_1          0\n",
       "Merchnum_count_3                 0\n",
       "Merchnum_avg_3                   0\n",
       "Merchnum_max_3                   0\n",
       "Merchnum_med_3                   0\n",
       "Merchnum_total_3                 0\n",
       "Merchnum_actual/avg_3            0\n",
       "Merchnum_actual/max_3            0\n",
       "Merchnum_actual/med_3            0\n",
       "Merchnum_actual/total_3          0\n",
       "Merchnum_count_7                 0\n",
       "Merchnum_avg_7                   0\n",
       "Merchnum_max_7                   0\n",
       "Merchnum_med_7                   0\n",
       "Merchnum_total_7                 0\n",
       "Merchnum_actual/avg_7            0\n",
       "Merchnum_actual/max_7            0\n",
       "Merchnum_actual/med_7            0\n",
       "Merchnum_actual/total_7          0\n",
       "Merchnum_count_14                0\n",
       "Merchnum_avg_14                  0\n",
       "Merchnum_max_14                  0\n",
       "Merchnum_med_14                  0\n",
       "Merchnum_total_14                0\n",
       "Merchnum_actual/avg_14           0\n",
       "Merchnum_actual/max_14           0\n",
       "Merchnum_actual/med_14           0\n",
       "Merchnum_actual/total_14         0\n",
       "Merchnum_count_30                0\n",
       "Merchnum_avg_30                  0\n",
       "Merchnum_max_30                  0\n",
       "Merchnum_med_30                  0\n",
       "Merchnum_total_30                0\n",
       "Merchnum_actual/avg_30           0\n",
       "Merchnum_actual/max_30           0\n",
       "Merchnum_actual/med_30           0\n",
       "Merchnum_actual/total_30         0\n",
       "card_merch_day_since             0\n",
       "card_merch_count_0               0\n",
       "card_merch_avg_0                 0\n",
       "card_merch_max_0                 0\n",
       "card_merch_med_0                 0\n",
       "card_merch_total_0               0\n",
       "card_merch_actual/avg_0          0\n",
       "card_merch_actual/max_0          0\n",
       "card_merch_actual/med_0          0\n",
       "card_merch_actual/total_0        0\n",
       "card_merch_count_1               0\n",
       "card_merch_avg_1                 0\n",
       "card_merch_max_1                 0\n",
       "card_merch_med_1                 0\n",
       "card_merch_total_1               0\n",
       "card_merch_actual/avg_1          0\n",
       "card_merch_actual/max_1          0\n",
       "card_merch_actual/med_1          0\n",
       "card_merch_actual/total_1        0\n",
       "card_merch_count_3               0\n",
       "card_merch_avg_3                 0\n",
       "card_merch_max_3                 0\n",
       "card_merch_med_3                 0\n",
       "card_merch_total_3               0\n",
       "card_merch_actual/avg_3          0\n",
       "card_merch_actual/max_3          0\n",
       "card_merch_actual/med_3          0\n",
       "card_merch_actual/total_3        0\n",
       "card_merch_count_7               0\n",
       "card_merch_avg_7                 0\n",
       "card_merch_max_7                 0\n",
       "card_merch_med_7                 0\n",
       "card_merch_total_7               0\n",
       "card_merch_actual/avg_7          0\n",
       "card_merch_actual/max_7          0\n",
       "card_merch_actual/med_7          0\n",
       "card_merch_actual/total_7        0\n",
       "card_merch_count_14              0\n",
       "card_merch_avg_14                0\n",
       "card_merch_max_14                0\n",
       "card_merch_med_14                0\n",
       "card_merch_total_14              0\n",
       "card_merch_actual/avg_14         0\n",
       "card_merch_actual/max_14         0\n",
       "card_merch_actual/med_14         0\n",
       "card_merch_actual/total_14       0\n",
       "card_merch_count_30              0\n",
       "card_merch_avg_30                0\n",
       "card_merch_max_30                0\n",
       "card_merch_med_30                0\n",
       "card_merch_total_30              0\n",
       "card_merch_actual/avg_30         0\n",
       "card_merch_actual/max_30         0\n",
       "card_merch_actual/med_30         0\n",
       "card_merch_actual/total_30       0\n",
       "card_zip_day_since               0\n",
       "card_zip_count_0                 0\n",
       "card_zip_avg_0                   0\n",
       "card_zip_max_0                   0\n",
       "card_zip_med_0                   0\n",
       "card_zip_total_0                 0\n",
       "card_zip_actual/avg_0            0\n",
       "card_zip_actual/max_0            0\n",
       "card_zip_actual/med_0            0\n",
       "card_zip_actual/total_0          0\n",
       "card_zip_count_1                 0\n",
       "card_zip_avg_1                   0\n",
       "card_zip_max_1                   0\n",
       "card_zip_med_1                   0\n",
       "card_zip_total_1                 0\n",
       "card_zip_actual/avg_1            0\n",
       "card_zip_actual/max_1            0\n",
       "card_zip_actual/med_1            0\n",
       "card_zip_actual/total_1          0\n",
       "card_zip_count_3                 0\n",
       "card_zip_avg_3                   0\n",
       "card_zip_max_3                   0\n",
       "card_zip_med_3                   0\n",
       "card_zip_total_3                 0\n",
       "card_zip_actual/avg_3            0\n",
       "card_zip_actual/max_3            0\n",
       "card_zip_actual/med_3            0\n",
       "card_zip_actual/total_3          0\n",
       "card_zip_count_7                 0\n",
       "card_zip_avg_7                   0\n",
       "card_zip_max_7                   0\n",
       "card_zip_med_7                   0\n",
       "card_zip_total_7                 0\n",
       "card_zip_actual/avg_7            0\n",
       "card_zip_actual/max_7            0\n",
       "card_zip_actual/med_7            0\n",
       "card_zip_actual/total_7          0\n",
       "card_zip_count_14                0\n",
       "card_zip_avg_14                  0\n",
       "card_zip_max_14                  0\n",
       "card_zip_med_14                  0\n",
       "card_zip_total_14                0\n",
       "card_zip_actual/avg_14           0\n",
       "card_zip_actual/max_14           0\n",
       "card_zip_actual/med_14           0\n",
       "card_zip_actual/total_14         0\n",
       "card_zip_count_30                0\n",
       "card_zip_avg_30                  0\n",
       "card_zip_max_30                  0\n",
       "card_zip_med_30                  0\n",
       "card_zip_total_30                0\n",
       "card_zip_actual/avg_30           0\n",
       "card_zip_actual/max_30           0\n",
       "card_zip_actual/med_30           0\n",
       "card_zip_actual/total_30         0\n",
       "card_state_day_since             0\n",
       "card_state_count_0               0\n",
       "card_state_avg_0                 0\n",
       "card_state_max_0                 0\n",
       "card_state_med_0                 0\n",
       "card_state_total_0               0\n",
       "card_state_actual/avg_0          0\n",
       "card_state_actual/max_0          0\n",
       "card_state_actual/med_0          0\n",
       "card_state_actual/total_0        0\n",
       "card_state_count_1               0\n",
       "card_state_avg_1                 0\n",
       "card_state_max_1                 0\n",
       "card_state_med_1                 0\n",
       "card_state_total_1               0\n",
       "card_state_actual/avg_1          0\n",
       "card_state_actual/max_1          0\n",
       "card_state_actual/med_1          0\n",
       "card_state_actual/total_1        0\n",
       "card_state_count_3               0\n",
       "card_state_avg_3                 0\n",
       "card_state_max_3                 0\n",
       "card_state_med_3                 0\n",
       "card_state_total_3               0\n",
       "card_state_actual/avg_3          0\n",
       "card_state_actual/max_3          0\n",
       "card_state_actual/med_3          0\n",
       "card_state_actual/total_3        0\n",
       "card_state_count_7               0\n",
       "card_state_avg_7                 0\n",
       "card_state_max_7                 0\n",
       "card_state_med_7                 0\n",
       "card_state_total_7               0\n",
       "card_state_actual/avg_7          0\n",
       "card_state_actual/max_7          0\n",
       "card_state_actual/med_7          0\n",
       "card_state_actual/total_7        0\n",
       "card_state_count_14              0\n",
       "card_state_avg_14                0\n",
       "card_state_max_14                0\n",
       "card_state_med_14                0\n",
       "card_state_total_14              0\n",
       "card_state_actual/avg_14         0\n",
       "card_state_actual/max_14         0\n",
       "card_state_actual/med_14         0\n",
       "card_state_actual/total_14       0\n",
       "card_state_count_30              0\n",
       "card_state_avg_30                0\n",
       "card_state_max_30                0\n",
       "card_state_med_30                0\n",
       "card_state_total_30              0\n",
       "card_state_actual/avg_30         0\n",
       "card_state_actual/max_30         0\n",
       "card_state_actual/med_30         0\n",
       "card_state_actual/total_30       0\n",
       "Cardnum_count_0/avg_count_7      0\n",
       "Cardnum_actual_0/avg_7           0\n",
       "Cardnum_count_0/avg_count_14     0\n",
       "Cardnum_actual_0/avg_14          0\n",
       "Cardnum_count_0/avg_count_30     0\n",
       "Cardnum_actual_0/avg_30          0\n",
       "Cardnum_count_1/avg_count_7      0\n",
       "Cardnum_actual_1/avg_7           0\n",
       "Cardnum_count_1/avg_count_14     0\n",
       "Cardnum_actual_1/avg_14          0\n",
       "Cardnum_count_1/avg_count_30     0\n",
       "Cardnum_actual_1/avg_30          0\n",
       "Merchnum_count_0/avg_count_7     0\n",
       "Merchnum_actual_0/avg_7          0\n",
       "Merchnum_count_0/avg_count_14    0\n",
       "Merchnum_actual_0/avg_14         0\n",
       "Merchnum_count_0/avg_count_30    0\n",
       "Merchnum_actual_0/avg_30         0\n",
       "Merchnum_count_1/avg_count_7     0\n",
       "Merchnum_actual_1/avg_7          0\n",
       "Merchnum_count_1/avg_count_14    0\n",
       "Merchnum_actual_1/avg_14         0\n",
       "Merchnum_count_1/avg_count_30    0\n",
       "Merchnum_actual_1/avg_30         0\n",
       "weekday_risk                     0\n",
       "state_risk                       0\n",
       "Fraud                            0\n",
       "randNum                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check missing value\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "newdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select 30 best variables with filter and wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run a filter: Sort by the average of FDR @ 3% rank and univariate KS rank, keep about 80 variables\n",
    "## Get goods and bads\n",
    "goods = newdata.loc[(newdata.Fraud == 0)]\n",
    "bads = newdata.loc[(newdata.Fraud == 1)]\n",
    "\n",
    "## Get KS measurement\n",
    "KSFDR = pd.DataFrame({'Variable':newdata.columns})\n",
    "ks = []\n",
    "for column in newdata:\n",
    "    ks.append(stats.ks_2samp(goods[column], bads[column])[0])\n",
    "KSFDR['ks'] = ks\n",
    "\n",
    "## Get FDR @ 3% (upper and lower)\n",
    "topRows = int(round(len(newdata) * 0.03))\n",
    "j = 0\n",
    "for column in newdata:\n",
    "    temp = newdata.sort_values(column, ascending = False)\n",
    "    temp1 = temp.head(topRows)\n",
    "    temp2 = temp.tail(topRows)\n",
    "    needed1 = temp1.loc[:, 'Fraud']\n",
    "    needed2 = temp2.loc[:, 'Fraud']\n",
    "    FDR1 = sum(needed1) / bads.shape[0]\n",
    "    FDR2 = sum(needed2) / bads.shape[0]\n",
    "    FDRate = np.maximum(FDR1, FDR2)\n",
    "    KSFDR.loc[j, 'FDR'] = FDRate\n",
    "    j = j + 1\n",
    "\n",
    "## Rank of ks\n",
    "KSFDR['rank_ks'] = KSFDR['ks'].rank(ascending = True)\n",
    "\n",
    "## Rank of FDR @ 3%\n",
    "KSFDR['rank_FDR'] = KSFDR['FDR'].rank(ascending = True)\n",
    "\n",
    "## Average rank of ks and FDR @ 3%\n",
    "KSFDR['average_rank'] = (KSFDR['rank_ks'] + KSFDR['rank_FDR']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>ks</th>\n",
       "      <th>FDR</th>\n",
       "      <th>rank_ks</th>\n",
       "      <th>rank_FDR</th>\n",
       "      <th>average_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Fraud</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>303.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>303.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>card_zip_total_7</td>\n",
       "      <td>0.686097</td>\n",
       "      <td>0.639401</td>\n",
       "      <td>302.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>301.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>card_zip_total_3</td>\n",
       "      <td>0.679002</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>300.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>301.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>card_merch_total_7</td>\n",
       "      <td>0.681855</td>\n",
       "      <td>0.633641</td>\n",
       "      <td>301.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>card_merch_total_14</td>\n",
       "      <td>0.676265</td>\n",
       "      <td>0.631336</td>\n",
       "      <td>299.0</td>\n",
       "      <td>298.5</td>\n",
       "      <td>298.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>card_merch_total_3</td>\n",
       "      <td>0.675786</td>\n",
       "      <td>0.631336</td>\n",
       "      <td>298.0</td>\n",
       "      <td>298.5</td>\n",
       "      <td>298.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>card_state_total_3</td>\n",
       "      <td>0.674461</td>\n",
       "      <td>0.630184</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>card_zip_total_14</td>\n",
       "      <td>0.673388</td>\n",
       "      <td>0.627880</td>\n",
       "      <td>296.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>296.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>card_state_total_7</td>\n",
       "      <td>0.669424</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>295.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>293.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>card_zip_total_1</td>\n",
       "      <td>0.660988</td>\n",
       "      <td>0.597926</td>\n",
       "      <td>293.0</td>\n",
       "      <td>293.5</td>\n",
       "      <td>293.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>card_state_total_1</td>\n",
       "      <td>0.659490</td>\n",
       "      <td>0.601382</td>\n",
       "      <td>291.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>293.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>card_merch_total_1</td>\n",
       "      <td>0.658840</td>\n",
       "      <td>0.597926</td>\n",
       "      <td>290.0</td>\n",
       "      <td>293.5</td>\n",
       "      <td>291.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>card_merch_total_30</td>\n",
       "      <td>0.659890</td>\n",
       "      <td>0.559908</td>\n",
       "      <td>292.0</td>\n",
       "      <td>289.5</td>\n",
       "      <td>290.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>card_state_total_14</td>\n",
       "      <td>0.668924</td>\n",
       "      <td>0.523041</td>\n",
       "      <td>294.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>288.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>card_zip_total_30</td>\n",
       "      <td>0.656569</td>\n",
       "      <td>0.544931</td>\n",
       "      <td>288.0</td>\n",
       "      <td>284.5</td>\n",
       "      <td>286.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>card_zip_max_14</td>\n",
       "      <td>0.656887</td>\n",
       "      <td>0.476959</td>\n",
       "      <td>289.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>282.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>card_state_total_0</td>\n",
       "      <td>0.610943</td>\n",
       "      <td>0.562212</td>\n",
       "      <td>271.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>281.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>card_merch_total_0</td>\n",
       "      <td>0.611628</td>\n",
       "      <td>0.559908</td>\n",
       "      <td>272.0</td>\n",
       "      <td>289.5</td>\n",
       "      <td>280.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>card_zip_total_0</td>\n",
       "      <td>0.612584</td>\n",
       "      <td>0.557604</td>\n",
       "      <td>273.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>280.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>card_zip_max_30</td>\n",
       "      <td>0.650336</td>\n",
       "      <td>0.480415</td>\n",
       "      <td>283.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>280.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>card_state_max_7</td>\n",
       "      <td>0.646827</td>\n",
       "      <td>0.489631</td>\n",
       "      <td>280.0</td>\n",
       "      <td>279.5</td>\n",
       "      <td>279.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>card_merch_max_14</td>\n",
       "      <td>0.654928</td>\n",
       "      <td>0.474654</td>\n",
       "      <td>286.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>278.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cardnum_total_3</td>\n",
       "      <td>0.602060</td>\n",
       "      <td>0.552995</td>\n",
       "      <td>268.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>277.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>card_state_max_14</td>\n",
       "      <td>0.629882</td>\n",
       "      <td>0.488479</td>\n",
       "      <td>277.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>277.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>card_zip_max_3</td>\n",
       "      <td>0.648802</td>\n",
       "      <td>0.475806</td>\n",
       "      <td>282.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>277.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>card_zip_max_7</td>\n",
       "      <td>0.656497</td>\n",
       "      <td>0.466590</td>\n",
       "      <td>287.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>277.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>card_merch_max_30</td>\n",
       "      <td>0.650896</td>\n",
       "      <td>0.473502</td>\n",
       "      <td>284.0</td>\n",
       "      <td>269.5</td>\n",
       "      <td>276.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>card_merch_max_3</td>\n",
       "      <td>0.645214</td>\n",
       "      <td>0.475806</td>\n",
       "      <td>279.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>276.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>card_merch_max_7</td>\n",
       "      <td>0.650989</td>\n",
       "      <td>0.465438</td>\n",
       "      <td>285.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>275.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>card_state_max_3</td>\n",
       "      <td>0.648072</td>\n",
       "      <td>0.473502</td>\n",
       "      <td>281.0</td>\n",
       "      <td>269.5</td>\n",
       "      <td>275.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Cardnum_total_7</td>\n",
       "      <td>0.599896</td>\n",
       "      <td>0.518433</td>\n",
       "      <td>265.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>273.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>card_state_max_30</td>\n",
       "      <td>0.597115</td>\n",
       "      <td>0.478111</td>\n",
       "      <td>264.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>270.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>card_state_total_30</td>\n",
       "      <td>0.635167</td>\n",
       "      <td>0.444700</td>\n",
       "      <td>278.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>270.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>card_merch_max_1</td>\n",
       "      <td>0.621067</td>\n",
       "      <td>0.457373</td>\n",
       "      <td>274.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>269.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>card_zip_max_1</td>\n",
       "      <td>0.624140</td>\n",
       "      <td>0.455069</td>\n",
       "      <td>275.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>269.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>card_state_max_1</td>\n",
       "      <td>0.625878</td>\n",
       "      <td>0.442396</td>\n",
       "      <td>276.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>268.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cardnum_total_1</td>\n",
       "      <td>0.576927</td>\n",
       "      <td>0.544931</td>\n",
       "      <td>247.0</td>\n",
       "      <td>284.5</td>\n",
       "      <td>265.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cardnum_total_0</td>\n",
       "      <td>0.570956</td>\n",
       "      <td>0.551843</td>\n",
       "      <td>239.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>262.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>card_state_max_0</td>\n",
       "      <td>0.602610</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>269.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>262.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>card_zip_max_0</td>\n",
       "      <td>0.604239</td>\n",
       "      <td>0.415899</td>\n",
       "      <td>270.0</td>\n",
       "      <td>254.5</td>\n",
       "      <td>262.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>card_merch_max_0</td>\n",
       "      <td>0.601008</td>\n",
       "      <td>0.415899</td>\n",
       "      <td>267.0</td>\n",
       "      <td>254.5</td>\n",
       "      <td>260.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Merchnum_total_0</td>\n",
       "      <td>0.571342</td>\n",
       "      <td>0.514977</td>\n",
       "      <td>240.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>260.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Merchnum_max_0</td>\n",
       "      <td>0.591500</td>\n",
       "      <td>0.421659</td>\n",
       "      <td>261.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>259.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cardnum_max_0</td>\n",
       "      <td>0.585228</td>\n",
       "      <td>0.425115</td>\n",
       "      <td>253.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>255.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Merchnum_total_1</td>\n",
       "      <td>0.583667</td>\n",
       "      <td>0.414747</td>\n",
       "      <td>252.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>252.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Cardnum_max_7</td>\n",
       "      <td>0.558783</td>\n",
       "      <td>0.489631</td>\n",
       "      <td>218.0</td>\n",
       "      <td>279.5</td>\n",
       "      <td>248.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cardnum_max_1</td>\n",
       "      <td>0.570372</td>\n",
       "      <td>0.430876</td>\n",
       "      <td>237.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>248.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cardnum_max_3</td>\n",
       "      <td>0.561162</td>\n",
       "      <td>0.456221</td>\n",
       "      <td>224.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>244.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cardnum_avg_1</td>\n",
       "      <td>0.571908</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>241.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>242.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Cardnum_total_14</td>\n",
       "      <td>0.547260</td>\n",
       "      <td>0.475806</td>\n",
       "      <td>208.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>240.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>card_state_avg_7</td>\n",
       "      <td>0.587236</td>\n",
       "      <td>0.308756</td>\n",
       "      <td>254.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>240.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Merchnum_total_3</td>\n",
       "      <td>0.568238</td>\n",
       "      <td>0.381336</td>\n",
       "      <td>234.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>240.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>card_state_avg_3</td>\n",
       "      <td>0.589001</td>\n",
       "      <td>0.305300</td>\n",
       "      <td>256.0</td>\n",
       "      <td>223.5</td>\n",
       "      <td>239.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cardnum_avg_3</td>\n",
       "      <td>0.570028</td>\n",
       "      <td>0.359447</td>\n",
       "      <td>235.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>239.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>card_merch_avg_0</td>\n",
       "      <td>0.573744</td>\n",
       "      <td>0.319124</td>\n",
       "      <td>246.0</td>\n",
       "      <td>231.5</td>\n",
       "      <td>238.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>card_zip_avg_30</td>\n",
       "      <td>0.600269</td>\n",
       "      <td>0.293779</td>\n",
       "      <td>266.0</td>\n",
       "      <td>210.5</td>\n",
       "      <td>238.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>card_state_avg_0</td>\n",
       "      <td>0.572745</td>\n",
       "      <td>0.323733</td>\n",
       "      <td>242.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>238.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>card_zip_avg_0</td>\n",
       "      <td>0.573452</td>\n",
       "      <td>0.319124</td>\n",
       "      <td>244.0</td>\n",
       "      <td>231.5</td>\n",
       "      <td>237.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Merchnum_max_1</td>\n",
       "      <td>0.557938</td>\n",
       "      <td>0.426267</td>\n",
       "      <td>216.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>237.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>card_state_avg_1</td>\n",
       "      <td>0.582663</td>\n",
       "      <td>0.305300</td>\n",
       "      <td>251.0</td>\n",
       "      <td>223.5</td>\n",
       "      <td>237.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Merchnum_avg_0</td>\n",
       "      <td>0.579426</td>\n",
       "      <td>0.307604</td>\n",
       "      <td>249.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>237.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cardnum_avg_0</td>\n",
       "      <td>0.570178</td>\n",
       "      <td>0.328341</td>\n",
       "      <td>236.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>237.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>card_zip_avg_3</td>\n",
       "      <td>0.589605</td>\n",
       "      <td>0.298387</td>\n",
       "      <td>258.0</td>\n",
       "      <td>215.5</td>\n",
       "      <td>236.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>card_merch_avg_3</td>\n",
       "      <td>0.590142</td>\n",
       "      <td>0.297235</td>\n",
       "      <td>259.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>236.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>card_state_avg_14</td>\n",
       "      <td>0.572961</td>\n",
       "      <td>0.315668</td>\n",
       "      <td>243.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>236.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>card_zip_avg_7</td>\n",
       "      <td>0.590674</td>\n",
       "      <td>0.294931</td>\n",
       "      <td>260.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>236.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>card_zip_avg_1</td>\n",
       "      <td>0.579509</td>\n",
       "      <td>0.301843</td>\n",
       "      <td>250.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>235.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>card_merch_avg_30</td>\n",
       "      <td>0.593927</td>\n",
       "      <td>0.292627</td>\n",
       "      <td>263.0</td>\n",
       "      <td>207.5</td>\n",
       "      <td>235.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>card_state_avg_30</td>\n",
       "      <td>0.566645</td>\n",
       "      <td>0.328341</td>\n",
       "      <td>232.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>235.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Cardnum_max_14</td>\n",
       "      <td>0.525422</td>\n",
       "      <td>0.470046</td>\n",
       "      <td>200.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>234.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>card_zip_avg_14</td>\n",
       "      <td>0.592974</td>\n",
       "      <td>0.291475</td>\n",
       "      <td>262.0</td>\n",
       "      <td>204.5</td>\n",
       "      <td>233.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>card_merch_avg_1</td>\n",
       "      <td>0.576942</td>\n",
       "      <td>0.299539</td>\n",
       "      <td>248.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>233.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>card_merch_avg_7</td>\n",
       "      <td>0.588388</td>\n",
       "      <td>0.293779</td>\n",
       "      <td>255.0</td>\n",
       "      <td>210.5</td>\n",
       "      <td>232.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>card_merch_avg_14</td>\n",
       "      <td>0.589365</td>\n",
       "      <td>0.292627</td>\n",
       "      <td>257.0</td>\n",
       "      <td>207.5</td>\n",
       "      <td>232.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cardnum_avg_7</td>\n",
       "      <td>0.547325</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>209.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>229.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cardnum_med_1</td>\n",
       "      <td>0.557223</td>\n",
       "      <td>0.331797</td>\n",
       "      <td>215.0</td>\n",
       "      <td>240.5</td>\n",
       "      <td>227.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Cardnum_avg_14</td>\n",
       "      <td>0.531202</td>\n",
       "      <td>0.404378</td>\n",
       "      <td>201.0</td>\n",
       "      <td>251.5</td>\n",
       "      <td>226.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Merchnum_max_3</td>\n",
       "      <td>0.531419</td>\n",
       "      <td>0.364055</td>\n",
       "      <td>202.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>223.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Cardnum_avg_30</td>\n",
       "      <td>0.508837</td>\n",
       "      <td>0.383641</td>\n",
       "      <td>199.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>223.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>card_state_med_0</td>\n",
       "      <td>0.561188</td>\n",
       "      <td>0.302995</td>\n",
       "      <td>225.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>223.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>card_merch_med_0</td>\n",
       "      <td>0.563690</td>\n",
       "      <td>0.299539</td>\n",
       "      <td>229.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>223.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>card_zip_med_0</td>\n",
       "      <td>0.562688</td>\n",
       "      <td>0.299539</td>\n",
       "      <td>228.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>223.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Cardnum_total_30</td>\n",
       "      <td>0.486549</td>\n",
       "      <td>0.404378</td>\n",
       "      <td>193.0</td>\n",
       "      <td>251.5</td>\n",
       "      <td>222.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Merchnum_max_7</td>\n",
       "      <td>0.537164</td>\n",
       "      <td>0.331797</td>\n",
       "      <td>204.0</td>\n",
       "      <td>240.5</td>\n",
       "      <td>222.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cardnum_med_0</td>\n",
       "      <td>0.557940</td>\n",
       "      <td>0.308756</td>\n",
       "      <td>217.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>222.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Cardnum_actual_1/avg_30</td>\n",
       "      <td>0.489778</td>\n",
       "      <td>0.388249</td>\n",
       "      <td>195.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>222.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Cardnum_max_30</td>\n",
       "      <td>0.503413</td>\n",
       "      <td>0.380184</td>\n",
       "      <td>197.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>221.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cardnum_med_3</td>\n",
       "      <td>0.544923</td>\n",
       "      <td>0.323733</td>\n",
       "      <td>207.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>220.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Merchnum_avg_1</td>\n",
       "      <td>0.573488</td>\n",
       "      <td>0.279954</td>\n",
       "      <td>245.0</td>\n",
       "      <td>192.5</td>\n",
       "      <td>218.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>card_merch_med_1</td>\n",
       "      <td>0.564179</td>\n",
       "      <td>0.291475</td>\n",
       "      <td>230.0</td>\n",
       "      <td>204.5</td>\n",
       "      <td>217.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>card_zip_med_1</td>\n",
       "      <td>0.561305</td>\n",
       "      <td>0.292627</td>\n",
       "      <td>226.0</td>\n",
       "      <td>207.5</td>\n",
       "      <td>216.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>card_zip_med_3</td>\n",
       "      <td>0.566784</td>\n",
       "      <td>0.288018</td>\n",
       "      <td>233.0</td>\n",
       "      <td>200.5</td>\n",
       "      <td>216.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>card_state_med_1</td>\n",
       "      <td>0.560207</td>\n",
       "      <td>0.296083</td>\n",
       "      <td>219.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>216.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Merchnum_avg_7</td>\n",
       "      <td>0.561567</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>227.0</td>\n",
       "      <td>202.5</td>\n",
       "      <td>214.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Cardnum_med_14</td>\n",
       "      <td>0.483187</td>\n",
       "      <td>0.328341</td>\n",
       "      <td>191.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>214.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>card_merch_med_3</td>\n",
       "      <td>0.565764</td>\n",
       "      <td>0.286866</td>\n",
       "      <td>231.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>214.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>card_merch_med_30</td>\n",
       "      <td>0.570772</td>\n",
       "      <td>0.277650</td>\n",
       "      <td>238.0</td>\n",
       "      <td>189.5</td>\n",
       "      <td>213.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Merchnum_total_7</td>\n",
       "      <td>0.504191</td>\n",
       "      <td>0.312212</td>\n",
       "      <td>198.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>213.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Cardnum_actual_1/avg_14</td>\n",
       "      <td>0.451912</td>\n",
       "      <td>0.347926</td>\n",
       "      <td>185.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>213.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>card_state_med_30</td>\n",
       "      <td>0.550301</td>\n",
       "      <td>0.298387</td>\n",
       "      <td>210.0</td>\n",
       "      <td>215.5</td>\n",
       "      <td>212.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Cardnum_actual_0/avg_30</td>\n",
       "      <td>0.457537</td>\n",
       "      <td>0.323733</td>\n",
       "      <td>188.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>211.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Cardnum_actual_1/avg_7</td>\n",
       "      <td>0.446039</td>\n",
       "      <td>0.324885</td>\n",
       "      <td>184.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>210.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Cardnum_med_7</td>\n",
       "      <td>0.483455</td>\n",
       "      <td>0.308756</td>\n",
       "      <td>192.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>209.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>card_state_med_3</td>\n",
       "      <td>0.560343</td>\n",
       "      <td>0.286866</td>\n",
       "      <td>220.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>209.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>card_state_med_7</td>\n",
       "      <td>0.551772</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>212.0</td>\n",
       "      <td>202.5</td>\n",
       "      <td>207.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>card_merch_med_14</td>\n",
       "      <td>0.561003</td>\n",
       "      <td>0.278802</td>\n",
       "      <td>223.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>207.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>card_state_med_14</td>\n",
       "      <td>0.537007</td>\n",
       "      <td>0.292627</td>\n",
       "      <td>203.0</td>\n",
       "      <td>207.5</td>\n",
       "      <td>205.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>card_zip_med_30</td>\n",
       "      <td>0.560686</td>\n",
       "      <td>0.276498</td>\n",
       "      <td>222.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>205.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>card_zip_med_7</td>\n",
       "      <td>0.555145</td>\n",
       "      <td>0.281106</td>\n",
       "      <td>213.0</td>\n",
       "      <td>194.5</td>\n",
       "      <td>203.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Cardnum_med_30</td>\n",
       "      <td>0.454153</td>\n",
       "      <td>0.300691</td>\n",
       "      <td>187.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>203.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Merchnum_avg_3</td>\n",
       "      <td>0.560654</td>\n",
       "      <td>0.268433</td>\n",
       "      <td>221.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>203.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>card_merch_med_7</td>\n",
       "      <td>0.555193</td>\n",
       "      <td>0.279954</td>\n",
       "      <td>214.0</td>\n",
       "      <td>192.5</td>\n",
       "      <td>203.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Merchnum_avg_14</td>\n",
       "      <td>0.537611</td>\n",
       "      <td>0.288018</td>\n",
       "      <td>205.0</td>\n",
       "      <td>200.5</td>\n",
       "      <td>202.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Merchnum_med_0</td>\n",
       "      <td>0.540992</td>\n",
       "      <td>0.286866</td>\n",
       "      <td>206.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>202.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>card_zip_med_14</td>\n",
       "      <td>0.551124</td>\n",
       "      <td>0.277650</td>\n",
       "      <td>211.0</td>\n",
       "      <td>189.5</td>\n",
       "      <td>200.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Merchnum_med_1</td>\n",
       "      <td>0.501890</td>\n",
       "      <td>0.281106</td>\n",
       "      <td>196.0</td>\n",
       "      <td>194.5</td>\n",
       "      <td>195.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Merchnum_med_3</td>\n",
       "      <td>0.488075</td>\n",
       "      <td>0.269585</td>\n",
       "      <td>194.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>190.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Cardnum_actual_0/avg_14</td>\n",
       "      <td>0.426766</td>\n",
       "      <td>0.284562</td>\n",
       "      <td>181.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>188.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Merchnum_max_14</td>\n",
       "      <td>0.479876</td>\n",
       "      <td>0.252304</td>\n",
       "      <td>189.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>186.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Merchnum_avg_30</td>\n",
       "      <td>0.482283</td>\n",
       "      <td>0.211982</td>\n",
       "      <td>190.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>184.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Merchnum_med_7</td>\n",
       "      <td>0.445273</td>\n",
       "      <td>0.251152</td>\n",
       "      <td>183.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>182.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Merchnum_total_14</td>\n",
       "      <td>0.452049</td>\n",
       "      <td>0.207373</td>\n",
       "      <td>186.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>182.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Cardnum_actual_0/avg_7</td>\n",
       "      <td>0.411142</td>\n",
       "      <td>0.262673</td>\n",
       "      <td>177.0</td>\n",
       "      <td>184.5</td>\n",
       "      <td>180.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Merchnum_med_14</td>\n",
       "      <td>0.419433</td>\n",
       "      <td>0.228111</td>\n",
       "      <td>180.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>180.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cardnum_count_1</td>\n",
       "      <td>0.380504</td>\n",
       "      <td>0.262673</td>\n",
       "      <td>174.0</td>\n",
       "      <td>184.5</td>\n",
       "      <td>179.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Merchnum_med_30</td>\n",
       "      <td>0.414814</td>\n",
       "      <td>0.194700</td>\n",
       "      <td>178.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>176.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cardnum_count_3</td>\n",
       "      <td>0.406860</td>\n",
       "      <td>0.197005</td>\n",
       "      <td>176.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>176.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Merchnum_actual/med_30</td>\n",
       "      <td>0.348455</td>\n",
       "      <td>0.220046</td>\n",
       "      <td>165.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>172.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>card_state_count_1</td>\n",
       "      <td>0.357649</td>\n",
       "      <td>0.184332</td>\n",
       "      <td>168.5</td>\n",
       "      <td>172.5</td>\n",
       "      <td>170.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>card_state_count_3</td>\n",
       "      <td>0.358861</td>\n",
       "      <td>0.141705</td>\n",
       "      <td>172.0</td>\n",
       "      <td>162.5</td>\n",
       "      <td>167.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Merchnum_actual/avg_30</td>\n",
       "      <td>0.342823</td>\n",
       "      <td>0.170507</td>\n",
       "      <td>162.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>166.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cardnum_count_0</td>\n",
       "      <td>0.339655</td>\n",
       "      <td>0.173963</td>\n",
       "      <td>161.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>166.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>card_state_actual/total_1</td>\n",
       "      <td>0.357774</td>\n",
       "      <td>0.124424</td>\n",
       "      <td>170.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>165.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Merchnum_total_30</td>\n",
       "      <td>0.418990</td>\n",
       "      <td>0.097926</td>\n",
       "      <td>179.0</td>\n",
       "      <td>143.5</td>\n",
       "      <td>161.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>card_merch_count_3</td>\n",
       "      <td>0.328081</td>\n",
       "      <td>0.147465</td>\n",
       "      <td>155.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>160.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>card_zip_count_1</td>\n",
       "      <td>0.320122</td>\n",
       "      <td>0.184332</td>\n",
       "      <td>147.0</td>\n",
       "      <td>172.5</td>\n",
       "      <td>159.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>state_risk</td>\n",
       "      <td>0.342858</td>\n",
       "      <td>0.111751</td>\n",
       "      <td>163.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>159.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>card_merch_count_1</td>\n",
       "      <td>0.319111</td>\n",
       "      <td>0.190092</td>\n",
       "      <td>145.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>159.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Merchnum_actual/med_14</td>\n",
       "      <td>0.312219</td>\n",
       "      <td>0.203917</td>\n",
       "      <td>141.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>159.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Merchnum_max_30</td>\n",
       "      <td>0.440870</td>\n",
       "      <td>0.089862</td>\n",
       "      <td>182.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>158.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>card_zip_day_since</td>\n",
       "      <td>0.320390</td>\n",
       "      <td>0.157834</td>\n",
       "      <td>149.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>158.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>card_zip_count_3</td>\n",
       "      <td>0.326809</td>\n",
       "      <td>0.141705</td>\n",
       "      <td>151.0</td>\n",
       "      <td>162.5</td>\n",
       "      <td>156.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>card_merch_actual/total_1</td>\n",
       "      <td>0.319223</td>\n",
       "      <td>0.154378</td>\n",
       "      <td>146.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>156.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>card_merch_actual/total_3</td>\n",
       "      <td>0.326886</td>\n",
       "      <td>0.114055</td>\n",
       "      <td>153.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>156.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>card_zip_actual/total_1</td>\n",
       "      <td>0.320234</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>148.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>156.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Merchnum_actual/avg_14</td>\n",
       "      <td>0.305595</td>\n",
       "      <td>0.148618</td>\n",
       "      <td>139.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>152.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Merchnum_actual/med_7</td>\n",
       "      <td>0.302464</td>\n",
       "      <td>0.167051</td>\n",
       "      <td>135.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>152.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cardnum_count_7</td>\n",
       "      <td>0.400647</td>\n",
       "      <td>0.084101</td>\n",
       "      <td>175.0</td>\n",
       "      <td>128.5</td>\n",
       "      <td>151.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Merchnum_actual/avg_7</td>\n",
       "      <td>0.303956</td>\n",
       "      <td>0.115207</td>\n",
       "      <td>138.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>149.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Cardnum_actual/avg_30</td>\n",
       "      <td>0.357937</td>\n",
       "      <td>0.082949</td>\n",
       "      <td>171.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>148.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>card_zip_actual/total_3</td>\n",
       "      <td>0.320427</td>\n",
       "      <td>0.102535</td>\n",
       "      <td>150.0</td>\n",
       "      <td>146.5</td>\n",
       "      <td>148.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>card_merch_day_since</td>\n",
       "      <td>0.326849</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>152.0</td>\n",
       "      <td>141.5</td>\n",
       "      <td>146.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Merchnum_actual/avg_3</td>\n",
       "      <td>0.301944</td>\n",
       "      <td>0.108295</td>\n",
       "      <td>134.0</td>\n",
       "      <td>152.5</td>\n",
       "      <td>143.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>card_state_actual/total_3</td>\n",
       "      <td>0.351406</td>\n",
       "      <td>0.076037</td>\n",
       "      <td>167.0</td>\n",
       "      <td>115.5</td>\n",
       "      <td>141.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>card_state_count_0</td>\n",
       "      <td>0.289267</td>\n",
       "      <td>0.111751</td>\n",
       "      <td>122.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>139.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cardnum_day_since</td>\n",
       "      <td>0.291275</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>124.0</td>\n",
       "      <td>150.5</td>\n",
       "      <td>137.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Cardnum_actual/med_30</td>\n",
       "      <td>0.281282</td>\n",
       "      <td>0.111751</td>\n",
       "      <td>118.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>137.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>card_merch_actual/max_1</td>\n",
       "      <td>0.293043</td>\n",
       "      <td>0.099078</td>\n",
       "      <td>125.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>135.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>card_merch_count_0</td>\n",
       "      <td>0.267732</td>\n",
       "      <td>0.112903</td>\n",
       "      <td>105.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>131.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>card_state_actual/total_0</td>\n",
       "      <td>0.289441</td>\n",
       "      <td>0.094470</td>\n",
       "      <td>123.0</td>\n",
       "      <td>139.5</td>\n",
       "      <td>131.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>card_zip_actual/max_1</td>\n",
       "      <td>0.295764</td>\n",
       "      <td>0.088710</td>\n",
       "      <td>128.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>130.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>card_merch_actual/max_3</td>\n",
       "      <td>0.300255</td>\n",
       "      <td>0.081797</td>\n",
       "      <td>132.0</td>\n",
       "      <td>124.5</td>\n",
       "      <td>128.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>card_merch_actual/total_0</td>\n",
       "      <td>0.267820</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>106.0</td>\n",
       "      <td>150.5</td>\n",
       "      <td>128.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>card_zip_count_0</td>\n",
       "      <td>0.266697</td>\n",
       "      <td>0.110599</td>\n",
       "      <td>101.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>127.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>card_zip_actual/total_0</td>\n",
       "      <td>0.266785</td>\n",
       "      <td>0.104839</td>\n",
       "      <td>102.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>125.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>card_state_day_since</td>\n",
       "      <td>0.357649</td>\n",
       "      <td>0.056452</td>\n",
       "      <td>168.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>125.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>card_state_actual/max_1</td>\n",
       "      <td>0.318063</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>143.0</td>\n",
       "      <td>105.5</td>\n",
       "      <td>124.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>card_zip_actual/max_3</td>\n",
       "      <td>0.298444</td>\n",
       "      <td>0.077189</td>\n",
       "      <td>130.0</td>\n",
       "      <td>118.5</td>\n",
       "      <td>124.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Merchnum_actual/med_3</td>\n",
       "      <td>0.249180</td>\n",
       "      <td>0.103687</td>\n",
       "      <td>93.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>120.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>card_merch_actual/max_0</td>\n",
       "      <td>0.229603</td>\n",
       "      <td>0.108295</td>\n",
       "      <td>86.0</td>\n",
       "      <td>152.5</td>\n",
       "      <td>119.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>card_merch_count_7</td>\n",
       "      <td>0.343322</td>\n",
       "      <td>0.050691</td>\n",
       "      <td>164.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>119.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Cardnum_actual/avg_14</td>\n",
       "      <td>0.284798</td>\n",
       "      <td>0.073733</td>\n",
       "      <td>121.0</td>\n",
       "      <td>110.5</td>\n",
       "      <td>115.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>card_state_count_7</td>\n",
       "      <td>0.362552</td>\n",
       "      <td>0.044931</td>\n",
       "      <td>173.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>115.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Merchnum_actual/avg_1</td>\n",
       "      <td>0.260612</td>\n",
       "      <td>0.085253</td>\n",
       "      <td>99.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>114.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>card_zip_actual/max_0</td>\n",
       "      <td>0.229782</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>87.0</td>\n",
       "      <td>141.5</td>\n",
       "      <td>114.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>card_merch_actual/total_7</td>\n",
       "      <td>0.300372</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>133.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>112.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>card_state_actual/max_3</td>\n",
       "      <td>0.310012</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>140.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>109.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Cardnum_actual/avg_7</td>\n",
       "      <td>0.273021</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>112.0</td>\n",
       "      <td>105.5</td>\n",
       "      <td>108.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>card_state_actual/max_0</td>\n",
       "      <td>0.242317</td>\n",
       "      <td>0.081797</td>\n",
       "      <td>90.0</td>\n",
       "      <td>124.5</td>\n",
       "      <td>107.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Cardnum_actual/med_14</td>\n",
       "      <td>0.252090</td>\n",
       "      <td>0.078341</td>\n",
       "      <td>94.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>107.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>card_zip_count_7</td>\n",
       "      <td>0.338998</td>\n",
       "      <td>0.041475</td>\n",
       "      <td>160.0</td>\n",
       "      <td>52.5</td>\n",
       "      <td>106.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Cardnum_actual/med_7</td>\n",
       "      <td>0.234021</td>\n",
       "      <td>0.079493</td>\n",
       "      <td>88.0</td>\n",
       "      <td>121.5</td>\n",
       "      <td>104.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>card_zip_actual/total_7</td>\n",
       "      <td>0.299318</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>131.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>104.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cardnum_actual/total_0</td>\n",
       "      <td>0.316797</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>142.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>card_merch_actual/med_7</td>\n",
       "      <td>0.204479</td>\n",
       "      <td>0.092166</td>\n",
       "      <td>66.0</td>\n",
       "      <td>137.5</td>\n",
       "      <td>101.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>card_merch_actual/max_7</td>\n",
       "      <td>0.278265</td>\n",
       "      <td>0.061060</td>\n",
       "      <td>115.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Cardnum_actual/max_30</td>\n",
       "      <td>0.337572</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>159.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>100.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>card_zip_actual/med_7</td>\n",
       "      <td>0.199777</td>\n",
       "      <td>0.094470</td>\n",
       "      <td>60.0</td>\n",
       "      <td>139.5</td>\n",
       "      <td>99.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>card_state_actual/total_7</td>\n",
       "      <td>0.296844</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>129.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>97.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Merchnum_actual/med_1</td>\n",
       "      <td>0.212583</td>\n",
       "      <td>0.077189</td>\n",
       "      <td>75.0</td>\n",
       "      <td>118.5</td>\n",
       "      <td>96.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>card_zip_actual/max_7</td>\n",
       "      <td>0.275197</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>113.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>95.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Merchnum_actual_0/avg_30</td>\n",
       "      <td>0.350393</td>\n",
       "      <td>0.020737</td>\n",
       "      <td>166.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>95.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>card_merch_actual/med_14</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>0.092166</td>\n",
       "      <td>48.0</td>\n",
       "      <td>137.5</td>\n",
       "      <td>92.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>card_state_actual/med_3</td>\n",
       "      <td>0.207715</td>\n",
       "      <td>0.076037</td>\n",
       "      <td>70.0</td>\n",
       "      <td>115.5</td>\n",
       "      <td>92.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Cardnum_count_14</td>\n",
       "      <td>0.333346</td>\n",
       "      <td>0.021889</td>\n",
       "      <td>158.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>92.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>card_merch_actual/med_1</td>\n",
       "      <td>0.189042</td>\n",
       "      <td>0.088710</td>\n",
       "      <td>51.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>92.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>card_merch_actual/med_3</td>\n",
       "      <td>0.197294</td>\n",
       "      <td>0.084101</td>\n",
       "      <td>56.0</td>\n",
       "      <td>128.5</td>\n",
       "      <td>92.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>card_state_count_14</td>\n",
       "      <td>0.332547</td>\n",
       "      <td>0.021889</td>\n",
       "      <td>157.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>92.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>card_zip_actual/med_1</td>\n",
       "      <td>0.188637</td>\n",
       "      <td>0.087558</td>\n",
       "      <td>49.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>90.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cardnum_actual/total_1</td>\n",
       "      <td>0.302950</td>\n",
       "      <td>0.033410</td>\n",
       "      <td>136.0</td>\n",
       "      <td>43.5</td>\n",
       "      <td>89.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>card_merch_actual/avg_1</td>\n",
       "      <td>0.185520</td>\n",
       "      <td>0.086406</td>\n",
       "      <td>46.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>88.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>card_state_actual/avg_30</td>\n",
       "      <td>0.215933</td>\n",
       "      <td>0.069124</td>\n",
       "      <td>77.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>88.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Merchnum_actual_0/avg_14</td>\n",
       "      <td>0.303255</td>\n",
       "      <td>0.027650</td>\n",
       "      <td>137.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>88.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>card_merch_actual/total_14</td>\n",
       "      <td>0.267224</td>\n",
       "      <td>0.047235</td>\n",
       "      <td>104.0</td>\n",
       "      <td>70.5</td>\n",
       "      <td>87.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Cardnum_count_1/avg_count_30</td>\n",
       "      <td>0.281827</td>\n",
       "      <td>0.042627</td>\n",
       "      <td>119.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>87.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>card_state_actual/avg_14</td>\n",
       "      <td>0.212006</td>\n",
       "      <td>0.066820</td>\n",
       "      <td>73.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>85.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>card_state_actual/med_7</td>\n",
       "      <td>0.219516</td>\n",
       "      <td>0.063364</td>\n",
       "      <td>80.0</td>\n",
       "      <td>89.5</td>\n",
       "      <td>84.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Merchnum_actual_0/avg_7</td>\n",
       "      <td>0.272269</td>\n",
       "      <td>0.044931</td>\n",
       "      <td>111.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>84.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>card_merch_actual/avg_3</td>\n",
       "      <td>0.184991</td>\n",
       "      <td>0.082949</td>\n",
       "      <td>42.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>84.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>card_merch_actual/avg_0</td>\n",
       "      <td>0.158590</td>\n",
       "      <td>0.102535</td>\n",
       "      <td>21.0</td>\n",
       "      <td>146.5</td>\n",
       "      <td>83.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>card_zip_actual/med_3</td>\n",
       "      <td>0.191438</td>\n",
       "      <td>0.076037</td>\n",
       "      <td>52.0</td>\n",
       "      <td>115.5</td>\n",
       "      <td>83.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Merchnum_actual_1/avg_7</td>\n",
       "      <td>0.271385</td>\n",
       "      <td>0.042627</td>\n",
       "      <td>110.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>82.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Merchnum_day_since</td>\n",
       "      <td>0.221858</td>\n",
       "      <td>0.056452</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>card_state_actual/avg_3</td>\n",
       "      <td>0.204575</td>\n",
       "      <td>0.066820</td>\n",
       "      <td>67.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>82.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>card_merch_actual/med_0</td>\n",
       "      <td>0.152523</td>\n",
       "      <td>0.097926</td>\n",
       "      <td>20.0</td>\n",
       "      <td>143.5</td>\n",
       "      <td>81.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>card_state_actual/avg_7</td>\n",
       "      <td>0.206702</td>\n",
       "      <td>0.065668</td>\n",
       "      <td>68.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>81.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>card_merch_actual/max_14</td>\n",
       "      <td>0.245888</td>\n",
       "      <td>0.047235</td>\n",
       "      <td>92.0</td>\n",
       "      <td>70.5</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>card_merch_actual/avg_7</td>\n",
       "      <td>0.182018</td>\n",
       "      <td>0.079493</td>\n",
       "      <td>40.0</td>\n",
       "      <td>121.5</td>\n",
       "      <td>80.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Cardnum_actual/avg_3</td>\n",
       "      <td>0.219448</td>\n",
       "      <td>0.056452</td>\n",
       "      <td>79.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>80.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>card_zip_actual/avg_1</td>\n",
       "      <td>0.185437</td>\n",
       "      <td>0.076037</td>\n",
       "      <td>45.0</td>\n",
       "      <td>115.5</td>\n",
       "      <td>80.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Merchnum_actual_1/avg_30</td>\n",
       "      <td>0.332082</td>\n",
       "      <td>0.005760</td>\n",
       "      <td>156.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>79.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>card_state_actual/med_1</td>\n",
       "      <td>0.198452</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>58.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>79.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>card_zip_actual/med_14</td>\n",
       "      <td>0.185857</td>\n",
       "      <td>0.073733</td>\n",
       "      <td>47.0</td>\n",
       "      <td>110.5</td>\n",
       "      <td>78.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>card_zip_actual/avg_0</td>\n",
       "      <td>0.159056</td>\n",
       "      <td>0.089862</td>\n",
       "      <td>22.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>78.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Cardnum_count_1/avg_count_14</td>\n",
       "      <td>0.269486</td>\n",
       "      <td>0.039171</td>\n",
       "      <td>108.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>78.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>card_merch_count_14</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>77.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>card_state_actual/avg_1</td>\n",
       "      <td>0.202019</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>62.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>77.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>card_merch_actual/avg_14</td>\n",
       "      <td>0.182755</td>\n",
       "      <td>0.074885</td>\n",
       "      <td>41.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>77.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>card_state_actual/med_14</td>\n",
       "      <td>0.207329</td>\n",
       "      <td>0.057604</td>\n",
       "      <td>69.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>76.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cardnum_actual/max_0</td>\n",
       "      <td>0.279711</td>\n",
       "      <td>0.026498</td>\n",
       "      <td>116.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>76.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>card_zip_count_14</td>\n",
       "      <td>0.318920</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>144.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>74.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>card_state_actual/max_7</td>\n",
       "      <td>0.266799</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>103.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>74.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>card_zip_actual/total_14</td>\n",
       "      <td>0.254297</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>97.0</td>\n",
       "      <td>50.5</td>\n",
       "      <td>73.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>card_zip_actual/avg_7</td>\n",
       "      <td>0.179392</td>\n",
       "      <td>0.073733</td>\n",
       "      <td>35.0</td>\n",
       "      <td>110.5</td>\n",
       "      <td>72.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>card_zip_actual/avg_3</td>\n",
       "      <td>0.180663</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>38.0</td>\n",
       "      <td>105.5</td>\n",
       "      <td>71.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Cardnum_actual/med_3</td>\n",
       "      <td>0.203740</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>65.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>71.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Merchnum_actual_1/avg_14</td>\n",
       "      <td>0.294970</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>126.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>71.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>card_zip_actual/med_0</td>\n",
       "      <td>0.152480</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>19.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>71.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>card_zip_actual/avg_14</td>\n",
       "      <td>0.179433</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>36.0</td>\n",
       "      <td>105.5</td>\n",
       "      <td>70.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>card_zip_actual/max_14</td>\n",
       "      <td>0.234688</td>\n",
       "      <td>0.041475</td>\n",
       "      <td>89.0</td>\n",
       "      <td>52.5</td>\n",
       "      <td>70.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>card_state_actual/med_30</td>\n",
       "      <td>0.196812</td>\n",
       "      <td>0.058756</td>\n",
       "      <td>55.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Merchnum_actual/avg_0</td>\n",
       "      <td>0.185020</td>\n",
       "      <td>0.066820</td>\n",
       "      <td>43.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>card_merch_actual/med_30</td>\n",
       "      <td>0.164794</td>\n",
       "      <td>0.073733</td>\n",
       "      <td>29.0</td>\n",
       "      <td>110.5</td>\n",
       "      <td>69.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>card_merch_actual/total_30</td>\n",
       "      <td>0.226375</td>\n",
       "      <td>0.042627</td>\n",
       "      <td>84.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>69.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Merchnum_actual/max_30</td>\n",
       "      <td>0.212257</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>74.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>69.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>card_merch_actual/avg_30</td>\n",
       "      <td>0.166640</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>30.0</td>\n",
       "      <td>105.5</td>\n",
       "      <td>67.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>card_zip_count_30</td>\n",
       "      <td>0.281887</td>\n",
       "      <td>0.013825</td>\n",
       "      <td>120.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>67.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cardnum_actual/max_1</td>\n",
       "      <td>0.278238</td>\n",
       "      <td>0.017281</td>\n",
       "      <td>114.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>67.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>card_merch_count_30</td>\n",
       "      <td>0.295221</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>127.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>66.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>card_state_actual/avg_0</td>\n",
       "      <td>0.168529</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>31.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>66.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>card_state_actual/total_14</td>\n",
       "      <td>0.226992</td>\n",
       "      <td>0.036866</td>\n",
       "      <td>85.0</td>\n",
       "      <td>46.5</td>\n",
       "      <td>65.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Cardnum_count_30</td>\n",
       "      <td>0.264505</td>\n",
       "      <td>0.023041</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>65.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>card_state_count_30</td>\n",
       "      <td>0.280521</td>\n",
       "      <td>0.012673</td>\n",
       "      <td>117.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>64.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cardnum_actual/avg_1</td>\n",
       "      <td>0.203594</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Cardnum_actual/total_3</td>\n",
       "      <td>0.270617</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>109.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>64.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Merchnum_count_1</td>\n",
       "      <td>0.252216</td>\n",
       "      <td>0.023041</td>\n",
       "      <td>95.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>62.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>card_state_actual/med_0</td>\n",
       "      <td>0.159255</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>62.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Cardnum_actual/max_14</td>\n",
       "      <td>0.245109</td>\n",
       "      <td>0.023041</td>\n",
       "      <td>91.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cardnum_actual/med_1</td>\n",
       "      <td>0.192051</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>53.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>59.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cardnum_actual/med_0</td>\n",
       "      <td>0.163126</td>\n",
       "      <td>0.063364</td>\n",
       "      <td>27.0</td>\n",
       "      <td>89.5</td>\n",
       "      <td>58.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Merchnum_count_7</td>\n",
       "      <td>0.253665</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>96.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>57.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cardnum_actual/max_3</td>\n",
       "      <td>0.212805</td>\n",
       "      <td>0.027650</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>57.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>card_zip_actual/avg_30</td>\n",
       "      <td>0.162987</td>\n",
       "      <td>0.062212</td>\n",
       "      <td>26.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>56.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Merchnum_count_0</td>\n",
       "      <td>0.218572</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>78.0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>55.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Merchnum_count_3</td>\n",
       "      <td>0.269256</td>\n",
       "      <td>0.005760</td>\n",
       "      <td>107.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>55.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Cardnum_count_1/avg_count_7</td>\n",
       "      <td>0.180413</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>37.0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>54.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Cardnum_count_0/avg_count_7</td>\n",
       "      <td>0.078069</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>2.0</td>\n",
       "      <td>105.5</td>\n",
       "      <td>53.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Merchnum_actual/med_0</td>\n",
       "      <td>0.148481</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>15.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>53.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cardnum_actual/avg_0</td>\n",
       "      <td>0.170904</td>\n",
       "      <td>0.051843</td>\n",
       "      <td>32.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>53.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>weekday_risk</td>\n",
       "      <td>0.135014</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>12.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>52.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Cardnum_count_0/avg_count_30</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>54.0</td>\n",
       "      <td>50.5</td>\n",
       "      <td>52.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Merchnum_actual/total_7</td>\n",
       "      <td>0.181661</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>39.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>52.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>card_zip_actual/med_30</td>\n",
       "      <td>0.160299</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>24.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Merchnum_count_14</td>\n",
       "      <td>0.254612</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>49.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Merchnum_actual/total_30</td>\n",
       "      <td>0.173326</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>34.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>49.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>card_zip_actual/total_30</td>\n",
       "      <td>0.211577</td>\n",
       "      <td>0.021889</td>\n",
       "      <td>72.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>49.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Merchnum_actual/max_14</td>\n",
       "      <td>0.172067</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>49.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>card_merch_actual/max_30</td>\n",
       "      <td>0.199451</td>\n",
       "      <td>0.027650</td>\n",
       "      <td>59.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>49.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>card_state_actual/max_14</td>\n",
       "      <td>0.203160</td>\n",
       "      <td>0.025346</td>\n",
       "      <td>63.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>48.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Cardnum_actual/total_30</td>\n",
       "      <td>0.200073</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>61.0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>46.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Merchnum_count_1/avg_count_30</td>\n",
       "      <td>0.125631</td>\n",
       "      <td>0.062212</td>\n",
       "      <td>6.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>46.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Merchnum_actual/total_3</td>\n",
       "      <td>0.221896</td>\n",
       "      <td>0.009217</td>\n",
       "      <td>83.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>45.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Merchnum_actual/total_1</td>\n",
       "      <td>0.219932</td>\n",
       "      <td>0.010369</td>\n",
       "      <td>81.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Merchnum_actual/max_7</td>\n",
       "      <td>0.132795</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>11.0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>41.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Merchnum_actual/total_14</td>\n",
       "      <td>0.150282</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>18.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>41.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>card_zip_actual/max_30</td>\n",
       "      <td>0.185386</td>\n",
       "      <td>0.027650</td>\n",
       "      <td>44.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>41.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Merchnum_count_30</td>\n",
       "      <td>0.209539</td>\n",
       "      <td>0.009217</td>\n",
       "      <td>71.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>39.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Merchnum_count_0/avg_count_7</td>\n",
       "      <td>0.163737</td>\n",
       "      <td>0.038018</td>\n",
       "      <td>28.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>38.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Cardnum_count_0/avg_count_14</td>\n",
       "      <td>0.145883</td>\n",
       "      <td>0.044931</td>\n",
       "      <td>14.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>36.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Cardnum_actual/total_7</td>\n",
       "      <td>0.188891</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>50.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>34.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Merchnum_count_1/avg_count_7</td>\n",
       "      <td>0.127874</td>\n",
       "      <td>0.044931</td>\n",
       "      <td>8.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>33.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Merchnum_actual/total_0</td>\n",
       "      <td>0.197317</td>\n",
       "      <td>0.009217</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Merchnum_count_0/avg_count_14</td>\n",
       "      <td>0.132698</td>\n",
       "      <td>0.027650</td>\n",
       "      <td>10.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>24.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>randNum</td>\n",
       "      <td>0.033620</td>\n",
       "      <td>0.036866</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.5</td>\n",
       "      <td>23.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>card_state_actual/max_30</td>\n",
       "      <td>0.118602</td>\n",
       "      <td>0.033410</td>\n",
       "      <td>4.0</td>\n",
       "      <td>43.5</td>\n",
       "      <td>23.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Cardnum_actual/total_14</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.025346</td>\n",
       "      <td>9.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>21.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>card_state_actual/total_30</td>\n",
       "      <td>0.149686</td>\n",
       "      <td>0.020737</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>20.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Merchnum_actual/max_1</td>\n",
       "      <td>0.149278</td>\n",
       "      <td>0.019585</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>19.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Cardnum_actual/max_7</td>\n",
       "      <td>0.161066</td>\n",
       "      <td>0.011521</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Merchnum_actual/max_3</td>\n",
       "      <td>0.142154</td>\n",
       "      <td>0.013825</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Merchnum_actual/max_0</td>\n",
       "      <td>0.124179</td>\n",
       "      <td>0.019585</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>13.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Merchnum_count_1/avg_count_14</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.013825</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Merchnum_count_0/avg_count_30</td>\n",
       "      <td>0.104943</td>\n",
       "      <td>0.012673</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Variable        ks       FDR  rank_ks  rank_FDR  \\\n",
       "301                          Fraud  1.000000  1.000000    303.0     303.0   \n",
       "197               card_zip_total_7  0.686097  0.639401    302.0     301.0   \n",
       "188               card_zip_total_3  0.679002  0.642857    300.0     302.0   \n",
       "142             card_merch_total_7  0.681855  0.633641    301.0     300.0   \n",
       "151            card_merch_total_14  0.676265  0.631336    299.0     298.5   \n",
       "133             card_merch_total_3  0.675786  0.631336    298.0     298.5   \n",
       "243             card_state_total_3  0.674461  0.630184    297.0     297.0   \n",
       "206              card_zip_total_14  0.673388  0.627880    296.0     296.0   \n",
       "252             card_state_total_7  0.669424  0.596774    295.0     292.0   \n",
       "179               card_zip_total_1  0.660988  0.597926    293.0     293.5   \n",
       "234             card_state_total_1  0.659490  0.601382    291.0     295.0   \n",
       "124             card_merch_total_1  0.658840  0.597926    290.0     293.5   \n",
       "160            card_merch_total_30  0.659890  0.559908    292.0     289.5   \n",
       "261            card_state_total_14  0.668924  0.523041    294.0     283.0   \n",
       "215              card_zip_total_30  0.656569  0.544931    288.0     284.5   \n",
       "204                card_zip_max_14  0.656887  0.476959    289.0     275.0   \n",
       "225             card_state_total_0  0.610943  0.562212    271.0     291.0   \n",
       "115             card_merch_total_0  0.611628  0.559908    272.0     289.5   \n",
       "170               card_zip_total_0  0.612584  0.557604    273.0     288.0   \n",
       "213                card_zip_max_30  0.650336  0.480415    283.0     277.0   \n",
       "250               card_state_max_7  0.646827  0.489631    280.0     279.5   \n",
       "149              card_merch_max_14  0.654928  0.474654    286.0     271.0   \n",
       "23                 Cardnum_total_3  0.602060  0.552995    268.0     287.0   \n",
       "259              card_state_max_14  0.629882  0.488479    277.0     278.0   \n",
       "186                 card_zip_max_3  0.648802  0.475806    282.0     273.0   \n",
       "195                 card_zip_max_7  0.656497  0.466590    287.0     267.0   \n",
       "158              card_merch_max_30  0.650896  0.473502    284.0     269.5   \n",
       "131               card_merch_max_3  0.645214  0.475806    279.0     273.0   \n",
       "140               card_merch_max_7  0.650989  0.465438    285.0     266.0   \n",
       "241               card_state_max_3  0.648072  0.473502    281.0     269.5   \n",
       "32                 Cardnum_total_7  0.599896  0.518433    265.0     282.0   \n",
       "268              card_state_max_30  0.597115  0.478111    264.0     276.0   \n",
       "270            card_state_total_30  0.635167  0.444700    278.0     262.0   \n",
       "122               card_merch_max_1  0.621067  0.457373    274.0     265.0   \n",
       "177                 card_zip_max_1  0.624140  0.455069    275.0     263.0   \n",
       "232               card_state_max_1  0.625878  0.442396    276.0     261.0   \n",
       "14                 Cardnum_total_1  0.576927  0.544931    247.0     284.5   \n",
       "5                  Cardnum_total_0  0.570956  0.551843    239.0     286.0   \n",
       "223               card_state_max_0  0.602610  0.419355    269.0     256.0   \n",
       "168                 card_zip_max_0  0.604239  0.415899    270.0     254.5   \n",
       "113               card_merch_max_0  0.601008  0.415899    267.0     254.5   \n",
       "60                Merchnum_total_0  0.571342  0.514977    240.0     281.0   \n",
       "58                  Merchnum_max_0  0.591500  0.421659    261.0     257.0   \n",
       "3                    Cardnum_max_0  0.585228  0.425115    253.0     258.0   \n",
       "69                Merchnum_total_1  0.583667  0.414747    252.0     253.0   \n",
       "30                   Cardnum_max_7  0.558783  0.489631    218.0     279.5   \n",
       "12                   Cardnum_max_1  0.570372  0.430876    237.0     260.0   \n",
       "21                   Cardnum_max_3  0.561162  0.456221    224.0     264.0   \n",
       "11                   Cardnum_avg_1  0.571908  0.354839    241.0     243.0   \n",
       "41                Cardnum_total_14  0.547260  0.475806    208.0     273.0   \n",
       "249               card_state_avg_7  0.587236  0.308756    254.0     227.0   \n",
       "78                Merchnum_total_3  0.568238  0.381336    234.0     247.0   \n",
       "240               card_state_avg_3  0.589001  0.305300    256.0     223.5   \n",
       "20                   Cardnum_avg_3  0.570028  0.359447    235.0     244.0   \n",
       "112               card_merch_avg_0  0.573744  0.319124    246.0     231.5   \n",
       "212                card_zip_avg_30  0.600269  0.293779    266.0     210.5   \n",
       "222               card_state_avg_0  0.572745  0.323733    242.0     234.0   \n",
       "167                 card_zip_avg_0  0.573452  0.319124    244.0     231.5   \n",
       "67                  Merchnum_max_1  0.557938  0.426267    216.0     259.0   \n",
       "231               card_state_avg_1  0.582663  0.305300    251.0     223.5   \n",
       "57                  Merchnum_avg_0  0.579426  0.307604    249.0     225.0   \n",
       "2                    Cardnum_avg_0  0.570178  0.328341    236.0     238.0   \n",
       "185                 card_zip_avg_3  0.589605  0.298387    258.0     215.5   \n",
       "130               card_merch_avg_3  0.590142  0.297235    259.0     214.0   \n",
       "258              card_state_avg_14  0.572961  0.315668    243.0     230.0   \n",
       "194                 card_zip_avg_7  0.590674  0.294931    260.0     212.0   \n",
       "176                 card_zip_avg_1  0.579509  0.301843    250.0     221.0   \n",
       "157              card_merch_avg_30  0.593927  0.292627    263.0     207.5   \n",
       "267              card_state_avg_30  0.566645  0.328341    232.0     238.0   \n",
       "39                  Cardnum_max_14  0.525422  0.470046    200.0     268.0   \n",
       "203                card_zip_avg_14  0.592974  0.291475    262.0     204.5   \n",
       "121               card_merch_avg_1  0.576942  0.299539    248.0     218.0   \n",
       "139               card_merch_avg_7  0.588388  0.293779    255.0     210.5   \n",
       "148              card_merch_avg_14  0.589365  0.292627    257.0     207.5   \n",
       "29                   Cardnum_avg_7  0.547325  0.403226    209.0     250.0   \n",
       "13                   Cardnum_med_1  0.557223  0.331797    215.0     240.5   \n",
       "38                  Cardnum_avg_14  0.531202  0.404378    201.0     251.5   \n",
       "76                  Merchnum_max_3  0.531419  0.364055    202.0     245.0   \n",
       "47                  Cardnum_avg_30  0.508837  0.383641    199.0     248.0   \n",
       "224               card_state_med_0  0.561188  0.302995    225.0     222.0   \n",
       "114               card_merch_med_0  0.563690  0.299539    229.0     218.0   \n",
       "169                 card_zip_med_0  0.562688  0.299539    228.0     218.0   \n",
       "50                Cardnum_total_30  0.486549  0.404378    193.0     251.5   \n",
       "85                  Merchnum_max_7  0.537164  0.331797    204.0     240.5   \n",
       "4                    Cardnum_med_0  0.557940  0.308756    217.0     227.0   \n",
       "286        Cardnum_actual_1/avg_30  0.489778  0.388249    195.0     249.0   \n",
       "48                  Cardnum_max_30  0.503413  0.380184    197.0     246.0   \n",
       "22                   Cardnum_med_3  0.544923  0.323733    207.0     234.0   \n",
       "66                  Merchnum_avg_1  0.573488  0.279954    245.0     192.5   \n",
       "123               card_merch_med_1  0.564179  0.291475    230.0     204.5   \n",
       "178                 card_zip_med_1  0.561305  0.292627    226.0     207.5   \n",
       "187                 card_zip_med_3  0.566784  0.288018    233.0     200.5   \n",
       "233               card_state_med_1  0.560207  0.296083    219.0     213.0   \n",
       "84                  Merchnum_avg_7  0.561567  0.290323    227.0     202.5   \n",
       "40                  Cardnum_med_14  0.483187  0.328341    191.0     238.0   \n",
       "132               card_merch_med_3  0.565764  0.286866    231.0     198.0   \n",
       "159              card_merch_med_30  0.570772  0.277650    238.0     189.5   \n",
       "87                Merchnum_total_7  0.504191  0.312212    198.0     229.0   \n",
       "284        Cardnum_actual_1/avg_14  0.451912  0.347926    185.0     242.0   \n",
       "269              card_state_med_30  0.550301  0.298387    210.0     215.5   \n",
       "280        Cardnum_actual_0/avg_30  0.457537  0.323733    188.0     234.0   \n",
       "282         Cardnum_actual_1/avg_7  0.446039  0.324885    184.0     236.0   \n",
       "31                   Cardnum_med_7  0.483455  0.308756    192.0     227.0   \n",
       "242               card_state_med_3  0.560343  0.286866    220.0     198.0   \n",
       "251               card_state_med_7  0.551772  0.290323    212.0     202.5   \n",
       "150              card_merch_med_14  0.561003  0.278802    223.0     191.0   \n",
       "260              card_state_med_14  0.537007  0.292627    203.0     207.5   \n",
       "214                card_zip_med_30  0.560686  0.276498    222.0     188.0   \n",
       "196                 card_zip_med_7  0.555145  0.281106    213.0     194.5   \n",
       "49                  Cardnum_med_30  0.454153  0.300691    187.0     220.0   \n",
       "75                  Merchnum_avg_3  0.560654  0.268433    221.0     186.0   \n",
       "141               card_merch_med_7  0.555193  0.279954    214.0     192.5   \n",
       "93                 Merchnum_avg_14  0.537611  0.288018    205.0     200.5   \n",
       "59                  Merchnum_med_0  0.540992  0.286866    206.0     198.0   \n",
       "205                card_zip_med_14  0.551124  0.277650    211.0     189.5   \n",
       "68                  Merchnum_med_1  0.501890  0.281106    196.0     194.5   \n",
       "77                  Merchnum_med_3  0.488075  0.269585    194.0     187.0   \n",
       "278        Cardnum_actual_0/avg_14  0.426766  0.284562    181.0     196.0   \n",
       "94                 Merchnum_max_14  0.479876  0.252304    189.0     183.0   \n",
       "102                Merchnum_avg_30  0.482283  0.211982    190.0     179.0   \n",
       "86                  Merchnum_med_7  0.445273  0.251152    183.0     182.0   \n",
       "96               Merchnum_total_14  0.452049  0.207373    186.0     178.0   \n",
       "276         Cardnum_actual_0/avg_7  0.411142  0.262673    177.0     184.5   \n",
       "95                 Merchnum_med_14  0.419433  0.228111    180.0     181.0   \n",
       "10                 Cardnum_count_1  0.380504  0.262673    174.0     184.5   \n",
       "104                Merchnum_med_30  0.414814  0.194700    178.0     175.0   \n",
       "19                 Cardnum_count_3  0.406860  0.197005    176.0     176.0   \n",
       "108         Merchnum_actual/med_30  0.348455  0.220046    165.0     180.0   \n",
       "230             card_state_count_1  0.357649  0.184332    168.5     172.5   \n",
       "239             card_state_count_3  0.358861  0.141705    172.0     162.5   \n",
       "106         Merchnum_actual/avg_30  0.342823  0.170507    162.0     170.0   \n",
       "1                  Cardnum_count_0  0.339655  0.173963    161.0     171.0   \n",
       "238      card_state_actual/total_1  0.357774  0.124424    170.0     161.0   \n",
       "105              Merchnum_total_30  0.418990  0.097926    179.0     143.5   \n",
       "129             card_merch_count_3  0.328081  0.147465    155.0     165.0   \n",
       "175               card_zip_count_1  0.320122  0.184332    147.0     172.5   \n",
       "300                     state_risk  0.342858  0.111751    163.0     156.0   \n",
       "120             card_merch_count_1  0.319111  0.190092    145.0     174.0   \n",
       "99          Merchnum_actual/med_14  0.312219  0.203917    141.0     177.0   \n",
       "103                Merchnum_max_30  0.440870  0.089862    182.0     135.5   \n",
       "165             card_zip_day_since  0.320390  0.157834    149.0     168.0   \n",
       "184               card_zip_count_3  0.326809  0.141705    151.0     162.5   \n",
       "128      card_merch_actual/total_1  0.319223  0.154378    146.0     167.0   \n",
       "137      card_merch_actual/total_3  0.326886  0.114055    153.0     159.0   \n",
       "183        card_zip_actual/total_1  0.320234  0.145161    148.0     164.0   \n",
       "97          Merchnum_actual/avg_14  0.305595  0.148618    139.0     166.0   \n",
       "90           Merchnum_actual/med_7  0.302464  0.167051    135.0     169.0   \n",
       "28                 Cardnum_count_7  0.400647  0.084101    175.0     128.5   \n",
       "88           Merchnum_actual/avg_7  0.303956  0.115207    138.0     160.0   \n",
       "51           Cardnum_actual/avg_30  0.357937  0.082949    171.0     126.5   \n",
       "192        card_zip_actual/total_3  0.320427  0.102535    150.0     146.5   \n",
       "110           card_merch_day_since  0.326849  0.096774    152.0     141.5   \n",
       "79           Merchnum_actual/avg_3  0.301944  0.108295    134.0     152.5   \n",
       "247      card_state_actual/total_3  0.351406  0.076037    167.0     115.5   \n",
       "221             card_state_count_0  0.289267  0.111751    122.0     156.0   \n",
       "0                Cardnum_day_since  0.291275  0.107143    124.0     150.5   \n",
       "53           Cardnum_actual/med_30  0.281282  0.111751    118.0     156.0   \n",
       "126        card_merch_actual/max_1  0.293043  0.099078    125.0     145.0   \n",
       "111             card_merch_count_0  0.267732  0.112903    105.0     158.0   \n",
       "229      card_state_actual/total_0  0.289441  0.094470    123.0     139.5   \n",
       "181          card_zip_actual/max_1  0.295764  0.088710    128.0     133.5   \n",
       "135        card_merch_actual/max_3  0.300255  0.081797    132.0     124.5   \n",
       "119      card_merch_actual/total_0  0.267820  0.107143    106.0     150.5   \n",
       "166               card_zip_count_0  0.266697  0.110599    101.0     154.0   \n",
       "174        card_zip_actual/total_0  0.266785  0.104839    102.0     149.0   \n",
       "220           card_state_day_since  0.357649  0.056452    168.5      82.0   \n",
       "236        card_state_actual/max_1  0.318063  0.072581    143.0     105.5   \n",
       "190          card_zip_actual/max_3  0.298444  0.077189    130.0     118.5   \n",
       "81           Merchnum_actual/med_3  0.249180  0.103687     93.0     148.0   \n",
       "117        card_merch_actual/max_0  0.229603  0.108295     86.0     152.5   \n",
       "138             card_merch_count_7  0.343322  0.050691    164.0      74.0   \n",
       "42           Cardnum_actual/avg_14  0.284798  0.073733    121.0     110.5   \n",
       "248             card_state_count_7  0.362552  0.044931    173.0      58.5   \n",
       "70           Merchnum_actual/avg_1  0.260612  0.085253     99.0     130.0   \n",
       "172          card_zip_actual/max_0  0.229782  0.096774     87.0     141.5   \n",
       "146      card_merch_actual/total_7  0.300372  0.064516    133.0      92.5   \n",
       "245        card_state_actual/max_3  0.310012  0.055300    140.0      78.0   \n",
       "33            Cardnum_actual/avg_7  0.273021  0.072581    112.0     105.5   \n",
       "227        card_state_actual/max_0  0.242317  0.081797     90.0     124.5   \n",
       "44           Cardnum_actual/med_14  0.252090  0.078341     94.0     120.0   \n",
       "193               card_zip_count_7  0.338998  0.041475    160.0      52.5   \n",
       "35            Cardnum_actual/med_7  0.234021  0.079493     88.0     121.5   \n",
       "201        card_zip_actual/total_7  0.299318  0.055300    131.0      78.0   \n",
       "9           Cardnum_actual/total_0  0.316797  0.046083    142.0      65.0   \n",
       "145        card_merch_actual/med_7  0.204479  0.092166     66.0     137.5   \n",
       "144        card_merch_actual/max_7  0.278265  0.061060    115.0      86.0   \n",
       "52           Cardnum_actual/max_30  0.337572  0.032258    159.0      42.0   \n",
       "200          card_zip_actual/med_7  0.199777  0.094470     60.0     139.5   \n",
       "256      card_state_actual/total_7  0.296844  0.046083    129.0      65.0   \n",
       "72           Merchnum_actual/med_1  0.212583  0.077189     75.0     118.5   \n",
       "199          card_zip_actual/max_7  0.275197  0.055300    113.0      78.0   \n",
       "292       Merchnum_actual_0/avg_30  0.350393  0.020737    166.0      24.5   \n",
       "154       card_merch_actual/med_14  0.187945  0.092166     48.0     137.5   \n",
       "246        card_state_actual/med_3  0.207715  0.076037     70.0     115.5   \n",
       "37                Cardnum_count_14  0.333346  0.021889    158.0      27.0   \n",
       "127        card_merch_actual/med_1  0.189042  0.088710     51.0     133.5   \n",
       "136        card_merch_actual/med_3  0.197294  0.084101     56.0     128.5   \n",
       "257            card_state_count_14  0.332547  0.021889    157.0      27.0   \n",
       "182          card_zip_actual/med_1  0.188637  0.087558     49.0     132.0   \n",
       "18          Cardnum_actual/total_1  0.302950  0.033410    136.0      43.5   \n",
       "125        card_merch_actual/avg_1  0.185520  0.086406     46.0     131.0   \n",
       "271       card_state_actual/avg_30  0.215933  0.069124     77.0      99.0   \n",
       "290       Merchnum_actual_0/avg_14  0.303255  0.027650    137.0      39.0   \n",
       "155     card_merch_actual/total_14  0.267224  0.047235    104.0      70.5   \n",
       "285   Cardnum_count_1/avg_count_30  0.281827  0.042627    119.0      55.0   \n",
       "262       card_state_actual/avg_14  0.212006  0.066820     73.0      97.0   \n",
       "255        card_state_actual/med_7  0.219516  0.063364     80.0      89.5   \n",
       "288        Merchnum_actual_0/avg_7  0.272269  0.044931    111.0      58.5   \n",
       "134        card_merch_actual/avg_3  0.184991  0.082949     42.0     126.5   \n",
       "116        card_merch_actual/avg_0  0.158590  0.102535     21.0     146.5   \n",
       "191          card_zip_actual/med_3  0.191438  0.076037     52.0     115.5   \n",
       "294        Merchnum_actual_1/avg_7  0.271385  0.042627    110.0      55.0   \n",
       "55              Merchnum_day_since  0.221858  0.056452     82.0      82.0   \n",
       "244        card_state_actual/avg_3  0.204575  0.066820     67.0      97.0   \n",
       "118        card_merch_actual/med_0  0.152523  0.097926     20.0     143.5   \n",
       "253        card_state_actual/avg_7  0.206702  0.065668     68.0      95.0   \n",
       "153       card_merch_actual/max_14  0.245888  0.047235     92.0      70.5   \n",
       "143        card_merch_actual/avg_7  0.182018  0.079493     40.0     121.5   \n",
       "24            Cardnum_actual/avg_3  0.219448  0.056452     79.0      82.0   \n",
       "180          card_zip_actual/avg_1  0.185437  0.076037     45.0     115.5   \n",
       "298       Merchnum_actual_1/avg_30  0.332082  0.005760    156.0       3.5   \n",
       "237        card_state_actual/med_1  0.198452  0.071429     58.0     101.0   \n",
       "209         card_zip_actual/med_14  0.185857  0.073733     47.0     110.5   \n",
       "171          card_zip_actual/avg_0  0.159056  0.089862     22.0     135.5   \n",
       "283   Cardnum_count_1/avg_count_14  0.269486  0.039171    108.0      49.0   \n",
       "147            card_merch_count_14  0.326923  0.004608    154.0       1.5   \n",
       "235        card_state_actual/avg_1  0.202019  0.064516     62.0      92.5   \n",
       "152       card_merch_actual/avg_14  0.182755  0.074885     41.0     113.0   \n",
       "264       card_state_actual/med_14  0.207329  0.057604     69.0      84.0   \n",
       "7             Cardnum_actual/max_0  0.279711  0.026498    116.0      36.0   \n",
       "202              card_zip_count_14  0.318920  0.006912    144.0       5.0   \n",
       "254        card_state_actual/max_7  0.266799  0.035714    103.0      45.0   \n",
       "210       card_zip_actual/total_14  0.254297  0.040323     97.0      50.5   \n",
       "198          card_zip_actual/avg_7  0.179392  0.073733     35.0     110.5   \n",
       "189          card_zip_actual/avg_3  0.180663  0.072581     38.0     105.5   \n",
       "26            Cardnum_actual/med_3  0.203740  0.055300     65.0      78.0   \n",
       "296       Merchnum_actual_1/avg_14  0.294970  0.014977    126.0      17.0   \n",
       "173          card_zip_actual/med_0  0.152480  0.080645     19.0     123.0   \n",
       "207         card_zip_actual/avg_14  0.179433  0.072581     36.0     105.5   \n",
       "208         card_zip_actual/max_14  0.234688  0.041475     89.0      52.5   \n",
       "273       card_state_actual/med_30  0.196812  0.058756     55.0      85.0   \n",
       "61           Merchnum_actual/avg_0  0.185020  0.066820     43.0      97.0   \n",
       "163       card_merch_actual/med_30  0.164794  0.073733     29.0     110.5   \n",
       "164     card_merch_actual/total_30  0.226375  0.042627     84.0      55.0   \n",
       "107         Merchnum_actual/max_30  0.212257  0.046083     74.0      65.0   \n",
       "161       card_merch_actual/avg_30  0.166640  0.072581     30.0     105.5   \n",
       "211              card_zip_count_30  0.281887  0.013825    120.0      15.0   \n",
       "16            Cardnum_actual/max_1  0.278238  0.017281    114.0      21.0   \n",
       "156            card_merch_count_30  0.295221  0.008065    127.0       6.0   \n",
       "226        card_state_actual/avg_0  0.168529  0.071429     31.0     101.0   \n",
       "265     card_state_actual/total_14  0.226992  0.036866     85.0      46.5   \n",
       "46                Cardnum_count_30  0.264505  0.023041    100.0      30.0   \n",
       "266            card_state_count_30  0.280521  0.012673    117.0      12.5   \n",
       "15            Cardnum_actual/avg_1  0.203594  0.046083     64.0      65.0   \n",
       "27          Cardnum_actual/total_3  0.270617  0.016129    109.0      19.0   \n",
       "65                Merchnum_count_1  0.252216  0.023041     95.0      30.0   \n",
       "228        card_state_actual/med_0  0.159255  0.071429     23.0     101.0   \n",
       "43           Cardnum_actual/max_14  0.245109  0.023041     91.0      30.0   \n",
       "17            Cardnum_actual/med_1  0.192051  0.046083     53.0      65.0   \n",
       "8             Cardnum_actual/med_0  0.163126  0.063364     27.0      89.5   \n",
       "83                Merchnum_count_7  0.253665  0.016129     96.0      19.0   \n",
       "25            Cardnum_actual/max_3  0.212805  0.027650     76.0      39.0   \n",
       "216         card_zip_actual/avg_30  0.162987  0.062212     26.0      87.5   \n",
       "56                Merchnum_count_0  0.218572  0.024194     78.0      32.5   \n",
       "74                Merchnum_count_3  0.269256  0.005760    107.0       3.5   \n",
       "281    Cardnum_count_1/avg_count_7  0.180413  0.048387     37.0      72.5   \n",
       "275    Cardnum_count_0/avg_count_7  0.078069  0.072581      2.0     105.5   \n",
       "63           Merchnum_actual/med_0  0.148481  0.064516     15.0      92.5   \n",
       "6             Cardnum_actual/avg_0  0.170904  0.051843     32.0      75.0   \n",
       "299                   weekday_risk  0.135014  0.064516     12.0      92.5   \n",
       "279   Cardnum_count_0/avg_count_30  0.192982  0.040323     54.0      50.5   \n",
       "91         Merchnum_actual/total_7  0.181661  0.046083     39.0      65.0   \n",
       "218         card_zip_actual/med_30  0.160299  0.055300     24.0      78.0   \n",
       "92               Merchnum_count_14  0.254612  0.004608     98.0       1.5   \n",
       "109       Merchnum_actual/total_30  0.173326  0.046083     34.0      65.0   \n",
       "219       card_zip_actual/total_30  0.211577  0.021889     72.0      27.0   \n",
       "98          Merchnum_actual/max_14  0.172067  0.046083     33.0      65.0   \n",
       "162       card_merch_actual/max_30  0.199451  0.027650     59.0      39.0   \n",
       "263       card_state_actual/max_14  0.203160  0.025346     63.0      34.5   \n",
       "54         Cardnum_actual/total_30  0.200073  0.024194     61.0      32.5   \n",
       "297  Merchnum_count_1/avg_count_30  0.125631  0.062212      6.0      87.5   \n",
       "82         Merchnum_actual/total_3  0.221896  0.009217     83.0       8.0   \n",
       "73         Merchnum_actual/total_1  0.219932  0.010369     81.0      10.0   \n",
       "89           Merchnum_actual/max_7  0.132795  0.048387     11.0      72.5   \n",
       "100       Merchnum_actual/total_14  0.150282  0.046083     18.0      65.0   \n",
       "217         card_zip_actual/max_30  0.185386  0.027650     44.0      39.0   \n",
       "101              Merchnum_count_30  0.209539  0.009217     71.0       8.0   \n",
       "287   Merchnum_count_0/avg_count_7  0.163737  0.038018     28.0      48.0   \n",
       "277   Cardnum_count_0/avg_count_14  0.145883  0.044931     14.0      58.5   \n",
       "36          Cardnum_actual/total_7  0.188891  0.016129     50.0      19.0   \n",
       "293   Merchnum_count_1/avg_count_7  0.127874  0.044931      8.0      58.5   \n",
       "64         Merchnum_actual/total_0  0.197317  0.009217     57.0       8.0   \n",
       "289  Merchnum_count_0/avg_count_14  0.132698  0.027650     10.0      39.0   \n",
       "302                        randNum  0.033620  0.036866      1.0      46.5   \n",
       "272       card_state_actual/max_30  0.118602  0.033410      4.0      43.5   \n",
       "45         Cardnum_actual/total_14  0.129032  0.025346      9.0      34.5   \n",
       "274     card_state_actual/total_30  0.149686  0.020737     17.0      24.5   \n",
       "71           Merchnum_actual/max_1  0.149278  0.019585     16.0      22.5   \n",
       "34            Cardnum_actual/max_7  0.161066  0.011521     25.0      11.0   \n",
       "80           Merchnum_actual/max_3  0.142154  0.013825     13.0      15.0   \n",
       "62           Merchnum_actual/max_0  0.124179  0.019585      5.0      22.5   \n",
       "295  Merchnum_count_1/avg_count_14  0.126900  0.013825      7.0      15.0   \n",
       "291  Merchnum_count_0/avg_count_30  0.104943  0.012673      3.0      12.5   \n",
       "\n",
       "     average_rank  \n",
       "301        303.00  \n",
       "197        301.50  \n",
       "188        301.00  \n",
       "142        300.50  \n",
       "151        298.75  \n",
       "133        298.25  \n",
       "243        297.00  \n",
       "206        296.00  \n",
       "252        293.50  \n",
       "179        293.25  \n",
       "234        293.00  \n",
       "124        291.75  \n",
       "160        290.75  \n",
       "261        288.50  \n",
       "215        286.25  \n",
       "204        282.00  \n",
       "225        281.00  \n",
       "115        280.75  \n",
       "170        280.50  \n",
       "213        280.00  \n",
       "250        279.75  \n",
       "149        278.50  \n",
       "23         277.50  \n",
       "259        277.50  \n",
       "186        277.50  \n",
       "195        277.00  \n",
       "158        276.75  \n",
       "131        276.00  \n",
       "140        275.50  \n",
       "241        275.25  \n",
       "32         273.50  \n",
       "268        270.00  \n",
       "270        270.00  \n",
       "122        269.50  \n",
       "177        269.00  \n",
       "232        268.50  \n",
       "14         265.75  \n",
       "5          262.50  \n",
       "223        262.50  \n",
       "168        262.25  \n",
       "113        260.75  \n",
       "60         260.50  \n",
       "58         259.00  \n",
       "3          255.50  \n",
       "69         252.50  \n",
       "30         248.75  \n",
       "12         248.50  \n",
       "21         244.00  \n",
       "11         242.00  \n",
       "41         240.50  \n",
       "249        240.50  \n",
       "78         240.50  \n",
       "240        239.75  \n",
       "20         239.50  \n",
       "112        238.75  \n",
       "212        238.25  \n",
       "222        238.00  \n",
       "167        237.75  \n",
       "67         237.50  \n",
       "231        237.25  \n",
       "57         237.00  \n",
       "2          237.00  \n",
       "185        236.75  \n",
       "130        236.50  \n",
       "258        236.50  \n",
       "194        236.00  \n",
       "176        235.50  \n",
       "157        235.25  \n",
       "267        235.00  \n",
       "39         234.00  \n",
       "203        233.25  \n",
       "121        233.00  \n",
       "139        232.75  \n",
       "148        232.25  \n",
       "29         229.50  \n",
       "13         227.75  \n",
       "38         226.25  \n",
       "76         223.50  \n",
       "47         223.50  \n",
       "224        223.50  \n",
       "114        223.50  \n",
       "169        223.00  \n",
       "50         222.25  \n",
       "85         222.25  \n",
       "4          222.00  \n",
       "286        222.00  \n",
       "48         221.50  \n",
       "22         220.50  \n",
       "66         218.75  \n",
       "123        217.25  \n",
       "178        216.75  \n",
       "187        216.75  \n",
       "233        216.00  \n",
       "84         214.75  \n",
       "40         214.50  \n",
       "132        214.50  \n",
       "159        213.75  \n",
       "87         213.50  \n",
       "284        213.50  \n",
       "269        212.75  \n",
       "280        211.00  \n",
       "282        210.00  \n",
       "31         209.50  \n",
       "242        209.00  \n",
       "251        207.25  \n",
       "150        207.00  \n",
       "260        205.25  \n",
       "214        205.00  \n",
       "196        203.75  \n",
       "49         203.50  \n",
       "75         203.50  \n",
       "141        203.25  \n",
       "93         202.75  \n",
       "59         202.00  \n",
       "205        200.25  \n",
       "68         195.25  \n",
       "77         190.50  \n",
       "278        188.50  \n",
       "94         186.00  \n",
       "102        184.50  \n",
       "86         182.50  \n",
       "96         182.00  \n",
       "276        180.75  \n",
       "95         180.50  \n",
       "10         179.25  \n",
       "104        176.50  \n",
       "19         176.00  \n",
       "108        172.50  \n",
       "230        170.50  \n",
       "239        167.25  \n",
       "106        166.00  \n",
       "1          166.00  \n",
       "238        165.50  \n",
       "105        161.25  \n",
       "129        160.00  \n",
       "175        159.75  \n",
       "300        159.50  \n",
       "120        159.50  \n",
       "99         159.00  \n",
       "103        158.75  \n",
       "165        158.50  \n",
       "184        156.75  \n",
       "128        156.50  \n",
       "137        156.00  \n",
       "183        156.00  \n",
       "97         152.50  \n",
       "90         152.00  \n",
       "28         151.75  \n",
       "88         149.00  \n",
       "51         148.75  \n",
       "192        148.25  \n",
       "110        146.75  \n",
       "79         143.25  \n",
       "247        141.25  \n",
       "221        139.00  \n",
       "0          137.25  \n",
       "53         137.00  \n",
       "126        135.00  \n",
       "111        131.50  \n",
       "229        131.25  \n",
       "181        130.75  \n",
       "135        128.25  \n",
       "119        128.25  \n",
       "166        127.50  \n",
       "174        125.50  \n",
       "220        125.25  \n",
       "236        124.25  \n",
       "190        124.25  \n",
       "81         120.50  \n",
       "117        119.25  \n",
       "138        119.00  \n",
       "42         115.75  \n",
       "248        115.75  \n",
       "70         114.50  \n",
       "172        114.25  \n",
       "146        112.75  \n",
       "245        109.00  \n",
       "33         108.75  \n",
       "227        107.25  \n",
       "44         107.00  \n",
       "193        106.25  \n",
       "35         104.75  \n",
       "201        104.50  \n",
       "9          103.50  \n",
       "145        101.75  \n",
       "144        100.50  \n",
       "52         100.50  \n",
       "200         99.75  \n",
       "256         97.00  \n",
       "72          96.75  \n",
       "199         95.50  \n",
       "292         95.25  \n",
       "154         92.75  \n",
       "246         92.75  \n",
       "37          92.50  \n",
       "127         92.25  \n",
       "136         92.25  \n",
       "257         92.00  \n",
       "182         90.50  \n",
       "18          89.75  \n",
       "125         88.50  \n",
       "271         88.00  \n",
       "290         88.00  \n",
       "155         87.25  \n",
       "285         87.00  \n",
       "262         85.00  \n",
       "255         84.75  \n",
       "288         84.75  \n",
       "134         84.25  \n",
       "116         83.75  \n",
       "191         83.75  \n",
       "294         82.50  \n",
       "55          82.00  \n",
       "244         82.00  \n",
       "118         81.75  \n",
       "253         81.50  \n",
       "153         81.25  \n",
       "143         80.75  \n",
       "24          80.50  \n",
       "180         80.25  \n",
       "298         79.75  \n",
       "237         79.50  \n",
       "209         78.75  \n",
       "171         78.75  \n",
       "283         78.50  \n",
       "147         77.75  \n",
       "235         77.25  \n",
       "152         77.00  \n",
       "264         76.50  \n",
       "7           76.00  \n",
       "202         74.50  \n",
       "254         74.00  \n",
       "210         73.75  \n",
       "198         72.75  \n",
       "189         71.75  \n",
       "26          71.50  \n",
       "296         71.50  \n",
       "173         71.00  \n",
       "207         70.75  \n",
       "208         70.75  \n",
       "273         70.00  \n",
       "61          70.00  \n",
       "163         69.75  \n",
       "164         69.50  \n",
       "107         69.50  \n",
       "161         67.75  \n",
       "211         67.50  \n",
       "16          67.50  \n",
       "156         66.50  \n",
       "226         66.00  \n",
       "265         65.75  \n",
       "46          65.00  \n",
       "266         64.75  \n",
       "15          64.50  \n",
       "27          64.00  \n",
       "65          62.50  \n",
       "228         62.00  \n",
       "43          60.50  \n",
       "17          59.00  \n",
       "8           58.25  \n",
       "83          57.50  \n",
       "25          57.50  \n",
       "216         56.75  \n",
       "56          55.25  \n",
       "74          55.25  \n",
       "281         54.75  \n",
       "275         53.75  \n",
       "63          53.75  \n",
       "6           53.50  \n",
       "299         52.25  \n",
       "279         52.25  \n",
       "91          52.00  \n",
       "218         51.00  \n",
       "92          49.75  \n",
       "109         49.50  \n",
       "219         49.50  \n",
       "98          49.00  \n",
       "162         49.00  \n",
       "263         48.75  \n",
       "54          46.75  \n",
       "297         46.75  \n",
       "82          45.50  \n",
       "73          45.50  \n",
       "89          41.75  \n",
       "100         41.50  \n",
       "217         41.50  \n",
       "101         39.50  \n",
       "287         38.00  \n",
       "277         36.25  \n",
       "36          34.50  \n",
       "293         33.25  \n",
       "64          32.50  \n",
       "289         24.50  \n",
       "302         23.75  \n",
       "272         23.75  \n",
       "45          21.75  \n",
       "274         20.75  \n",
       "71          19.25  \n",
       "34          18.00  \n",
       "80          14.00  \n",
       "62          13.75  \n",
       "295         11.00  \n",
       "291          7.75  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KSFDR.sort_values(by = ['average_rank'], ascending = False, inplace = True)\n",
    "KSFDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keep top 80 variables except Fraud\n",
    "KSFDRtop80 = KSFDR.Variable.head(81).tolist()\n",
    "wrapdata = newdata[KSFDRtop80]\n",
    "Y = wrapdata.Fraud\n",
    "wrapdata = wrapdata.drop(['Fraud'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_zip_total_7</th>\n",
       "      <th>card_zip_total_3</th>\n",
       "      <th>card_merch_total_7</th>\n",
       "      <th>card_merch_total_14</th>\n",
       "      <th>card_merch_total_3</th>\n",
       "      <th>card_state_total_3</th>\n",
       "      <th>card_zip_total_14</th>\n",
       "      <th>card_state_total_7</th>\n",
       "      <th>card_zip_total_1</th>\n",
       "      <th>card_state_total_1</th>\n",
       "      <th>card_merch_total_1</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>card_state_total_14</th>\n",
       "      <th>card_zip_total_30</th>\n",
       "      <th>card_zip_max_14</th>\n",
       "      <th>card_state_total_0</th>\n",
       "      <th>card_merch_total_0</th>\n",
       "      <th>card_zip_total_0</th>\n",
       "      <th>card_zip_max_30</th>\n",
       "      <th>card_state_max_7</th>\n",
       "      <th>card_merch_max_14</th>\n",
       "      <th>Cardnum_total_3</th>\n",
       "      <th>card_state_max_14</th>\n",
       "      <th>card_zip_max_3</th>\n",
       "      <th>card_zip_max_7</th>\n",
       "      <th>card_merch_max_30</th>\n",
       "      <th>card_merch_max_3</th>\n",
       "      <th>card_merch_max_7</th>\n",
       "      <th>card_state_max_3</th>\n",
       "      <th>Cardnum_total_7</th>\n",
       "      <th>card_state_max_30</th>\n",
       "      <th>card_state_total_30</th>\n",
       "      <th>card_merch_max_1</th>\n",
       "      <th>card_zip_max_1</th>\n",
       "      <th>card_state_max_1</th>\n",
       "      <th>Cardnum_total_1</th>\n",
       "      <th>Cardnum_total_0</th>\n",
       "      <th>card_state_max_0</th>\n",
       "      <th>card_zip_max_0</th>\n",
       "      <th>card_merch_max_0</th>\n",
       "      <th>Merchnum_total_0</th>\n",
       "      <th>Merchnum_max_0</th>\n",
       "      <th>Cardnum_max_0</th>\n",
       "      <th>Merchnum_total_1</th>\n",
       "      <th>Cardnum_max_7</th>\n",
       "      <th>Cardnum_max_1</th>\n",
       "      <th>Cardnum_max_3</th>\n",
       "      <th>Cardnum_avg_1</th>\n",
       "      <th>Cardnum_total_14</th>\n",
       "      <th>card_state_avg_7</th>\n",
       "      <th>Merchnum_total_3</th>\n",
       "      <th>card_state_avg_3</th>\n",
       "      <th>Cardnum_avg_3</th>\n",
       "      <th>card_merch_avg_0</th>\n",
       "      <th>card_zip_avg_30</th>\n",
       "      <th>card_state_avg_0</th>\n",
       "      <th>card_zip_avg_0</th>\n",
       "      <th>Merchnum_max_1</th>\n",
       "      <th>card_state_avg_1</th>\n",
       "      <th>Merchnum_avg_0</th>\n",
       "      <th>Cardnum_avg_0</th>\n",
       "      <th>card_zip_avg_3</th>\n",
       "      <th>card_merch_avg_3</th>\n",
       "      <th>card_state_avg_14</th>\n",
       "      <th>card_zip_avg_7</th>\n",
       "      <th>card_zip_avg_1</th>\n",
       "      <th>card_merch_avg_30</th>\n",
       "      <th>card_state_avg_30</th>\n",
       "      <th>Cardnum_max_14</th>\n",
       "      <th>card_zip_avg_14</th>\n",
       "      <th>card_merch_avg_1</th>\n",
       "      <th>card_merch_avg_7</th>\n",
       "      <th>card_merch_avg_14</th>\n",
       "      <th>Cardnum_avg_7</th>\n",
       "      <th>Cardnum_med_1</th>\n",
       "      <th>Cardnum_avg_14</th>\n",
       "      <th>Merchnum_max_3</th>\n",
       "      <th>Cardnum_avg_30</th>\n",
       "      <th>card_state_med_0</th>\n",
       "      <th>card_merch_med_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3344</th>\n",
       "      <td>0.112875</td>\n",
       "      <td>-0.031600</td>\n",
       "      <td>0.114971</td>\n",
       "      <td>0.107300</td>\n",
       "      <td>-0.030513</td>\n",
       "      <td>-0.040389</td>\n",
       "      <td>0.103796</td>\n",
       "      <td>0.094687</td>\n",
       "      <td>-0.028245</td>\n",
       "      <td>-0.033101</td>\n",
       "      <td>-0.027625</td>\n",
       "      <td>0.092679</td>\n",
       "      <td>0.071038</td>\n",
       "      <td>0.086288</td>\n",
       "      <td>0.045616</td>\n",
       "      <td>-0.024397</td>\n",
       "      <td>-0.021971</td>\n",
       "      <td>-0.022283</td>\n",
       "      <td>0.041519</td>\n",
       "      <td>0.040925</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.010302</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>-0.014476</td>\n",
       "      <td>0.048263</td>\n",
       "      <td>0.043745</td>\n",
       "      <td>-0.013962</td>\n",
       "      <td>0.049151</td>\n",
       "      <td>-0.018398</td>\n",
       "      <td>0.029839</td>\n",
       "      <td>0.023843</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>-0.013076</td>\n",
       "      <td>-0.013364</td>\n",
       "      <td>-0.015564</td>\n",
       "      <td>0.009931</td>\n",
       "      <td>-0.026477</td>\n",
       "      <td>-0.013049</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>-0.011960</td>\n",
       "      <td>-0.034782</td>\n",
       "      <td>-0.031554</td>\n",
       "      <td>-0.014666</td>\n",
       "      <td>-0.039690</td>\n",
       "      <td>-0.008867</td>\n",
       "      <td>0.005197</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>0.009414</td>\n",
       "      <td>0.130810</td>\n",
       "      <td>0.022171</td>\n",
       "      <td>-0.042657</td>\n",
       "      <td>-0.009612</td>\n",
       "      <td>-0.034008</td>\n",
       "      <td>-0.009430</td>\n",
       "      <td>0.021718</td>\n",
       "      <td>-0.009377</td>\n",
       "      <td>-0.009413</td>\n",
       "      <td>-0.033170</td>\n",
       "      <td>-0.009535</td>\n",
       "      <td>-0.050635</td>\n",
       "      <td>-0.010625</td>\n",
       "      <td>-0.009662</td>\n",
       "      <td>-0.009666</td>\n",
       "      <td>0.021988</td>\n",
       "      <td>0.022148</td>\n",
       "      <td>-0.009569</td>\n",
       "      <td>0.021754</td>\n",
       "      <td>0.021880</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.021928</td>\n",
       "      <td>-0.009571</td>\n",
       "      <td>0.022143</td>\n",
       "      <td>0.021953</td>\n",
       "      <td>-0.008515</td>\n",
       "      <td>-0.009277</td>\n",
       "      <td>-0.008777</td>\n",
       "      <td>-0.039859</td>\n",
       "      <td>-0.009776</td>\n",
       "      <td>-0.009043</td>\n",
       "      <td>-0.009197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3345</th>\n",
       "      <td>-0.037276</td>\n",
       "      <td>-0.046003</td>\n",
       "      <td>-0.036790</td>\n",
       "      <td>-0.027940</td>\n",
       "      <td>-0.046127</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.028500</td>\n",
       "      <td>-0.054761</td>\n",
       "      <td>-0.058862</td>\n",
       "      <td>-0.063686</td>\n",
       "      <td>-0.058245</td>\n",
       "      <td>-0.041930</td>\n",
       "      <td>-0.059726</td>\n",
       "      <td>-0.045255</td>\n",
       "      <td>-0.050952</td>\n",
       "      <td>-0.056308</td>\n",
       "      <td>-0.053896</td>\n",
       "      <td>-0.054206</td>\n",
       "      <td>-0.055018</td>\n",
       "      <td>-0.055574</td>\n",
       "      <td>-0.049568</td>\n",
       "      <td>-0.034552</td>\n",
       "      <td>-0.062026</td>\n",
       "      <td>-0.046449</td>\n",
       "      <td>-0.048330</td>\n",
       "      <td>-0.052812</td>\n",
       "      <td>-0.046505</td>\n",
       "      <td>-0.047448</td>\n",
       "      <td>-0.050360</td>\n",
       "      <td>-0.054434</td>\n",
       "      <td>-0.072453</td>\n",
       "      <td>-0.104284</td>\n",
       "      <td>-0.045912</td>\n",
       "      <td>-0.046200</td>\n",
       "      <td>-0.048395</td>\n",
       "      <td>-0.025558</td>\n",
       "      <td>-0.042738</td>\n",
       "      <td>-0.045907</td>\n",
       "      <td>-0.044965</td>\n",
       "      <td>-0.044821</td>\n",
       "      <td>-0.038400</td>\n",
       "      <td>-0.035178</td>\n",
       "      <td>-0.031147</td>\n",
       "      <td>-0.043263</td>\n",
       "      <td>-0.019790</td>\n",
       "      <td>-0.006004</td>\n",
       "      <td>-0.011291</td>\n",
       "      <td>-0.016142</td>\n",
       "      <td>-0.088177</td>\n",
       "      <td>-0.042691</td>\n",
       "      <td>-0.046018</td>\n",
       "      <td>-0.042415</td>\n",
       "      <td>-0.092819</td>\n",
       "      <td>-0.042330</td>\n",
       "      <td>-0.043165</td>\n",
       "      <td>-0.042279</td>\n",
       "      <td>-0.042313</td>\n",
       "      <td>-0.036751</td>\n",
       "      <td>-0.042437</td>\n",
       "      <td>-0.190227</td>\n",
       "      <td>-0.038234</td>\n",
       "      <td>-0.042459</td>\n",
       "      <td>-0.042486</td>\n",
       "      <td>-0.042915</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.042469</td>\n",
       "      <td>-0.043140</td>\n",
       "      <td>-0.043044</td>\n",
       "      <td>-0.027019</td>\n",
       "      <td>-0.042951</td>\n",
       "      <td>-0.042470</td>\n",
       "      <td>-0.042711</td>\n",
       "      <td>-0.042938</td>\n",
       "      <td>-0.093402</td>\n",
       "      <td>-0.009880</td>\n",
       "      <td>-0.107756</td>\n",
       "      <td>-0.042632</td>\n",
       "      <td>-0.175662</td>\n",
       "      <td>-0.041946</td>\n",
       "      <td>-0.042098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3346</th>\n",
       "      <td>-0.014860</td>\n",
       "      <td>-0.008426</td>\n",
       "      <td>-0.012807</td>\n",
       "      <td>0.139393</td>\n",
       "      <td>-0.007336</td>\n",
       "      <td>0.017240</td>\n",
       "      <td>0.135866</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>-0.005037</td>\n",
       "      <td>-0.009916</td>\n",
       "      <td>-0.004414</td>\n",
       "      <td>0.124622</td>\n",
       "      <td>0.136753</td>\n",
       "      <td>0.118175</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>-0.030364</td>\n",
       "      <td>-0.027941</td>\n",
       "      <td>-0.028252</td>\n",
       "      <td>-0.001281</td>\n",
       "      <td>-0.020029</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>0.268160</td>\n",
       "      <td>-0.008351</td>\n",
       "      <td>-0.019937</td>\n",
       "      <td>-0.022060</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>-0.019423</td>\n",
       "      <td>-0.021177</td>\n",
       "      <td>-0.014550</td>\n",
       "      <td>0.227464</td>\n",
       "      <td>-0.018850</td>\n",
       "      <td>0.087038</td>\n",
       "      <td>-0.018538</td>\n",
       "      <td>-0.018825</td>\n",
       "      <td>-0.021025</td>\n",
       "      <td>0.063876</td>\n",
       "      <td>-0.029518</td>\n",
       "      <td>-0.019193</td>\n",
       "      <td>-0.018249</td>\n",
       "      <td>-0.018105</td>\n",
       "      <td>-0.035458</td>\n",
       "      <td>-0.032231</td>\n",
       "      <td>-0.017747</td>\n",
       "      <td>-0.036982</td>\n",
       "      <td>0.040827</td>\n",
       "      <td>0.023602</td>\n",
       "      <td>0.062933</td>\n",
       "      <td>-0.004577</td>\n",
       "      <td>0.325432</td>\n",
       "      <td>-0.019297</td>\n",
       "      <td>-0.047441</td>\n",
       "      <td>-0.019083</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>-0.015582</td>\n",
       "      <td>-0.017985</td>\n",
       "      <td>-0.015530</td>\n",
       "      <td>-0.015565</td>\n",
       "      <td>-0.033765</td>\n",
       "      <td>-0.023447</td>\n",
       "      <td>-0.076738</td>\n",
       "      <td>-0.015788</td>\n",
       "      <td>-0.023574</td>\n",
       "      <td>-0.023577</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.023751</td>\n",
       "      <td>-0.023481</td>\n",
       "      <td>-0.017946</td>\n",
       "      <td>-0.016690</td>\n",
       "      <td>0.030477</td>\n",
       "      <td>-0.017772</td>\n",
       "      <td>-0.023482</td>\n",
       "      <td>-0.023755</td>\n",
       "      <td>-0.017746</td>\n",
       "      <td>0.028950</td>\n",
       "      <td>-0.021515</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>-0.040354</td>\n",
       "      <td>0.010980</td>\n",
       "      <td>-0.015195</td>\n",
       "      <td>-0.015349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3347</th>\n",
       "      <td>-0.036940</td>\n",
       "      <td>-0.045667</td>\n",
       "      <td>-0.036454</td>\n",
       "      <td>-0.027605</td>\n",
       "      <td>-0.045790</td>\n",
       "      <td>-0.054430</td>\n",
       "      <td>-0.028166</td>\n",
       "      <td>-0.054427</td>\n",
       "      <td>-0.058526</td>\n",
       "      <td>-0.063350</td>\n",
       "      <td>-0.057908</td>\n",
       "      <td>-0.041596</td>\n",
       "      <td>-0.059395</td>\n",
       "      <td>-0.044922</td>\n",
       "      <td>-0.050952</td>\n",
       "      <td>-0.055957</td>\n",
       "      <td>-0.053545</td>\n",
       "      <td>-0.053855</td>\n",
       "      <td>-0.055018</td>\n",
       "      <td>-0.055574</td>\n",
       "      <td>-0.049568</td>\n",
       "      <td>-0.034408</td>\n",
       "      <td>-0.062026</td>\n",
       "      <td>-0.046449</td>\n",
       "      <td>-0.048330</td>\n",
       "      <td>-0.052812</td>\n",
       "      <td>-0.046505</td>\n",
       "      <td>-0.047448</td>\n",
       "      <td>-0.050360</td>\n",
       "      <td>-0.054316</td>\n",
       "      <td>-0.072453</td>\n",
       "      <td>-0.103961</td>\n",
       "      <td>-0.045912</td>\n",
       "      <td>-0.046200</td>\n",
       "      <td>-0.048395</td>\n",
       "      <td>-0.025413</td>\n",
       "      <td>-0.042559</td>\n",
       "      <td>-0.045907</td>\n",
       "      <td>-0.044965</td>\n",
       "      <td>-0.044821</td>\n",
       "      <td>-0.038360</td>\n",
       "      <td>-0.035178</td>\n",
       "      <td>-0.031147</td>\n",
       "      <td>-0.043223</td>\n",
       "      <td>-0.019790</td>\n",
       "      <td>-0.006004</td>\n",
       "      <td>-0.011291</td>\n",
       "      <td>-0.031064</td>\n",
       "      <td>-0.088067</td>\n",
       "      <td>-0.042693</td>\n",
       "      <td>-0.045985</td>\n",
       "      <td>-0.042420</td>\n",
       "      <td>-0.092956</td>\n",
       "      <td>-0.042367</td>\n",
       "      <td>-0.043166</td>\n",
       "      <td>-0.042317</td>\n",
       "      <td>-0.042350</td>\n",
       "      <td>-0.036751</td>\n",
       "      <td>-0.042475</td>\n",
       "      <td>-0.190386</td>\n",
       "      <td>-0.038266</td>\n",
       "      <td>-0.042464</td>\n",
       "      <td>-0.042490</td>\n",
       "      <td>-0.042916</td>\n",
       "      <td>-0.042699</td>\n",
       "      <td>-0.042506</td>\n",
       "      <td>-0.043140</td>\n",
       "      <td>-0.043044</td>\n",
       "      <td>-0.027019</td>\n",
       "      <td>-0.042951</td>\n",
       "      <td>-0.042507</td>\n",
       "      <td>-0.042712</td>\n",
       "      <td>-0.042939</td>\n",
       "      <td>-0.093433</td>\n",
       "      <td>-0.074722</td>\n",
       "      <td>-0.107769</td>\n",
       "      <td>-0.042632</td>\n",
       "      <td>-0.175684</td>\n",
       "      <td>-0.041984</td>\n",
       "      <td>-0.042135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3348</th>\n",
       "      <td>-0.067412</td>\n",
       "      <td>-0.061063</td>\n",
       "      <td>-0.065377</td>\n",
       "      <td>-0.072642</td>\n",
       "      <td>-0.059981</td>\n",
       "      <td>-0.069799</td>\n",
       "      <td>-0.076021</td>\n",
       "      <td>-0.084756</td>\n",
       "      <td>-0.057754</td>\n",
       "      <td>-0.062580</td>\n",
       "      <td>-0.057136</td>\n",
       "      <td>-0.086424</td>\n",
       "      <td>-0.106696</td>\n",
       "      <td>-0.092505</td>\n",
       "      <td>-0.050864</td>\n",
       "      <td>-0.055153</td>\n",
       "      <td>-0.052740</td>\n",
       "      <td>-0.053051</td>\n",
       "      <td>-0.054930</td>\n",
       "      <td>-0.055487</td>\n",
       "      <td>-0.049480</td>\n",
       "      <td>-0.067051</td>\n",
       "      <td>-0.061938</td>\n",
       "      <td>-0.046122</td>\n",
       "      <td>-0.048242</td>\n",
       "      <td>-0.052724</td>\n",
       "      <td>-0.045609</td>\n",
       "      <td>-0.047360</td>\n",
       "      <td>-0.050033</td>\n",
       "      <td>-0.086321</td>\n",
       "      <td>-0.072366</td>\n",
       "      <td>-0.150021</td>\n",
       "      <td>-0.044724</td>\n",
       "      <td>-0.045012</td>\n",
       "      <td>-0.047207</td>\n",
       "      <td>-0.051256</td>\n",
       "      <td>-0.042149</td>\n",
       "      <td>-0.044718</td>\n",
       "      <td>-0.043775</td>\n",
       "      <td>-0.043632</td>\n",
       "      <td>-0.038269</td>\n",
       "      <td>-0.035046</td>\n",
       "      <td>-0.030550</td>\n",
       "      <td>-0.043133</td>\n",
       "      <td>-0.041166</td>\n",
       "      <td>-0.032186</td>\n",
       "      <td>-0.037465</td>\n",
       "      <td>-0.059173</td>\n",
       "      <td>-0.123722</td>\n",
       "      <td>-0.041544</td>\n",
       "      <td>-0.051522</td>\n",
       "      <td>-0.041328</td>\n",
       "      <td>-0.094719</td>\n",
       "      <td>-0.041139</td>\n",
       "      <td>-0.041987</td>\n",
       "      <td>-0.041088</td>\n",
       "      <td>-0.041122</td>\n",
       "      <td>-0.036621</td>\n",
       "      <td>-0.041247</td>\n",
       "      <td>-0.185175</td>\n",
       "      <td>-0.037235</td>\n",
       "      <td>-0.041372</td>\n",
       "      <td>-0.041375</td>\n",
       "      <td>-0.041736</td>\n",
       "      <td>-0.041550</td>\n",
       "      <td>-0.041278</td>\n",
       "      <td>-0.041946</td>\n",
       "      <td>-0.041864</td>\n",
       "      <td>-0.047294</td>\n",
       "      <td>-0.041772</td>\n",
       "      <td>-0.041279</td>\n",
       "      <td>-0.041553</td>\n",
       "      <td>-0.041745</td>\n",
       "      <td>-0.092869</td>\n",
       "      <td>-0.072353</td>\n",
       "      <td>-0.106154</td>\n",
       "      <td>-0.041846</td>\n",
       "      <td>-0.172977</td>\n",
       "      <td>-0.040755</td>\n",
       "      <td>-0.040907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      card_zip_total_7  card_zip_total_3  card_merch_total_7  \\\n",
       "3344          0.112875         -0.031600            0.114971   \n",
       "3345         -0.037276         -0.046003           -0.036790   \n",
       "3346         -0.014860         -0.008426           -0.012807   \n",
       "3347         -0.036940         -0.045667           -0.036454   \n",
       "3348         -0.067412         -0.061063           -0.065377   \n",
       "\n",
       "      card_merch_total_14  card_merch_total_3  card_state_total_3  \\\n",
       "3344             0.107300           -0.030513           -0.040389   \n",
       "3345            -0.027940           -0.046127           -0.054766   \n",
       "3346             0.139393           -0.007336            0.017240   \n",
       "3347            -0.027605           -0.045790           -0.054430   \n",
       "3348            -0.072642           -0.059981           -0.069799   \n",
       "\n",
       "      card_zip_total_14  card_state_total_7  card_zip_total_1  \\\n",
       "3344           0.103796            0.094687         -0.028245   \n",
       "3345          -0.028500           -0.054761         -0.058862   \n",
       "3346           0.135866            0.001894         -0.005037   \n",
       "3347          -0.028166           -0.054427         -0.058526   \n",
       "3348          -0.076021           -0.084756         -0.057754   \n",
       "\n",
       "      card_state_total_1  card_merch_total_1  card_merch_total_30  \\\n",
       "3344           -0.033101           -0.027625             0.092679   \n",
       "3345           -0.063686           -0.058245            -0.041930   \n",
       "3346           -0.009916           -0.004414             0.124622   \n",
       "3347           -0.063350           -0.057908            -0.041596   \n",
       "3348           -0.062580           -0.057136            -0.086424   \n",
       "\n",
       "      card_state_total_14  card_zip_total_30  card_zip_max_14  \\\n",
       "3344             0.071038           0.086288         0.045616   \n",
       "3345            -0.059726          -0.045255        -0.050952   \n",
       "3346             0.136753           0.118175         0.002802   \n",
       "3347            -0.059395          -0.044922        -0.050952   \n",
       "3348            -0.106696          -0.092505        -0.050864   \n",
       "\n",
       "      card_state_total_0  card_merch_total_0  card_zip_total_0  \\\n",
       "3344           -0.024397           -0.021971         -0.022283   \n",
       "3345           -0.056308           -0.053896         -0.054206   \n",
       "3346           -0.030364           -0.027941         -0.028252   \n",
       "3347           -0.055957           -0.053545         -0.053855   \n",
       "3348           -0.055153           -0.052740         -0.053051   \n",
       "\n",
       "      card_zip_max_30  card_state_max_7  card_merch_max_14  Cardnum_total_3  \\\n",
       "3344         0.041519          0.040925           0.047012         0.010302   \n",
       "3345        -0.055018         -0.055574          -0.049568        -0.034552   \n",
       "3346        -0.001281         -0.020029           0.004193         0.268160   \n",
       "3347        -0.055018         -0.055574          -0.049568        -0.034408   \n",
       "3348        -0.054930         -0.055487          -0.049480        -0.067051   \n",
       "\n",
       "      card_state_max_14  card_zip_max_3  card_zip_max_7  card_merch_max_30  \\\n",
       "3344           0.034400       -0.014476        0.048263           0.043745   \n",
       "3345          -0.062026       -0.046449       -0.048330          -0.052812   \n",
       "3346          -0.008351       -0.019937       -0.022060           0.000936   \n",
       "3347          -0.062026       -0.046449       -0.048330          -0.052812   \n",
       "3348          -0.061938       -0.046122       -0.048242          -0.052724   \n",
       "\n",
       "      card_merch_max_3  card_merch_max_7  card_state_max_3  Cardnum_total_7  \\\n",
       "3344         -0.013962          0.049151         -0.018398         0.029839   \n",
       "3345         -0.046505         -0.047448         -0.050360        -0.054434   \n",
       "3346         -0.019423         -0.021177         -0.014550         0.227464   \n",
       "3347         -0.046505         -0.047448         -0.050360        -0.054316   \n",
       "3348         -0.045609         -0.047360         -0.050033        -0.086321   \n",
       "\n",
       "      card_state_max_30  card_state_total_30  card_merch_max_1  \\\n",
       "3344           0.023843             0.023048         -0.013076   \n",
       "3345          -0.072453            -0.104284         -0.045912   \n",
       "3346          -0.018850             0.087038         -0.018538   \n",
       "3347          -0.072453            -0.103961         -0.045912   \n",
       "3348          -0.072366            -0.150021         -0.044724   \n",
       "\n",
       "      card_zip_max_1  card_state_max_1  Cardnum_total_1  Cardnum_total_0  \\\n",
       "3344       -0.013364         -0.015564         0.009931        -0.026477   \n",
       "3345       -0.046200         -0.048395        -0.025558        -0.042738   \n",
       "3346       -0.018825         -0.021025         0.063876        -0.029518   \n",
       "3347       -0.046200         -0.048395        -0.025413        -0.042559   \n",
       "3348       -0.045012         -0.047207        -0.051256        -0.042149   \n",
       "\n",
       "      card_state_max_0  card_zip_max_0  card_merch_max_0  Merchnum_total_0  \\\n",
       "3344         -0.013049       -0.012105         -0.011960         -0.034782   \n",
       "3345         -0.045907       -0.044965         -0.044821         -0.038400   \n",
       "3346         -0.019193       -0.018249         -0.018105         -0.035458   \n",
       "3347         -0.045907       -0.044965         -0.044821         -0.038360   \n",
       "3348         -0.044718       -0.043775         -0.043632         -0.038269   \n",
       "\n",
       "      Merchnum_max_0  Cardnum_max_0  Merchnum_total_1  Cardnum_max_7  \\\n",
       "3344       -0.031554      -0.014666         -0.039690      -0.008867   \n",
       "3345       -0.035178      -0.031147         -0.043263      -0.019790   \n",
       "3346       -0.032231      -0.017747         -0.036982       0.040827   \n",
       "3347       -0.035178      -0.031147         -0.043223      -0.019790   \n",
       "3348       -0.035046      -0.030550         -0.043133      -0.041166   \n",
       "\n",
       "      Cardnum_max_1  Cardnum_max_3  Cardnum_avg_1  Cardnum_total_14  \\\n",
       "3344       0.005197      -0.000092       0.009414          0.130810   \n",
       "3345      -0.006004      -0.011291      -0.016142         -0.088177   \n",
       "3346       0.023602       0.062933      -0.004577          0.325432   \n",
       "3347      -0.006004      -0.011291      -0.031064         -0.088067   \n",
       "3348      -0.032186      -0.037465      -0.059173         -0.123722   \n",
       "\n",
       "      card_state_avg_7  Merchnum_total_3  card_state_avg_3  Cardnum_avg_3  \\\n",
       "3344          0.022171         -0.042657         -0.009612      -0.034008   \n",
       "3345         -0.042691         -0.046018         -0.042415      -0.092819   \n",
       "3346         -0.019297         -0.047441         -0.019083       0.040300   \n",
       "3347         -0.042693         -0.045985         -0.042420      -0.092956   \n",
       "3348         -0.041544         -0.051522         -0.041328      -0.094719   \n",
       "\n",
       "      card_merch_avg_0  card_zip_avg_30  card_state_avg_0  card_zip_avg_0  \\\n",
       "3344         -0.009430         0.021718         -0.009377       -0.009413   \n",
       "3345         -0.042330        -0.043165         -0.042279       -0.042313   \n",
       "3346         -0.015582        -0.017985         -0.015530       -0.015565   \n",
       "3347         -0.042367        -0.043166         -0.042317       -0.042350   \n",
       "3348         -0.041139        -0.041987         -0.041088       -0.041122   \n",
       "\n",
       "      Merchnum_max_1  card_state_avg_1  Merchnum_avg_0  Cardnum_avg_0  \\\n",
       "3344       -0.033170         -0.009535       -0.050635      -0.010625   \n",
       "3345       -0.036751         -0.042437       -0.190227      -0.038234   \n",
       "3346       -0.033765         -0.023447       -0.076738      -0.015788   \n",
       "3347       -0.036751         -0.042475       -0.190386      -0.038266   \n",
       "3348       -0.036621         -0.041247       -0.185175      -0.037235   \n",
       "\n",
       "      card_zip_avg_3  card_merch_avg_3  card_state_avg_14  card_zip_avg_7  \\\n",
       "3344       -0.009662         -0.009666           0.021988        0.022148   \n",
       "3345       -0.042459         -0.042486          -0.042915       -0.042697   \n",
       "3346       -0.023574         -0.023577          -0.016570       -0.023751   \n",
       "3347       -0.042464         -0.042490          -0.042916       -0.042699   \n",
       "3348       -0.041372         -0.041375          -0.041736       -0.041550   \n",
       "\n",
       "      card_zip_avg_1  card_merch_avg_30  card_state_avg_30  Cardnum_max_14  \\\n",
       "3344       -0.009569           0.021754           0.021880        0.002652   \n",
       "3345       -0.042469          -0.043140          -0.043044       -0.027019   \n",
       "3346       -0.023481          -0.017946          -0.016690        0.030477   \n",
       "3347       -0.042506          -0.043140          -0.043044       -0.027019   \n",
       "3348       -0.041278          -0.041946          -0.041864       -0.047294   \n",
       "\n",
       "      card_zip_avg_14  card_merch_avg_1  card_merch_avg_7  card_merch_avg_14  \\\n",
       "3344         0.021928         -0.009571          0.022143           0.021953   \n",
       "3345        -0.042951         -0.042470         -0.042711          -0.042938   \n",
       "3346        -0.017772         -0.023482         -0.023755          -0.017746   \n",
       "3347        -0.042951         -0.042507         -0.042712          -0.042939   \n",
       "3348        -0.041772         -0.041279         -0.041553          -0.041745   \n",
       "\n",
       "      Cardnum_avg_7  Cardnum_med_1  Cardnum_avg_14  Merchnum_max_3  \\\n",
       "3344      -0.008515      -0.009277       -0.008777       -0.039859   \n",
       "3345      -0.093402      -0.009880       -0.107756       -0.042632   \n",
       "3346       0.028950      -0.021515        0.003608       -0.040354   \n",
       "3347      -0.093433      -0.074722       -0.107769       -0.042632   \n",
       "3348      -0.092869      -0.072353       -0.106154       -0.041846   \n",
       "\n",
       "      Cardnum_avg_30  card_state_med_0  card_merch_med_0  \n",
       "3344       -0.009776         -0.009043         -0.009197  \n",
       "3345       -0.175662         -0.041946         -0.042098  \n",
       "3346        0.010980         -0.015195         -0.015349  \n",
       "3347       -0.175684         -0.041984         -0.042135  \n",
       "3348       -0.172977         -0.040755         -0.040907  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 80 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 79 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 78 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 77 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 76 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 75 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 74 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 73 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 72 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 71 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 70 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 69 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 68 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 67 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 66 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 65 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 64 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 63 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 62 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 61 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 60 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 59 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 58 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 57 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 56 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 55 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 54 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 53 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 52 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 51 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 50 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 49 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 48 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 47 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 46 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 45 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 44 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 43 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 42 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 41 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 40 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 39 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 38 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 37 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 36 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 35 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 34 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 33 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 32 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 31 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 30 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 29 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 28 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 27 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 26 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFECV(cv=2,\n",
       "      estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                   fit_intercept=True, intercept_scaling=1,\n",
       "                                   l1_ratio=None, max_iter=100,\n",
       "                                   multi_class='auto', n_jobs=None,\n",
       "                                   penalty='l2', random_state=None,\n",
       "                                   solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                   warm_start=False),\n",
       "      min_features_to_select=1, n_jobs=-1, scoring='roc_auc', step=1,\n",
       "      verbose=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "rfecv = RFECV(estimator = model, step = 1, cv = 2, verbose = 2, n_jobs = -1, scoring = 'roc_auc')\n",
    "rfecv.fit(wrapdata, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_avg_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_max_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_total_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_max_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_max_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_total_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_total_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>card_merch_avg_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>card_merch_max_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_avg_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_avg_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_max_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_med_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_total_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>card_zip_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>card_zip_avg_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>card_zip_max_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>card_zip_total_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>Cardnum_avg_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>Cardnum_avg_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>card_state_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>card_zip_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td>card_merch_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7</td>\n",
       "      <td>card_zip_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>card_zip_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9</td>\n",
       "      <td>Cardnum_med_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10</td>\n",
       "      <td>card_merch_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>11</td>\n",
       "      <td>card_state_max_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>12</td>\n",
       "      <td>card_merch_avg_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>13</td>\n",
       "      <td>card_merch_avg_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>14</td>\n",
       "      <td>Cardnum_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>15</td>\n",
       "      <td>Merchnum_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>16</td>\n",
       "      <td>card_merch_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>17</td>\n",
       "      <td>card_merch_avg_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>18</td>\n",
       "      <td>Cardnum_max_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>19</td>\n",
       "      <td>Cardnum_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20</td>\n",
       "      <td>Cardnum_total_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>21</td>\n",
       "      <td>Cardnum_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>22</td>\n",
       "      <td>Cardnum_max_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>23</td>\n",
       "      <td>card_state_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>24</td>\n",
       "      <td>card_zip_max_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>25</td>\n",
       "      <td>card_merch_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>26</td>\n",
       "      <td>card_merch_total_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>27</td>\n",
       "      <td>card_merch_total_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>28</td>\n",
       "      <td>card_state_avg_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>29</td>\n",
       "      <td>card_state_max_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>30</td>\n",
       "      <td>card_merch_max_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>31</td>\n",
       "      <td>card_zip_max_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>32</td>\n",
       "      <td>card_state_avg_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>33</td>\n",
       "      <td>card_zip_total_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>34</td>\n",
       "      <td>card_zip_total_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>35</td>\n",
       "      <td>card_state_avg_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>36</td>\n",
       "      <td>card_merch_total_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>37</td>\n",
       "      <td>card_state_max_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>38</td>\n",
       "      <td>card_merch_avg_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>39</td>\n",
       "      <td>card_merch_max_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>40</td>\n",
       "      <td>card_merch_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>41</td>\n",
       "      <td>card_state_total_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>42</td>\n",
       "      <td>card_merch_med_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>43</td>\n",
       "      <td>card_zip_avg_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>44</td>\n",
       "      <td>Cardnum_total_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>45</td>\n",
       "      <td>card_zip_total_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>46</td>\n",
       "      <td>Cardnum_avg_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>47</td>\n",
       "      <td>Cardnum_avg_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>48</td>\n",
       "      <td>card_merch_total_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>49</td>\n",
       "      <td>card_state_total_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>50</td>\n",
       "      <td>card_zip_avg_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>51</td>\n",
       "      <td>card_merch_max_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>52</td>\n",
       "      <td>card_zip_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>53</td>\n",
       "      <td>card_zip_avg_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>54</td>\n",
       "      <td>card_zip_max_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>55</td>\n",
       "      <td>card_zip_avg_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>56</td>\n",
       "      <td>card_state_total_7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ranking             variable\n",
       "0         1        Cardnum_avg_3\n",
       "1         1        Cardnum_max_0\n",
       "2         1        Cardnum_max_1\n",
       "3         1      Cardnum_total_0\n",
       "4         1      Cardnum_total_1\n",
       "5         1       Merchnum_max_0\n",
       "6         1       Merchnum_max_1\n",
       "7         1       Merchnum_max_3\n",
       "8         1     Merchnum_total_0\n",
       "9         1     Merchnum_total_1\n",
       "10        1     Merchnum_total_3\n",
       "11        1    card_merch_avg_14\n",
       "12        1    card_merch_max_30\n",
       "13        1     card_state_avg_0\n",
       "14        1    card_state_avg_14\n",
       "15        1     card_state_avg_7\n",
       "16        1     card_state_max_1\n",
       "17        1    card_state_max_14\n",
       "18        1     card_state_max_7\n",
       "19        1     card_state_med_0\n",
       "20        1   card_state_total_3\n",
       "21        1       card_zip_avg_0\n",
       "22        1      card_zip_avg_14\n",
       "23        1      card_zip_max_30\n",
       "24        1    card_zip_total_30\n",
       "25        2       Cardnum_avg_14\n",
       "26        3       Cardnum_avg_30\n",
       "27        4   card_state_total_0\n",
       "28        5    card_zip_total_14\n",
       "29        6  card_merch_total_14\n",
       "30        7       card_zip_max_7\n",
       "31        8       card_zip_max_1\n",
       "32        9        Cardnum_med_1\n",
       "33       10     card_merch_max_7\n",
       "34       11     card_state_max_0\n",
       "35       12     card_merch_avg_7\n",
       "36       13     card_merch_avg_3\n",
       "37       14        Cardnum_avg_0\n",
       "38       15       Merchnum_avg_0\n",
       "39       16     card_merch_avg_0\n",
       "40       17    card_merch_avg_30\n",
       "41       18        Cardnum_max_3\n",
       "42       19        Cardnum_max_7\n",
       "43       20      Cardnum_total_7\n",
       "44       21     Cardnum_total_14\n",
       "45       22       Cardnum_max_14\n",
       "46       23  card_state_total_14\n",
       "47       24       card_zip_max_3\n",
       "48       25     card_merch_max_1\n",
       "49       26   card_merch_total_1\n",
       "50       27   card_merch_total_7\n",
       "51       28     card_state_avg_3\n",
       "52       29    card_state_max_30\n",
       "53       30     card_merch_max_3\n",
       "54       31       card_zip_max_0\n",
       "55       32     card_state_avg_1\n",
       "56       33     card_zip_total_1\n",
       "57       34     card_zip_total_3\n",
       "58       35    card_state_avg_30\n",
       "59       36  card_merch_total_30\n",
       "60       37     card_state_max_3\n",
       "61       38     card_merch_avg_1\n",
       "62       39     card_merch_max_0\n",
       "63       40   card_merch_total_0\n",
       "64       41   card_state_total_1\n",
       "65       42     card_merch_med_0\n",
       "66       43      card_zip_avg_30\n",
       "67       44      Cardnum_total_3\n",
       "68       45     card_zip_total_7\n",
       "69       46        Cardnum_avg_1\n",
       "70       47        Cardnum_avg_7\n",
       "71       48   card_merch_total_3\n",
       "72       49  card_state_total_30\n",
       "73       50       card_zip_avg_1\n",
       "74       51    card_merch_max_14\n",
       "75       52     card_zip_total_0\n",
       "76       53       card_zip_avg_7\n",
       "77       54      card_zip_max_14\n",
       "78       55       card_zip_avg_3\n",
       "79       56   card_state_total_7"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_selected = pd.DataFrame(sorted(zip(map(lambda x: round(x), rfecv.ranking_), wrapdata.columns)), columns = ['ranking', 'variable'])\n",
    "var_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_avg_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_max_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_total_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_max_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_max_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_total_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_total_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>card_merch_avg_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>card_merch_max_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_avg_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_avg_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_max_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_med_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_total_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>card_zip_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>card_zip_avg_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>card_zip_max_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>card_zip_total_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>Cardnum_avg_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>Cardnum_avg_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>card_state_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>card_zip_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td>card_merch_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7</td>\n",
       "      <td>card_zip_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>card_zip_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9</td>\n",
       "      <td>Cardnum_med_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10</td>\n",
       "      <td>card_merch_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>11</td>\n",
       "      <td>card_state_max_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>12</td>\n",
       "      <td>card_merch_avg_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>13</td>\n",
       "      <td>card_merch_avg_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>14</td>\n",
       "      <td>Cardnum_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>15</td>\n",
       "      <td>Merchnum_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>16</td>\n",
       "      <td>card_merch_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>17</td>\n",
       "      <td>card_merch_avg_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>18</td>\n",
       "      <td>Cardnum_max_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>19</td>\n",
       "      <td>Cardnum_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20</td>\n",
       "      <td>Cardnum_total_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>21</td>\n",
       "      <td>Cardnum_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>22</td>\n",
       "      <td>Cardnum_max_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>23</td>\n",
       "      <td>card_state_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>24</td>\n",
       "      <td>card_zip_max_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>25</td>\n",
       "      <td>card_merch_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>26</td>\n",
       "      <td>card_merch_total_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ranking             variable\n",
       "0         1        Cardnum_avg_3\n",
       "1         1        Cardnum_max_0\n",
       "2         1        Cardnum_max_1\n",
       "3         1      Cardnum_total_0\n",
       "4         1      Cardnum_total_1\n",
       "5         1       Merchnum_max_0\n",
       "6         1       Merchnum_max_1\n",
       "7         1       Merchnum_max_3\n",
       "8         1     Merchnum_total_0\n",
       "9         1     Merchnum_total_1\n",
       "10        1     Merchnum_total_3\n",
       "11        1    card_merch_avg_14\n",
       "12        1    card_merch_max_30\n",
       "13        1     card_state_avg_0\n",
       "14        1    card_state_avg_14\n",
       "15        1     card_state_avg_7\n",
       "16        1     card_state_max_1\n",
       "17        1    card_state_max_14\n",
       "18        1     card_state_max_7\n",
       "19        1     card_state_med_0\n",
       "20        1   card_state_total_3\n",
       "21        1       card_zip_avg_0\n",
       "22        1      card_zip_avg_14\n",
       "23        1      card_zip_max_30\n",
       "24        1    card_zip_total_30\n",
       "25        2       Cardnum_avg_14\n",
       "26        3       Cardnum_avg_30\n",
       "27        4   card_state_total_0\n",
       "28        5    card_zip_total_14\n",
       "29        6  card_merch_total_14\n",
       "30        7       card_zip_max_7\n",
       "31        8       card_zip_max_1\n",
       "32        9        Cardnum_med_1\n",
       "33       10     card_merch_max_7\n",
       "34       11     card_state_max_0\n",
       "35       12     card_merch_avg_7\n",
       "36       13     card_merch_avg_3\n",
       "37       14        Cardnum_avg_0\n",
       "38       15       Merchnum_avg_0\n",
       "39       16     card_merch_avg_0\n",
       "40       17    card_merch_avg_30\n",
       "41       18        Cardnum_max_3\n",
       "42       19        Cardnum_max_7\n",
       "43       20      Cardnum_total_7\n",
       "44       21     Cardnum_total_14\n",
       "45       22       Cardnum_max_14\n",
       "46       23  card_state_total_14\n",
       "47       24       card_zip_max_3\n",
       "48       25     card_merch_max_1\n",
       "49       26   card_merch_total_1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_selected_top50 = var_selected.head(50)\n",
    "var_selected_top50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "varTop50List = var_selected_top50['variable'].tolist()\n",
    "wrapdata2nd = newdata[varTop50List]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 50 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 49 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 48 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 47 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 46 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 45 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 44 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 43 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 42 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 41 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 40 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 39 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 38 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 37 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 36 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 35 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 34 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 33 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 32 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 31 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 30 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 29 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 28 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 27 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 26 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 25 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 24 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 23 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 22 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFECV(cv=2,\n",
       "      estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                   fit_intercept=True, intercept_scaling=1,\n",
       "                                   l1_ratio=None, max_iter=100,\n",
       "                                   multi_class='auto', n_jobs=None,\n",
       "                                   penalty='l2', random_state=None,\n",
       "                                   solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                   warm_start=False),\n",
       "      min_features_to_select=1, n_jobs=-1, scoring='roc_auc', step=1,\n",
       "      verbose=2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.fit(wrapdata2nd, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_avg_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_max_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_max_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_max_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_total_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_total_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>card_merch_avg_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>card_merch_max_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_avg_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_avg_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_max_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_total_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>card_zip_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>card_zip_max_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>card_zip_total_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>card_zip_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>Cardnum_total_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>card_state_med_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>card_zip_avg_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>card_state_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>card_zip_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8</td>\n",
       "      <td>card_zip_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9</td>\n",
       "      <td>card_merch_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>Cardnum_avg_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>11</td>\n",
       "      <td>Cardnum_avg_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12</td>\n",
       "      <td>card_state_max_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>13</td>\n",
       "      <td>Cardnum_med_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>14</td>\n",
       "      <td>card_merch_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>15</td>\n",
       "      <td>card_merch_avg_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16</td>\n",
       "      <td>Cardnum_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>17</td>\n",
       "      <td>card_merch_avg_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18</td>\n",
       "      <td>Merchnum_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>19</td>\n",
       "      <td>card_state_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20</td>\n",
       "      <td>card_merch_avg_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>21</td>\n",
       "      <td>Cardnum_max_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>22</td>\n",
       "      <td>Cardnum_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23</td>\n",
       "      <td>Cardnum_total_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>24</td>\n",
       "      <td>Cardnum_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>25</td>\n",
       "      <td>Cardnum_max_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>26</td>\n",
       "      <td>card_state_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>27</td>\n",
       "      <td>card_merch_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>28</td>\n",
       "      <td>card_zip_max_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>29</td>\n",
       "      <td>card_merch_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>30</td>\n",
       "      <td>card_merch_total_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ranking             variable\n",
       "0         1        Cardnum_avg_3\n",
       "1         1        Cardnum_max_0\n",
       "2         1        Cardnum_max_1\n",
       "3         1      Cardnum_total_0\n",
       "4         1       Merchnum_max_0\n",
       "5         1       Merchnum_max_1\n",
       "6         1       Merchnum_max_3\n",
       "7         1     Merchnum_total_0\n",
       "8         1     Merchnum_total_1\n",
       "9         1     Merchnum_total_3\n",
       "10        1    card_merch_avg_14\n",
       "11        1    card_merch_max_30\n",
       "12        1     card_state_avg_0\n",
       "13        1    card_state_avg_14\n",
       "14        1     card_state_avg_7\n",
       "15        1     card_state_max_1\n",
       "16        1    card_state_max_14\n",
       "17        1   card_state_total_3\n",
       "18        1       card_zip_avg_0\n",
       "19        1      card_zip_max_30\n",
       "20        1    card_zip_total_30\n",
       "21        2       card_zip_max_7\n",
       "22        3      Cardnum_total_1\n",
       "23        4     card_state_med_0\n",
       "24        5      card_zip_avg_14\n",
       "25        6     card_state_max_7\n",
       "26        7       card_zip_max_1\n",
       "27        8    card_zip_total_14\n",
       "28        9  card_merch_total_14\n",
       "29       10       Cardnum_avg_14\n",
       "30       11       Cardnum_avg_30\n",
       "31       12     card_state_max_0\n",
       "32       13        Cardnum_med_1\n",
       "33       14     card_merch_max_7\n",
       "34       15     card_merch_avg_7\n",
       "35       16        Cardnum_avg_0\n",
       "36       17     card_merch_avg_3\n",
       "37       18       Merchnum_avg_0\n",
       "38       19  card_state_total_14\n",
       "39       20    card_merch_avg_30\n",
       "40       21        Cardnum_max_3\n",
       "41       22     Cardnum_total_14\n",
       "42       23      Cardnum_total_7\n",
       "43       24        Cardnum_max_7\n",
       "44       25       Cardnum_max_14\n",
       "45       26   card_state_total_0\n",
       "46       27     card_merch_avg_0\n",
       "47       28       card_zip_max_3\n",
       "48       29     card_merch_max_1\n",
       "49       30   card_merch_total_1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_selected_2nd = pd.DataFrame(sorted(zip(map(lambda x: round(x), rfecv.ranking_), wrapdata2nd.columns)), columns = ['ranking', 'variable'])\n",
    "var_selected_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "top30Var = var_selected_2nd.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_avg_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_max_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardnum_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_max_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_max_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_total_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_total_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Merchnum_total_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>card_merch_avg_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>card_merch_max_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_avg_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_avg_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_max_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>card_state_total_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>card_zip_avg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>card_zip_max_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>card_zip_total_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>card_zip_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>Cardnum_total_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>card_state_med_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>card_zip_avg_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>card_state_max_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>card_zip_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8</td>\n",
       "      <td>card_zip_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9</td>\n",
       "      <td>card_merch_total_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>Cardnum_avg_14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ranking             variable\n",
       "0         1        Cardnum_avg_3\n",
       "1         1        Cardnum_max_0\n",
       "2         1        Cardnum_max_1\n",
       "3         1      Cardnum_total_0\n",
       "4         1       Merchnum_max_0\n",
       "5         1       Merchnum_max_1\n",
       "6         1       Merchnum_max_3\n",
       "7         1     Merchnum_total_0\n",
       "8         1     Merchnum_total_1\n",
       "9         1     Merchnum_total_3\n",
       "10        1    card_merch_avg_14\n",
       "11        1    card_merch_max_30\n",
       "12        1     card_state_avg_0\n",
       "13        1    card_state_avg_14\n",
       "14        1     card_state_avg_7\n",
       "15        1     card_state_max_1\n",
       "16        1    card_state_max_14\n",
       "17        1   card_state_total_3\n",
       "18        1       card_zip_avg_0\n",
       "19        1      card_zip_max_30\n",
       "20        1    card_zip_total_30\n",
       "21        2       card_zip_max_7\n",
       "22        3      Cardnum_total_1\n",
       "23        4     card_state_med_0\n",
       "24        5      card_zip_avg_14\n",
       "25        6     card_state_max_7\n",
       "26        7       card_zip_max_1\n",
       "27        8    card_zip_total_14\n",
       "28        9  card_merch_total_14\n",
       "29       10       Cardnum_avg_14"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top30Var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a baseline linear model (logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "top30VarList = top30Var['variable'].tolist()\n",
    "x_trntst = newdata[top30VarList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trntst = pd.DataFrame(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "ootDF = mydata_newV.loc[(mydata_newV['Date'] >= dt.datetime.strptime('2010-11-01', \"%Y-%m-%d\")) & (mydata_newV['Date'] <= dt.datetime.strptime('2010-12-31', \"%Y-%m-%d\"))]\n",
    "X_oot = ootDF[top30VarList]\n",
    "Y_oot = pd.DataFrame(ootDF.Fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial 1: max_iter = 1000, other hyperparameters are default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "nitermax = 10\n",
    "FDR_trn_hyper1 = []\n",
    "FDR_tst_hyper1 = []\n",
    "FDR_oot_hyper1 = []\n",
    "for niter in range(nitermax):\n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(x_trntst, y_trntst, test_size = 0.3)\n",
    "    clf = LogisticRegression(max_iter = 1000).fit(X_trn, Y_trn)\n",
    "    \n",
    "    ## FDR on the training set\n",
    "    probOf1_trn = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_trn)).loc[:, 1])\n",
    "    probFraud_trn = pd.concat([probOf1_trn, Y_trn.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_trn = int(round(len(X_trn) * 0.03))\n",
    "    temp_trn = probFraud_trn.head(topRows_trn)\n",
    "    needed_trn = temp_trn.loc[:, 'Fraud']\n",
    "    bads_trn = probFraud_trn.loc[(probFraud_trn.Fraud == 1)]\n",
    "    FDR_trn = sum(needed_trn) / bads_trn.shape[0]\n",
    "    FDR_trn_hyper1.append(FDR_trn)\n",
    "    \n",
    "    ## FDR on the test set\n",
    "    probOf1_tst = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_tst)).loc[:, 1])\n",
    "    probFraud_tst = pd.concat([probOf1_tst, Y_tst.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_tst = int(round(len(X_tst) * 0.03))\n",
    "    temp_tst = probFraud_tst.head(topRows_tst)\n",
    "    needed_tst = temp_tst.loc[:, 'Fraud']\n",
    "    bads_tst = probFraud_tst.loc[(probFraud_tst.Fraud == 1)]\n",
    "    FDR_tst = sum(needed_tst) / bads_tst.shape[0]\n",
    "    FDR_tst_hyper1.append(FDR_tst)\n",
    "    \n",
    "    ## FDR on the OOT set\n",
    "    probOf1_oot = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_oot)).loc[:, 1])\n",
    "    probFraud_oot = pd.concat([probOf1_oot, Y_oot.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_oot = int(round(len(X_oot) * 0.03))\n",
    "    temp_oot = probFraud_oot.head(topRows_oot)\n",
    "    needed_oot = temp_oot.loc[:, 'Fraud']\n",
    "    bads_oot = probFraud_oot.loc[(probFraud_oot.Fraud == 1)]\n",
    "    FDR_oot = sum(needed_oot) / bads_oot.shape[0]\n",
    "    FDR_oot_hyper1.append(FDR_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6921824104234527,\n",
       " 0.6728187919463087,\n",
       " 0.6866666666666666,\n",
       " 0.6704918032786885,\n",
       " 0.6632825719120136,\n",
       " 0.6710310965630114,\n",
       " 0.6979522184300341,\n",
       " 0.6683673469387755,\n",
       " 0.6728499156829679,\n",
       " 0.6700507614213198]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_trn_hyper1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6765693583263238"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_trn_hyper1)/len(FDR_trn_hyper1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6535433070866141,\n",
       " 0.6727941176470589,\n",
       " 0.6492537313432836,\n",
       " 0.6666666666666666,\n",
       " 0.7075812274368231,\n",
       " 0.7042801556420234,\n",
       " 0.6418439716312057,\n",
       " 0.7,\n",
       " 0.6690909090909091,\n",
       " 0.7075812274368231]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_tst_hyper1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6772635313981408"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_tst_hyper1)/len(FDR_tst_hyper1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3575418994413408,\n",
       " 0.329608938547486,\n",
       " 0.3575418994413408,\n",
       " 0.329608938547486,\n",
       " 0.3407821229050279,\n",
       " 0.3854748603351955,\n",
       " 0.3407821229050279,\n",
       " 0.3240223463687151,\n",
       " 0.3743016759776536,\n",
       " 0.329608938547486]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_oot_hyper1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3469273743016759"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_oot_hyper1)/len(FDR_oot_hyper1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial 2: max_iter = 1000, class_weight = 'balanced', other hyperparameters are default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "nitermax = 10\n",
    "FDR_trn_hyper2 = []\n",
    "FDR_tst_hyper2 = []\n",
    "FDR_oot_hyper2 = []\n",
    "for niter in range(nitermax):\n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(x_trntst, y_trntst, test_size = 0.3)\n",
    "    clf = LogisticRegression(max_iter = 1000, class_weight = 'balanced').fit(X_trn, Y_trn)\n",
    "    \n",
    "    ## FDR on the training set\n",
    "    probOf1_trn = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_trn)).loc[:, 1])\n",
    "    probFraud_trn = pd.concat([probOf1_trn, Y_trn.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_trn = int(round(len(X_trn) * 0.03))\n",
    "    temp_trn = probFraud_trn.head(topRows_trn)\n",
    "    needed_trn = temp_trn.loc[:, 'Fraud']\n",
    "    bads_trn = probFraud_trn.loc[(probFraud_trn.Fraud == 1)]\n",
    "    FDR_trn = sum(needed_trn) / bads_trn.shape[0]\n",
    "    FDR_trn_hyper2.append(FDR_trn)\n",
    "    \n",
    "    ## FDR on the test set\n",
    "    probOf1_tst = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_tst)).loc[:, 1])\n",
    "    probFraud_tst = pd.concat([probOf1_tst, Y_tst.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_tst = int(round(len(X_tst) * 0.03))\n",
    "    temp_tst = probFraud_tst.head(topRows_tst)\n",
    "    needed_tst = temp_tst.loc[:, 'Fraud']\n",
    "    bads_tst = probFraud_tst.loc[(probFraud_tst.Fraud == 1)]\n",
    "    FDR_tst = sum(needed_tst) / bads_tst.shape[0]\n",
    "    FDR_tst_hyper2.append(FDR_tst)\n",
    "    \n",
    "    ## FDR on the OOT set\n",
    "    probOf1_oot = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_oot)).loc[:, 1])\n",
    "    probFraud_oot = pd.concat([probOf1_oot, Y_oot.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_oot = int(round(len(X_oot) * 0.03))\n",
    "    temp_oot = probFraud_oot.head(topRows_oot)\n",
    "    needed_oot = temp_oot.loc[:, 'Fraud']\n",
    "    bads_oot = probFraud_oot.loc[(probFraud_oot.Fraud == 1)]\n",
    "    FDR_oot = sum(needed_oot) / bads_oot.shape[0]\n",
    "    FDR_oot_hyper2.append(FDR_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6904761904761905,\n",
       " 0.7051070840197694,\n",
       " 0.6804635761589404,\n",
       " 0.6823338735818476,\n",
       " 0.6607431340872375,\n",
       " 0.6863057324840764,\n",
       " 0.6857638888888888,\n",
       " 0.6868686868686869,\n",
       " 0.7210440456769984,\n",
       " 0.7054908485856906]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_trn_hyper2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6904597060828326"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_trn_hyper2)/len(FDR_trn_hyper2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6890756302521008,\n",
       " 0.685823754789272,\n",
       " 0.7159090909090909,\n",
       " 0.7051792828685259,\n",
       " 0.7349397590361446,\n",
       " 0.6791666666666667,\n",
       " 0.6952054794520548,\n",
       " 0.6788321167883211,\n",
       " 0.6196078431372549,\n",
       " 0.6629213483146067]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_tst_hyper2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6866660972214038"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_tst_hyper2)/len(FDR_tst_hyper2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4245810055865922,\n",
       " 0.4301675977653631,\n",
       " 0.4301675977653631,\n",
       " 0.4301675977653631,\n",
       " 0.4134078212290503,\n",
       " 0.441340782122905,\n",
       " 0.4301675977653631,\n",
       " 0.3854748603351955,\n",
       " 0.41899441340782123,\n",
       " 0.41899441340782123]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_oot_hyper2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4223463687150838"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_oot_hyper2)/len(FDR_oot_hyper2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial 1: # of trees = 150, max_depth = 30, max_features = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "nitermax = 10\n",
    "FDR_trn_RF1 = []\n",
    "FDR_tst_RF1 = []\n",
    "FDR_oot_RF1 = []\n",
    "for niter in range(nitermax):\n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(x_trntst, y_trntst, test_size = 0.3)\n",
    "    clf = RandomForestClassifier(n_estimators=150, max_depth=30, max_features=20).fit(X_trn, Y_trn)\n",
    "    \n",
    "    ## FDR on the training set\n",
    "    probOf1_trn = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_trn)).loc[:, 1])\n",
    "    probFraud_trn = pd.concat([probOf1_trn, Y_trn.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_trn = int(round(len(X_trn) * 0.03))\n",
    "    temp_trn = probFraud_trn.head(topRows_trn)\n",
    "    needed_trn = temp_trn.loc[:, 'Fraud']\n",
    "    bads_trn = probFraud_trn.loc[(probFraud_trn.Fraud == 1)]\n",
    "    FDR_trn = sum(needed_trn) / bads_trn.shape[0]\n",
    "    FDR_trn_RF1.append(FDR_trn)\n",
    "    \n",
    "    ## FDR on the test set\n",
    "    probOf1_tst = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_tst)).loc[:, 1])\n",
    "    probFraud_tst = pd.concat([probOf1_tst, Y_tst.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_tst = int(round(len(X_tst) * 0.03))\n",
    "    temp_tst = probFraud_tst.head(topRows_tst)\n",
    "    needed_tst = temp_tst.loc[:, 'Fraud']\n",
    "    bads_tst = probFraud_tst.loc[(probFraud_tst.Fraud == 1)]\n",
    "    FDR_tst = sum(needed_tst) / bads_tst.shape[0]\n",
    "    FDR_tst_RF1.append(FDR_tst)\n",
    "    \n",
    "    ## FDR on the OOT set\n",
    "    probOf1_oot = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_oot)).loc[:, 1])\n",
    "    probFraud_oot = pd.concat([probOf1_oot, Y_oot.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_oot = int(round(len(X_oot) * 0.03))\n",
    "    temp_oot = probFraud_oot.head(topRows_oot)\n",
    "    needed_oot = temp_oot.loc[:, 'Fraud']\n",
    "    bads_oot = probFraud_oot.loc[(probFraud_oot.Fraud == 1)]\n",
    "    FDR_oot = sum(needed_oot) / bads_oot.shape[0]\n",
    "    FDR_oot_RF1.append(FDR_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_trn_RF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9053030303030303,\n",
       " 0.8941605839416058,\n",
       " 0.8912280701754386,\n",
       " 0.8929889298892989,\n",
       " 0.8773946360153256,\n",
       " 0.8847736625514403,\n",
       " 0.9047619047619048,\n",
       " 0.9188191881918819,\n",
       " 0.8645418326693227,\n",
       " 0.8846153846153846]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_tst_RF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8918587223114633"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_tst_RF1)/len(FDR_tst_RF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5363128491620112,\n",
       " 0.553072625698324,\n",
       " 0.5139664804469274,\n",
       " 0.5586592178770949,\n",
       " 0.553072625698324,\n",
       " 0.5586592178770949,\n",
       " 0.5307262569832403,\n",
       " 0.553072625698324,\n",
       " 0.5418994413407822,\n",
       " 0.5363128491620112]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_oot_RF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5435754189944134"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_oot_RF1)/len(FDR_oot_RF1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial 2: # of trees = 200, max_depth = 8, max_features = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "nitermax = 10\n",
    "FDR_trn_RF2 = []\n",
    "FDR_tst_RF2 = []\n",
    "FDR_oot_RF2 = []\n",
    "for niter in range(nitermax):\n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(x_trntst, y_trntst, test_size = 0.3)\n",
    "    clf = RandomForestClassifier(n_estimators=200, max_depth=8, max_features=5).fit(X_trn, Y_trn)\n",
    "    \n",
    "    ## FDR on the training set\n",
    "    probOf1_trn = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_trn)).loc[:, 1])\n",
    "    probFraud_trn = pd.concat([probOf1_trn, Y_trn.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_trn = int(round(len(X_trn) * 0.03))\n",
    "    temp_trn = probFraud_trn.head(topRows_trn)\n",
    "    needed_trn = temp_trn.loc[:, 'Fraud']\n",
    "    bads_trn = probFraud_trn.loc[(probFraud_trn.Fraud == 1)]\n",
    "    FDR_trn = sum(needed_trn) / bads_trn.shape[0]\n",
    "    FDR_trn_RF2.append(FDR_trn)\n",
    "    \n",
    "    ## FDR on the test set\n",
    "    probOf1_tst = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_tst)).loc[:, 1])\n",
    "    probFraud_tst = pd.concat([probOf1_tst, Y_tst.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_tst = int(round(len(X_tst) * 0.03))\n",
    "    temp_tst = probFraud_tst.head(topRows_tst)\n",
    "    needed_tst = temp_tst.loc[:, 'Fraud']\n",
    "    bads_tst = probFraud_tst.loc[(probFraud_tst.Fraud == 1)]\n",
    "    FDR_tst = sum(needed_tst) / bads_tst.shape[0]\n",
    "    FDR_tst_RF2.append(FDR_tst)\n",
    "    \n",
    "    ## FDR on the OOT set\n",
    "    probOf1_oot = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_oot)).loc[:, 1])\n",
    "    probFraud_oot = pd.concat([probOf1_oot, Y_oot.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_oot = int(round(len(X_oot) * 0.03))\n",
    "    temp_oot = probFraud_oot.head(topRows_oot)\n",
    "    needed_oot = temp_oot.loc[:, 'Fraud']\n",
    "    bads_oot = probFraud_oot.loc[(probFraud_oot.Fraud == 1)]\n",
    "    FDR_oot = sum(needed_oot) / bads_oot.shape[0]\n",
    "    FDR_oot_RF2.append(FDR_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8615635179153095,\n",
       " 0.8589951377633711,\n",
       " 0.8640132669983416,\n",
       " 0.8578512396694215,\n",
       " 0.8481421647819063,\n",
       " 0.8557213930348259,\n",
       " 0.8656716417910447,\n",
       " 0.8609715242881072,\n",
       " 0.8644338118022329,\n",
       " 0.8656716417910447]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_trn_RF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8603035339835605"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_trn_RF2)/len(FDR_trn_RF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8385826771653543,\n",
       " 0.8446215139442231,\n",
       " 0.8264150943396227,\n",
       " 0.8174904942965779,\n",
       " 0.8313253012048193,\n",
       " 0.8264150943396227,\n",
       " 0.8113207547169812,\n",
       " 0.8007380073800738,\n",
       " 0.7966804979253111,\n",
       " 0.7849056603773585]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_tst_RF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8178495095689945"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_tst_RF2)/len(FDR_tst_RF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5642458100558659,\n",
       " 0.5586592178770949,\n",
       " 0.5251396648044693,\n",
       " 0.553072625698324,\n",
       " 0.5642458100558659,\n",
       " 0.5418994413407822,\n",
       " 0.5307262569832403,\n",
       " 0.553072625698324,\n",
       " 0.5586592178770949,\n",
       " 0.5586592178770949]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_oot_RF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5508379888268156"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_oot_RF2)/len(FDR_oot_RF2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial 3: # of trees = 200, max_depth = 8, max_features = 5, class_weight = 'balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "nitermax = 10\n",
    "FDR_trn_RF3 = []\n",
    "FDR_tst_RF3 = []\n",
    "FDR_oot_RF3 = []\n",
    "for niter in range(nitermax):\n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(x_trntst, y_trntst, test_size = 0.3)\n",
    "    clf = RandomForestClassifier(n_estimators=200, max_depth=8, max_features=5, class_weight = 'balanced').fit(X_trn, Y_trn)\n",
    "    \n",
    "    ## FDR on the training set\n",
    "    probOf1_trn = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_trn)).loc[:, 1])\n",
    "    probFraud_trn = pd.concat([probOf1_trn, Y_trn.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_trn = int(round(len(X_trn) * 0.03))\n",
    "    temp_trn = probFraud_trn.head(topRows_trn)\n",
    "    needed_trn = temp_trn.loc[:, 'Fraud']\n",
    "    bads_trn = probFraud_trn.loc[(probFraud_trn.Fraud == 1)]\n",
    "    FDR_trn = sum(needed_trn) / bads_trn.shape[0]\n",
    "    FDR_trn_RF3.append(FDR_trn)\n",
    "    \n",
    "    ## FDR on the test set\n",
    "    probOf1_tst = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_tst)).loc[:, 1])\n",
    "    probFraud_tst = pd.concat([probOf1_tst, Y_tst.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_tst = int(round(len(X_tst) * 0.03))\n",
    "    temp_tst = probFraud_tst.head(topRows_tst)\n",
    "    needed_tst = temp_tst.loc[:, 'Fraud']\n",
    "    bads_tst = probFraud_tst.loc[(probFraud_tst.Fraud == 1)]\n",
    "    FDR_tst = sum(needed_tst) / bads_tst.shape[0]\n",
    "    FDR_tst_RF3.append(FDR_tst)\n",
    "    \n",
    "    ## FDR on the OOT set\n",
    "    probOf1_oot = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_oot)).loc[:, 1])\n",
    "    probFraud_oot = pd.concat([probOf1_oot, Y_oot.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_oot = int(round(len(X_oot) * 0.03))\n",
    "    temp_oot = probFraud_oot.head(topRows_oot)\n",
    "    needed_oot = temp_oot.loc[:, 'Fraud']\n",
    "    bads_oot = probFraud_oot.loc[(probFraud_oot.Fraud == 1)]\n",
    "    FDR_oot = sum(needed_oot) / bads_oot.shape[0]\n",
    "    FDR_oot_RF3.append(FDR_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9477124183006536,\n",
       " 0.945273631840796,\n",
       " 0.9515050167224081,\n",
       " 0.9624183006535948,\n",
       " 0.9492635024549918,\n",
       " 0.9508474576271186,\n",
       " 0.9420035149384886,\n",
       " 0.9532258064516129,\n",
       " 0.9596122778675282,\n",
       " 0.9579124579124579]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_trn_RF3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9519774384769653"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_trn_RF3)/len(FDR_trn_RF3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.80859375,\n",
       " 0.7924528301886793,\n",
       " 0.8185185185185185,\n",
       " 0.78125,\n",
       " 0.8404669260700389,\n",
       " 0.7877697841726619,\n",
       " 0.8662207357859532,\n",
       " 0.8266129032258065,\n",
       " 0.8112449799196787,\n",
       " 0.8248175182481752]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_tst_RF3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8157947946129512"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_tst_RF3)/len(FDR_tst_RF3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2905027932960894,\n",
       " 0.2905027932960894,\n",
       " 0.2905027932960894,\n",
       " 0.3128491620111732,\n",
       " 0.2905027932960894,\n",
       " 0.31843575418994413,\n",
       " 0.30726256983240224,\n",
       " 0.3016759776536313,\n",
       " 0.3240223463687151,\n",
       " 0.27932960893854747]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_oot_RF3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3005586592178771"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_oot_RF3)/len(FDR_oot_RF3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial 1: one layer, 4 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "nitermax = 10\n",
    "FDR_trn_NN1 = []\n",
    "FDR_tst_NN1 = []\n",
    "FDR_oot_NN1 = []\n",
    "for niter in range(nitermax):\n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(x_trntst, y_trntst, test_size = 0.3)\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(4)).fit(X_trn, Y_trn)\n",
    "    \n",
    "    ## FDR on the training set\n",
    "    probOf1_trn = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_trn)).loc[:, 1])\n",
    "    probFraud_trn = pd.concat([probOf1_trn, Y_trn.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_trn = int(round(len(X_trn) * 0.03))\n",
    "    temp_trn = probFraud_trn.head(topRows_trn)\n",
    "    needed_trn = temp_trn.loc[:, 'Fraud']\n",
    "    bads_trn = probFraud_trn.loc[(probFraud_trn.Fraud == 1)]\n",
    "    FDR_trn = sum(needed_trn) / bads_trn.shape[0]\n",
    "    FDR_trn_NN1.append(FDR_trn)\n",
    "    \n",
    "    ## FDR on the test set\n",
    "    probOf1_tst = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_tst)).loc[:, 1])\n",
    "    probFraud_tst = pd.concat([probOf1_tst, Y_tst.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_tst = int(round(len(X_tst) * 0.03))\n",
    "    temp_tst = probFraud_tst.head(topRows_tst)\n",
    "    needed_tst = temp_tst.loc[:, 'Fraud']\n",
    "    bads_tst = probFraud_tst.loc[(probFraud_tst.Fraud == 1)]\n",
    "    FDR_tst = sum(needed_tst) / bads_tst.shape[0]\n",
    "    FDR_tst_NN1.append(FDR_tst)\n",
    "    \n",
    "    ## FDR on the OOT set\n",
    "    probOf1_oot = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_oot)).loc[:, 1])\n",
    "    probFraud_oot = pd.concat([probOf1_oot, Y_oot.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_oot = int(round(len(X_oot) * 0.03))\n",
    "    temp_oot = probFraud_oot.head(topRows_oot)\n",
    "    needed_oot = temp_oot.loc[:, 'Fraud']\n",
    "    bads_oot = probFraud_oot.loc[(probFraud_oot.Fraud == 1)]\n",
    "    FDR_oot = sum(needed_oot) / bads_oot.shape[0]\n",
    "    FDR_oot_NN1.append(FDR_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6798107255520505,\n",
       " 0.6908212560386473,\n",
       " 0.7114754098360656,\n",
       " 0.6688524590163935,\n",
       " 0.6801948051948052,\n",
       " 0.6553398058252428,\n",
       " 0.7006920415224913,\n",
       " 0.6731391585760518,\n",
       " 0.6436974789915967,\n",
       " 0.6444805194805194]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_trn_NN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6748503660033865"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_trn_NN1)/len(FDR_trn_NN1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6581196581196581,\n",
       " 0.7206477732793523,\n",
       " 0.6627906976744186,\n",
       " 0.7325581395348837,\n",
       " 0.6904761904761905,\n",
       " 0.676,\n",
       " 0.6482758620689655,\n",
       " 0.664,\n",
       " 0.6483516483516484,\n",
       " 0.6626984126984127]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_tst_NN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6763918382203531"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_tst_NN1)/len(FDR_tst_NN1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3575418994413408,\n",
       " 0.3575418994413408,\n",
       " 0.441340782122905,\n",
       " 0.3687150837988827,\n",
       " 0.3575418994413408,\n",
       " 0.4301675977653631,\n",
       " 0.4245810055865922,\n",
       " 0.35195530726256985,\n",
       " 0.40782122905027934,\n",
       " 0.3575418994413408]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_oot_NN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38547486033519557"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_oot_NN1)/len(FDR_oot_NN1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial 2: one layer, 8 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "nitermax = 10\n",
    "FDR_trn_NN2 = []\n",
    "FDR_tst_NN2 = []\n",
    "FDR_oot_NN2 = []\n",
    "for niter in range(nitermax):\n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(x_trntst, y_trntst, test_size = 0.3)\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(8)).fit(X_trn, Y_trn)\n",
    "    \n",
    "    ## FDR on the training set\n",
    "    probOf1_trn = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_trn)).loc[:, 1])\n",
    "    probFraud_trn = pd.concat([probOf1_trn, Y_trn.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_trn = int(round(len(X_trn) * 0.03))\n",
    "    temp_trn = probFraud_trn.head(topRows_trn)\n",
    "    needed_trn = temp_trn.loc[:, 'Fraud']\n",
    "    bads_trn = probFraud_trn.loc[(probFraud_trn.Fraud == 1)]\n",
    "    FDR_trn = sum(needed_trn) / bads_trn.shape[0]\n",
    "    FDR_trn_NN2.append(FDR_trn)\n",
    "    \n",
    "    ## FDR on the test set\n",
    "    probOf1_tst = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_tst)).loc[:, 1])\n",
    "    probFraud_tst = pd.concat([probOf1_tst, Y_tst.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_tst = int(round(len(X_tst) * 0.03))\n",
    "    temp_tst = probFraud_tst.head(topRows_tst)\n",
    "    needed_tst = temp_tst.loc[:, 'Fraud']\n",
    "    bads_tst = probFraud_tst.loc[(probFraud_tst.Fraud == 1)]\n",
    "    FDR_tst = sum(needed_tst) / bads_tst.shape[0]\n",
    "    FDR_tst_NN2.append(FDR_tst)\n",
    "    \n",
    "    ## FDR on the OOT set\n",
    "    probOf1_oot = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_oot)).loc[:, 1])\n",
    "    probFraud_oot = pd.concat([probOf1_oot, Y_oot.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_oot = int(round(len(X_oot) * 0.03))\n",
    "    temp_oot = probFraud_oot.head(topRows_oot)\n",
    "    needed_oot = temp_oot.loc[:, 'Fraud']\n",
    "    bads_oot = probFraud_oot.loc[(probFraud_oot.Fraud == 1)]\n",
    "    FDR_oot = sum(needed_oot) / bads_oot.shape[0]\n",
    "    FDR_oot_NN2.append(FDR_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.70578231292517,\n",
       " 0.6818181818181818,\n",
       " 0.6915739268680445,\n",
       " 0.7231270358306189,\n",
       " 0.6948590381426202,\n",
       " 0.7324185248713551,\n",
       " 0.694078947368421,\n",
       " 0.7050847457627119,\n",
       " 0.7113564668769716,\n",
       " 0.7471264367816092]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_trn_NN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7087225617245705"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_trn_NN2)/len(FDR_trn_NN2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7178571428571429,\n",
       " 0.7301587301587301,\n",
       " 0.7071129707112971,\n",
       " 0.6692913385826772,\n",
       " 0.6830188679245283,\n",
       " 0.7403508771929824,\n",
       " 0.6961538461538461,\n",
       " 0.7482014388489209,\n",
       " 0.7521367521367521,\n",
       " 0.7335907335907336]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_tst_NN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.717787269815761"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_tst_NN2)/len(FDR_tst_NN2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5251396648044693,\n",
       " 0.39664804469273746,\n",
       " 0.5307262569832403,\n",
       " 0.5195530726256983,\n",
       " 0.5251396648044693,\n",
       " 0.547486033519553,\n",
       " 0.5027932960893855,\n",
       " 0.5307262569832403,\n",
       " 0.547486033519553,\n",
       " 0.547486033519553]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_oot_NN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5173184357541899"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_oot_NN2)/len(FDR_oot_NN2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial 3: one layer, 12 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "nitermax = 10\n",
    "FDR_trn_NN3 = []\n",
    "FDR_tst_NN3 = []\n",
    "FDR_oot_NN3 = []\n",
    "for niter in range(nitermax):\n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(x_trntst, y_trntst, test_size = 0.3)\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(12)).fit(X_trn, Y_trn)\n",
    "    \n",
    "    ## FDR on the training set\n",
    "    probOf1_trn = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_trn)).loc[:, 1])\n",
    "    probFraud_trn = pd.concat([probOf1_trn, Y_trn.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_trn = int(round(len(X_trn) * 0.03))\n",
    "    temp_trn = probFraud_trn.head(topRows_trn)\n",
    "    needed_trn = temp_trn.loc[:, 'Fraud']\n",
    "    bads_trn = probFraud_trn.loc[(probFraud_trn.Fraud == 1)]\n",
    "    FDR_trn = sum(needed_trn) / bads_trn.shape[0]\n",
    "    FDR_trn_NN3.append(FDR_trn)\n",
    "    \n",
    "    ## FDR on the test set\n",
    "    probOf1_tst = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_tst)).loc[:, 1])\n",
    "    probFraud_tst = pd.concat([probOf1_tst, Y_tst.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_tst = int(round(len(X_tst) * 0.03))\n",
    "    temp_tst = probFraud_tst.head(topRows_tst)\n",
    "    needed_tst = temp_tst.loc[:, 'Fraud']\n",
    "    bads_tst = probFraud_tst.loc[(probFraud_tst.Fraud == 1)]\n",
    "    FDR_tst = sum(needed_tst) / bads_tst.shape[0]\n",
    "    FDR_tst_NN3.append(FDR_tst)\n",
    "    \n",
    "    ## FDR on the OOT set\n",
    "    probOf1_oot = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_oot)).loc[:, 1])\n",
    "    probFraud_oot = pd.concat([probOf1_oot, Y_oot.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_oot = int(round(len(X_oot) * 0.03))\n",
    "    temp_oot = probFraud_oot.head(topRows_oot)\n",
    "    needed_oot = temp_oot.loc[:, 'Fraud']\n",
    "    bads_oot = probFraud_oot.loc[(probFraud_oot.Fraud == 1)]\n",
    "    FDR_oot = sum(needed_oot) / bads_oot.shape[0]\n",
    "    FDR_oot_NN3.append(FDR_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7487684729064039,\n",
       " 0.7089430894308943,\n",
       " 0.6694214876033058,\n",
       " 0.7377049180327869,\n",
       " 0.7203252032520325,\n",
       " 0.7386363636363636,\n",
       " 0.7512437810945274,\n",
       " 0.7389240506329114,\n",
       " 0.6939102564102564,\n",
       " 0.7475247524752475]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_trn_NN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.725540237547473"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_trn_NN3)/len(FDR_trn_NN3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6795366795366795,\n",
       " 0.6600790513833992,\n",
       " 0.7300380228136882,\n",
       " 0.7364341085271318,\n",
       " 0.6837944664031621,\n",
       " 0.7222222222222222,\n",
       " 0.720754716981132,\n",
       " 0.6991525423728814,\n",
       " 0.7090163934426229,\n",
       " 0.7404580152671756]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_tst_NN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7081486218950094"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_tst_NN3)/len(FDR_tst_NN3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5307262569832403,\n",
       " 0.44692737430167595,\n",
       " 0.4581005586592179,\n",
       " 0.5363128491620112,\n",
       " 0.5083798882681564,\n",
       " 0.5195530726256983,\n",
       " 0.5418994413407822,\n",
       " 0.5307262569832403,\n",
       " 0.4748603351955307,\n",
       " 0.5586592178770949]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_oot_NN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5106145251396648"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_oot_NN3)/len(FDR_oot_NN3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial 4: two layers, 8 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "nitermax = 10\n",
    "FDR_trn_NN4 = []\n",
    "FDR_tst_NN4 = []\n",
    "FDR_oot_NN4 = []\n",
    "for niter in range(nitermax):\n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(x_trntst, y_trntst, test_size = 0.3)\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(8, 8)).fit(X_trn, Y_trn)\n",
    "    \n",
    "    ## FDR on the training set\n",
    "    probOf1_trn = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_trn)).loc[:, 1])\n",
    "    probFraud_trn = pd.concat([probOf1_trn, Y_trn.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_trn = int(round(len(X_trn) * 0.03))\n",
    "    temp_trn = probFraud_trn.head(topRows_trn)\n",
    "    needed_trn = temp_trn.loc[:, 'Fraud']\n",
    "    bads_trn = probFraud_trn.loc[(probFraud_trn.Fraud == 1)]\n",
    "    FDR_trn = sum(needed_trn) / bads_trn.shape[0]\n",
    "    FDR_trn_NN4.append(FDR_trn)\n",
    "    \n",
    "    ## FDR on the test set\n",
    "    probOf1_tst = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_tst)).loc[:, 1])\n",
    "    probFraud_tst = pd.concat([probOf1_tst, Y_tst.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_tst = int(round(len(X_tst) * 0.03))\n",
    "    temp_tst = probFraud_tst.head(topRows_tst)\n",
    "    needed_tst = temp_tst.loc[:, 'Fraud']\n",
    "    bads_tst = probFraud_tst.loc[(probFraud_tst.Fraud == 1)]\n",
    "    FDR_tst = sum(needed_tst) / bads_tst.shape[0]\n",
    "    FDR_tst_NN4.append(FDR_tst)\n",
    "    \n",
    "    ## FDR on the OOT set\n",
    "    probOf1_oot = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_oot)).loc[:, 1])\n",
    "    probFraud_oot = pd.concat([probOf1_oot, Y_oot.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_oot = int(round(len(X_oot) * 0.03))\n",
    "    temp_oot = probFraud_oot.head(topRows_oot)\n",
    "    needed_oot = temp_oot.loc[:, 'Fraud']\n",
    "    bads_oot = probFraud_oot.loc[(probFraud_oot.Fraud == 1)]\n",
    "    FDR_oot = sum(needed_oot) / bads_oot.shape[0]\n",
    "    FDR_oot_NN4.append(FDR_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7654723127035831,\n",
       " 0.7698541329011345,\n",
       " 0.770764119601329,\n",
       " 0.7602627257799671,\n",
       " 0.7625418060200669,\n",
       " 0.7934426229508197,\n",
       " 0.7528089887640449,\n",
       " 0.7766497461928934,\n",
       " 0.7324414715719063,\n",
       " 0.7854889589905363]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_trn_NN4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7669726885476281"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_trn_NN4)/len(FDR_trn_NN4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7677165354330708,\n",
       " 0.7250996015936255,\n",
       " 0.7631578947368421,\n",
       " 0.7413127413127413,\n",
       " 0.774074074074074,\n",
       " 0.7558139534883721,\n",
       " 0.7755102040816326,\n",
       " 0.6931407942238267,\n",
       " 0.774074074074074,\n",
       " 0.7735042735042735]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_tst_NN4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7543404146522532"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_tst_NN4)/len(FDR_tst_NN4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5418994413407822,\n",
       " 0.5363128491620112,\n",
       " 0.5139664804469274,\n",
       " 0.5307262569832403,\n",
       " 0.5698324022346368,\n",
       " 0.5810055865921788,\n",
       " 0.5418994413407822,\n",
       " 0.5307262569832403,\n",
       " 0.5418994413407822,\n",
       " 0.5698324022346368]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_oot_NN4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5458100558659218"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_oot_NN4)/len(FDR_oot_NN4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial 5: two layers, 8 nodes, activation = 'logistic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "nitermax = 10\n",
    "FDR_trn_NN5 = []\n",
    "FDR_tst_NN5 = []\n",
    "FDR_oot_NN5 = []\n",
    "for niter in range(nitermax):\n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(x_trntst, y_trntst, test_size = 0.3)\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(8, 8), activation = 'logistic').fit(X_trn, Y_trn)\n",
    "    \n",
    "    ## FDR on the training set\n",
    "    probOf1_trn = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_trn)).loc[:, 1])\n",
    "    probFraud_trn = pd.concat([probOf1_trn, Y_trn.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_trn = int(round(len(X_trn) * 0.03))\n",
    "    temp_trn = probFraud_trn.head(topRows_trn)\n",
    "    needed_trn = temp_trn.loc[:, 'Fraud']\n",
    "    bads_trn = probFraud_trn.loc[(probFraud_trn.Fraud == 1)]\n",
    "    FDR_trn = sum(needed_trn) / bads_trn.shape[0]\n",
    "    FDR_trn_NN5.append(FDR_trn)\n",
    "    \n",
    "    ## FDR on the test set\n",
    "    probOf1_tst = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_tst)).loc[:, 1])\n",
    "    probFraud_tst = pd.concat([probOf1_tst, Y_tst.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_tst = int(round(len(X_tst) * 0.03))\n",
    "    temp_tst = probFraud_tst.head(topRows_tst)\n",
    "    needed_tst = temp_tst.loc[:, 'Fraud']\n",
    "    bads_tst = probFraud_tst.loc[(probFraud_tst.Fraud == 1)]\n",
    "    FDR_tst = sum(needed_tst) / bads_tst.shape[0]\n",
    "    FDR_tst_NN5.append(FDR_tst)\n",
    "    \n",
    "    ## FDR on the OOT set\n",
    "    probOf1_oot = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_oot)).loc[:, 1])\n",
    "    probFraud_oot = pd.concat([probOf1_oot, Y_oot.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_oot = int(round(len(X_oot) * 0.03))\n",
    "    temp_oot = probFraud_oot.head(topRows_oot)\n",
    "    needed_oot = temp_oot.loc[:, 'Fraud']\n",
    "    bads_oot = probFraud_oot.loc[(probFraud_oot.Fraud == 1)]\n",
    "    FDR_oot = sum(needed_oot) / bads_oot.shape[0]\n",
    "    FDR_oot_NN5.append(FDR_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6908517350157729,\n",
       " 0.6599063962558502,\n",
       " 0.6915584415584416,\n",
       " 0.687603305785124,\n",
       " 0.6859504132231405,\n",
       " 0.6962233169129721,\n",
       " 0.6913183279742765,\n",
       " 0.6857142857142857,\n",
       " 0.6981757877280266,\n",
       " 0.6852791878172588]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_trn_NN5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6872581197985149"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_trn_NN5)/len(FDR_trn_NN5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6794871794871795,\n",
       " 0.7224669603524229,\n",
       " 0.6666666666666666,\n",
       " 0.7034220532319392,\n",
       " 0.6653992395437263,\n",
       " 0.6602316602316602,\n",
       " 0.6626016260162602,\n",
       " 0.6886446886446886,\n",
       " 0.6415094339622641,\n",
       " 0.6750902527075813]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_tst_NN5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.676551976084439"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_tst_NN5)/len(FDR_tst_NN5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4022346368715084,\n",
       " 0.4301675977653631,\n",
       " 0.4134078212290503,\n",
       " 0.3743016759776536,\n",
       " 0.44692737430167595,\n",
       " 0.39664804469273746,\n",
       " 0.41899441340782123,\n",
       " 0.45251396648044695,\n",
       " 0.40782122905027934,\n",
       " 0.4301675977653631]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_oot_NN5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4173184357541899"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_oot_NN5)/len(FDR_oot_NN5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosted Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial 1: # of trees = 800, max_depth = 3, learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "nitermax = 10\n",
    "FDR_trn_xgb1 = []\n",
    "FDR_tst_xgb1 = []\n",
    "FDR_oot_xgb1 = []\n",
    "for niter in range(nitermax):\n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(x_trntst, y_trntst, test_size = 0.3)\n",
    "    clf = GradientBoostingClassifier(n_estimators = 800, max_depth = 3, learning_rate = 0.1).fit(X_trn, Y_trn)\n",
    "    \n",
    "    ## FDR on the training set\n",
    "    probOf1_trn = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_trn)).loc[:, 1])\n",
    "    probFraud_trn = pd.concat([probOf1_trn, Y_trn.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_trn = int(round(len(X_trn) * 0.03))\n",
    "    temp_trn = probFraud_trn.head(topRows_trn)\n",
    "    needed_trn = temp_trn.loc[:, 'Fraud']\n",
    "    bads_trn = probFraud_trn.loc[(probFraud_trn.Fraud == 1)]\n",
    "    FDR_trn = sum(needed_trn) / bads_trn.shape[0]\n",
    "    FDR_trn_xgb1.append(FDR_trn)\n",
    "    \n",
    "    ## FDR on the test set\n",
    "    probOf1_tst = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_tst)).loc[:, 1])\n",
    "    probFraud_tst = pd.concat([probOf1_tst, Y_tst.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_tst = int(round(len(X_tst) * 0.03))\n",
    "    temp_tst = probFraud_tst.head(topRows_tst)\n",
    "    needed_tst = temp_tst.loc[:, 'Fraud']\n",
    "    bads_tst = probFraud_tst.loc[(probFraud_tst.Fraud == 1)]\n",
    "    FDR_tst = sum(needed_tst) / bads_tst.shape[0]\n",
    "    FDR_tst_xgb1.append(FDR_tst)\n",
    "    \n",
    "    ## FDR on the OOT set\n",
    "    probOf1_oot = pd.DataFrame(pd.DataFrame(clf.predict_proba(X_oot)).loc[:, 1])\n",
    "    probFraud_oot = pd.concat([probOf1_oot, Y_oot.reset_index(drop=True)], axis=1).sort_values(1, ascending = False)\n",
    "    topRows_oot = int(round(len(X_oot) * 0.03))\n",
    "    temp_oot = probFraud_oot.head(topRows_oot)\n",
    "    needed_oot = temp_oot.loc[:, 'Fraud']\n",
    "    bads_oot = probFraud_oot.loc[(probFraud_oot.Fraud == 1)]\n",
    "    FDR_oot = sum(needed_oot) / bads_oot.shape[0]\n",
    "    FDR_oot_xgb1.append(FDR_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9983606557377049,\n",
       " 0.9982905982905983,\n",
       " 0.9983221476510067,\n",
       " 0.9983416252072969,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9967845659163987,\n",
       " 0.9983974358974359,\n",
       " 1.0]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_trn_xgb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988497028700442"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_trn_xgb1)/len(FDR_trn_xgb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9224806201550387,\n",
       " 0.8657243816254417,\n",
       " 0.8897058823529411,\n",
       " 0.9132075471698113,\n",
       " 0.8676470588235294,\n",
       " 0.9087591240875912,\n",
       " 0.8939929328621908,\n",
       " 0.8861788617886179,\n",
       " 0.9016393442622951,\n",
       " 0.8683274021352313]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_tst_xgb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8917663155262687"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_tst_xgb1)/len(FDR_tst_xgb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5251396648044693,\n",
       " 0.5195530726256983,\n",
       " 0.5586592178770949,\n",
       " 0.5307262569832403,\n",
       " 0.4245810055865922,\n",
       " 0.4748603351955307,\n",
       " 0.5642458100558659,\n",
       " 0.4972067039106145,\n",
       " 0.5139664804469274,\n",
       " 0.5418994413407822]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_oot_xgb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5150837988826817"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(FDR_oot_xgb1)/len(FDR_oot_xgb1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
